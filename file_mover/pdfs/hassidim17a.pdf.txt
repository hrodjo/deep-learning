Robust Guarantees of Stochastic Greedy Algorithms

Avinatan Hassidim 1 Yaron Singer 2

Abstract
In this paper we analyze the robustness of
stochastic variants of the greedy algorithm for
submodular maximization. Our main result
shows that for maximizing a monotone submodular function under a cardinality constraint, iteratively selecting an element whose marginal contribution is approximately maximal in expectation is a sufficient condition to obtain the optimal approximation guarantee with exponentially
high probability, assuming the cardinality is sufficiently large. One consequence of our result is
that the linear-time S TOCHASTIC -G REEDY algorithm recently proposed in (Mirzasoleiman et al.,
2015) achieves the optimal running time while
maintaining an optimal approximation guarantee. We also show that high probability guarantees cannot be obtained for stochastic greedy algorithms under matroid constraints, and prove an
approximation guarantee which holds in expectation. In contrast to the guarantees of the greedy
algorithm, we show that the approximation ratio
of stochastic local search is arbitrarily bad, with
high probability, as well as in expectation.

1. Introduction
In this paper we study the guarantees of stochastic optimization algorithms for submodular maximization. A function f : 2N → R is submodular if it exhibits a diminishing
returns property. That is, for any S ⊆ T ⊆ N and any
a∈
/ T , the function respects:
fS (a) ≥ fT (a)
where fH (x) denotes the marginal contribution of an element x ∈ N to a set H ⊆ N , i.e. fH (x) = f (H ∪ x) −
*

1
Equal contribution
Bar Ilan University and
Google 2 Harvard University.
Correspondence to:
Avinatan Hassidim <avinatan@cs.biu.ac.il>, Yaron Singer
<yaron@seas.harvard.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

f (H). Many fundamental measures such as entropy, diversity, and clustering can be modeled as submodular functions, and as a result submodular optimization is heavily
studied in machine learning for well over a decade now.
It is well known that for the problem of maximizing a
monotone (S ⊆ T =⇒ f (S) ≤ f (T )) submodular function under a cardinality constraint, the celebrated greedy algorithm which iteratively adds the element whose marginal
contribution is maximal, obtains an approximation guarantee of 1 − 1/e (Nemhauser et al., 1978). This is optimal unless P=NP (Feige) or alternatively, assuming polynomiallymany function evaluations (Nemhauser & Wolsey, 1978).
In recent years, there have been various adaptations of
the classic greedy algorithm to allow for scalable, distributed, and noise-resilient optimization. Most notably,
the S TOCHASTIC -G REEDY algorithm recently proposed
by (Mirzasoleiman et al., 2015) is a linear-time algorithm
which at every step takes an element, which approximates
in expectation the element with the maximal marginal contribution. Mirzasoleiman et al. show that S TOCHASTIC G REEDY gives an approximation guarantee which is arbitrarily close to 1 − 1/e in expectation, and does very well
in practice (Mirzasoleiman et al., 2015; Lucic et al., 2016).
Variants of this algorithm are used in clustering (Malioutov
et al., 2016), sparsification (Lindgren et al., 2016), Gaussian RBF kernels (Sharma et al., 2015), sensing (Li et al.,
2016), and social data analysis (Zhuang et al., 2016).
More generally, a greedy algorithm that iteratively adds elements that are only approximately maximal in expectation, may not necessarily be due to a design decision, but
rather an artifact of its application on large and noisy data
sets (see e.g. (Azaria et al., 2013)). One can model this
uncertainty with a probability distribution D: at every iteration, a value ξ ∼ D is being sampled, and the greedy
algorithm adds an element whose marginal contribution is
a ξ-approximation to the maximal marginal contribution.
In general, we refer to an algorithm that iteratively adds an
element whose marginal contribution is approximately optimal in expectation as a stochastic greedy algorithm. It is
easy to show that stochastic greedy algorithms give an approximation ratio of 1 − 1/eµ in expectation, where µ is
the mean of the distribution modeling the uncertainty. This
however is a weak guarantee as it leaves a non-negligible

Robust Guarantees of Stochastic Greedy Algorithms

likelihood that the algorithm terminates with a solution
with a poor approximation guarantee. Indeed, as we later
show, there are cases where stochastic greedy algorithms
have desirable guarantees in expectation, but with constant
probability have arbitrarily bad approximation guarantees.
Do stochastic optimization algorithms for submodular
maximization have robust approximation guarantees?
1.1. Our results
We prove the following results:
• Optimization under cardinality constraints. For
the problem of maximizing a monotone submodular
function under cardinality constraint k, with uncertainty distribution D with expectation µ, we show that
for any ε ∈ [0, 1], when k ≥ µε1 2 a stochastic greedy
algorithm obtains an approximation of 1 − 1/e(1−ε)µ
2
w.p. at least 1 − e−µkε /2 . Furthermore, we prove that
this bound is optimal by showing that for any δ > 0
no algorithm can obtain an approximation ratio better
than 1 − 1/e(1−ε)µ w.p. 1 − δ. For the special case in
which the function is modular, we prove an improved
2
bound of (1 − ε)µ w.p. at least 1 − e−µkε /2 ;
• Optimization under matroid constraints. To further study the difference between guarantees that occur in expectation and guarantees which appear w.h.p,
we study a generalization, where the greedy algorithm
is used to maximize a monotone submodular function
under intersection of matroid constraints, where a distribution D with mean µ generates uncertainty. We
show that in this case, with P matroids the algorithm
obtains an approximation ratio of µ/(P + 1) in expectation. However, we show that even for a single matroid no algorithm can give a finite approximate guarantee w.p. at least 1−µ−o(1), implying that in general
stochastic greedy algorithms cannot obtain high probability guarantees under general matroid constraints;
• Stochastic local search. Finally, a natural alternative
to greedy is local search. We show that even for cardinality constraints local search performs poorly, and
does not give any meaningful approximation guarantees when there is probabilistic uncertainty about the
quality of the elements. We contrast this with the
case where there is deterministic uncertainty about the
quality of the elements, in which we get an approximation ratio of (1 + 1/µ)−1 , where µ is our uncertainty. This implies that local search does not enjoy
the same robustness guarantees of the greedy algorithms under uncertainty of the quality of elements.

1.2. Applications
The above results have several immediate consequences:
• Fast algorithms for submodular optimization. Our
analysis applies to the S TOCHASTIC -G REEDY algorithm (Mirzasoleiman et al., 2015), thus showing its
approximation guarantee holds with high probability,
implying it is the optimal algorithm in terms of running time and approximation guarantee for the problem of maximizing a submodular function under a cardinality constraint; 1 The same guarantee holds for the
variants studied in (Malioutov et al., 2016; Lindgren
et al., 2016; Sharma et al., 2015; Li et al., 2016);
• Submodular optimization under noise. In (Hassidim & Singer, 2017) the problem of maximization
of submodular functions under a cardinality constraint
is considered when given access to a noisy oracle. Our
result simplifies the analysis of one of the algorithms
in this setting, and gives high probability results for
the inconsistent noise model (Singla et al., 2016).
1.3. Organization of the paper
We describe the results for general monotone submodular
functions in Section 2, and the improved analysis for modular functions in Section 3. In Section 4 we consider the
more general problem of maximizing a submodular function under matroid constraints, and show the inapproximabilities of stochastic local search algorithms in Section 5.
Finally, we discuss experiments in Section 6.

2. Submodular Functions
In this section we analyze the stochastic greedy algorithm
for general monotone submodular functions. We first analyze the algorithm, and then show the bound is tight.
2.1. Upper bound
For a given cardinality constraint k, the standard greedy algorithm begins with the empty set as its solution and at each
step {1, . . . , k} adds the element whose marginal contribution to the existing solution is largest. In the stochastic version, the algorithm may no longer add the element whose
marginal contribution is largest. Rather, the algorithm adds
the element whose marginal contribution is at least a factor of ξ from the maximal marginal contribution, where ξ
is drawn i.i.d from some distribution D with mean µ. We
give a formal description below.
1

Formally, the algorithm in (Mirzasoleiman et al., 2015) does
not assume that the expected marginal contribution of the element
selected is approximately optimal, but rather that in expectation
its marginal contribution approximates that of some element in
the optimal solution. Nevertheless our analysis still applies.

Robust Guarantees of Stochastic Greedy Algorithms

Algorithm 1 S TOCHASTIC -G REEDY

and using the inductive hypothesis:

input k
1: S ← ∅
2: while |S| < k do
3:
ξ∼D
4:
S ← S ∪ arbitrary a s.t. fS (a) ≥ ξ maxx∈N fS (x)
5: end while
output S

The following lemma shows that when the sampled mean
of the distribution is close to 1, stochastic greedy algorithms obtain a near optimal performance guarantee.
Lemma 1. Let S be the set of k elements selected by a
stochastic greedy algorithm s.t. in each iteration i ∈ [k]
the algorithm selects an element whose marginal contribution is an ξi approximation to the marginal contribution of
the element with the P
largest marginal contribution at that
k
stage, and let µ̂ = k1 i=1 ξi . Then:

f (S) ≥

1
1 − µ̂
e


OPT.

Proof. Let Si = {a1 , . . . , ai }, and let the optimal solution
be O, i.e. O ∈ argmaxT :|T |≤k f (T ). Note that for any
i < k we have that:
f (Si+1 ) − f (Si ) = fSi (ai+1 )
≥ ξi+1 max fSi (o)
ξi+1
fSi (O)
k
ξi+1
(f (O ∪ Si ) − f (Si ))
=
k
ξi+1
(f (O) − f (Si ))
≥
k

Rearranging, we get:
(1)

We will show by induction that in every iteration i ∈ [k]:

f (Si ) ≥ 1 −

i 
Y
j=1



ξj 
1−
f (O)
k

The base case is when i = 1, and S0 = ∅ and by (1):
f (S1 ) ≥

Since 1 − x ≤ e−x , the above inequality implies:
f (S) = f (Sk )




k 
Y
ξ
j
 f (O)
= 1 −
1−
k
j=1


Pk
1
≥ 1 − e− k i=1 ξi f (O)

= 1 − e−µ̂ f (O).

We can now apply concentration bounds on the previous
lemma and prove the main theorem.
Theorem 2. Let f be a monotone submodular function,
which is evaluated with uncertainty coming from a distribution D with mean µ. For any ε ∈ (0, 1), suppose a
stochastic greedy algorithm is being used with k ≥ ε22µ .
εµ·k
2

the algorithm returns S s.t.:


1
f (S) ≥ 1 − (1−ε)µ OPT
e

≥


ξi+1 
f (O) − f (Si ) + f (Si )
k



ξi+1
ξi+1
f (O) + 1 −
f (Si )
≥
k
k





i 
Y
ξi+1 
ξi+1
ξj 
f (O) + 1 −
1−
f (O)
≥
1−
k
k
k
j=1



i+1
Y
ξ
j 
= 1 −
f (O)
1−
k
j=1

Then, w.p. 1 − e−

o∈O

f (Si+1 ) ≥

f (Si+1 )




ξi+1 
ξ1
f (O) − f (S0 ) = 1 − 1 −
f (O)
k
k

For a general iteration i + 1, applying (1) for iteration i + 1

Proof. Consider an application of the stochastic greedy algorithm with mean µ, and let ξ1 , . . . , ξk be the approximations to the marginal contributions made by i.i.d samples from a distribution in all iterations 1, . . . , k. Since all
the values {ξi }ki=1 drawn from the distribution are bounded
from above by 1, by the Chernoff bound we have:
" k
#
εµ·k
1X
Pr
ξi < (1 − ε)µ < e 2
k i=1
By applying Lemma 1 we get our result.
2.2. Tight lower bound
Claim 3. For any δ ∈ [0, 1) the competitive ratio of
stochastic greedy with mean µ is at most (1 − 1/eµ ) + o(1)
with probability at least 1 − δ.
Proof. Consider maximizing a submodular function when
the oracle has probability µ of returning the element with

Robust Guarantees of Stochastic Greedy Algorithms

the largest marginal contribution, and probability 1 − µ to
return a random element. We present an instance where
greedy returns an approximation ratio of at most 1−1/eµ +
o(1) with probability at least 1 − 1/k. We use the same bad
instance regardless of µ.
The construction is as follows. There are k special elements, m = 4k 3 plain elements and n = 4(m + k)k 2
dummy elements (note that the total number of elements
is not n). The value f (S) depends only on the number of
special elements, plain elements and dummy elements contained in S (all special elements are identical). Moreover,
dummy elements contribute nothing to f , and hence, we
can write f (S) = f (i, j), where i is the number of special
elements in S, and j is the number of plain elements.
For i ≥ 1, the value of f depends on j as follows:
 k
k -(k-1)j k k-j-1 (k-i)



k k -(k-1)k-2 ((k-i)(2k-2-j))
f (i, j) =

k k -(k-1)k-2 (3k-i-j-3)


 k
k

0 ≤ j ≤ k-1

condition on this event. Assuming by induction that the last
i − 1 non dummy elements which were chosen by greedy
were plain, the probability that i’th non dummy element is
plain is 1 − 4k3k−1 . Taking a union bound over all t such
elements, gives that with probability 1 − 1/3k all t nondummy elements chosen by greedy were plain.
Combining this together with a union bound, we get that
with probability at least 1 − 1/k
√ greedy chose no special
elements, at most t = µk + 4 k log k plain elements, and
the rest are dummy elements that do not contribute to the
value of the function. This means that the value of the solution is at most k k − (k − 1)t k k−t , and thus with probability
at least 1 − 1/k the ratio between the value of greedy and
the optimal value is at least:
k k − (k − 1)t k k−t
=1−
kk

k ≤ j ≤ 2k-3
2k-2 ≤ j ≤ 3k-3-i
3k − i − 2 ≤ j

Note that for i = 0, we have f (0, j) = f (1, j − 1), and
f (0, 0) = 0. Also, one can verify, by case-by-case analysis
that this function is indeed monotone and submodular.
Since f (0, j) = f (1, j − 1) for every j ≥ 1, as long as the
greedy algorithm did not choose any special element yet,
the marginal contribution of a special elements is equal to
the marginal contribution of a plain element.
Let t be the number of times in which the oracle supplied the greedy algorithm with the element with the maximal marginal contribution. By an additive version of
the Chernoff bound we have that with probability at least
1 − 24 log k = 1 − k 4 :
√
t < kµ + 2 k log k
We condition on this event. Next, we argue that with probability at least 1 − 1/3k all the elements for which the algorithm selected a random element (i.e. did not take an
element whose marginal contribution is a µ approximation
to the largest marginal contribution) are dummy elements.
Consider one of the times in which greedy was given a random element. The probability that it was not a dummy elm+k
ement is at most 4(m+k)k
2 −k . Applying a union bound,
the probability that in the k − t cases in which greedy was
supplied with a random element it was always a dummy
element is at least 1 − 1/3k. We condition on this event.
We will now argue that with probability at least 1−1/3k all
the non-dummy elements selected are plain. Consider the
first non dummy element chosen by the algorithm. With
probability at least 1 − k/4k 3 it is a plain element. We

≥1−



t
k−1
k
k
√

k !µ+ 4 log
k
1
1−
k

≥ 1 − e−(µ+4 log k/

√

k)

= 1 − e−µ + o(1)
Choosing k = 1/δ we get our desired bound.

3. Modular Functions
In this section we show a tight upper bound for the special case in which the function is modular. Recall that a
function f : 2N → R P
is modular if for every set S ⊆ N
we have that f (S) = a∈S f (a). Note that in this case
fS (a) = f (a) for all S ⊆ N and a ∈ N .
Theorem 4. Let S ⊆ N be the set returned when applying
a stochastic greedy algorithm with mean µ ∈ [0, 1] on a
modular function f : 2N → R. Then, for any ε ∈ [0, 1],
2
when k ≥ ε22µ w.p. 1 − e−µkε /2 :
f (S) ≥ (1 − ε)µOPT.
Proof. Suppose that at every stage i ∈ [k] element ai ∈ N
is selected and its marginal contribution is at least ξi of
the optimal marginal contribution at that stage. Let O be
the optimal solution and o? ∈ argmaxo∈O\S f (o), where
S is the solution retuned by the algorithm, i.e. S =
{a1 , . . . , ak }. The basic idea in this proof is to observe
that since o? is not in the solution and throughout the iterations of the algorithm is always a feasible candidate, this
implies that every element ai in the solution S \O has value
at least as large as ξi f (o? ). Intuitively, if there are enough
elements in S \ P
O for concentration bounds to kick in, we
1
have that |S\O|
j∈S\O ξj = (1 − ε)µ and we would be
done since f (S) = f (S \ O) + f (O ∩ S) ≥ (1 − ε)µf (O).

Robust Guarantees of Stochastic Greedy Algorithms

The problem is that S \ O may not be sufficiently large, and
we therefore need slightly more nuanced arguments.
We will partition O ∩ S to two disjoint sets of low and high
valued elements: L = {o ∈ O ∩ S : f (o) < f (o? )} and
H = {o ∈ O ∩ S : f (o) ≥ f (o? )}. Notice that:
f (O)
= f (O \ S) + f (L) + f (H)
X
X
X
=
f (o) +
f (o) +
f (o)
o∈L

o∈O\S

≤

X

f (o? ) +

f (o? ) +

o∈L

o∈O\S
?

= k · f (o ) +

X

4. General Matroid Constraints

o∈H

X

X




f (o? ) + f (o)-f (o? )

o∈H
?

(f (o)-f (o ))

o∈H

Since o? ∈ O \ S, it is a feasible choice for the algorithm at
every stage, and therefore by the definition of the stochastic
greedy algorithm, for every element ai ∈ S we have that:
f (ai ) ≥ ξi max fS (a) = ξi max f (a) ≥ ξi f (o? )
a∈N

kµε2
2

:

f (S)
= f (S \ O) + f (H) + f (L)
X
X
X
=
f (ai ) +
f (ai ) +
f (o)
≥

X

ai ∈L

ξi f (o? ) +

o∈H

X

ξi f (o? ) +

ai ∈L

ai ∈S\O


= f (o? ) 


X

X

ξi  +

f (o)

o∈H




X

X

ξi  +

f (o? ) + f (o)-f (o? )



o∈H

ai ∈(S\O)∪L


≥ f (o? ) 

f (o)

o∈H

ai ∈(S\O)∪L

= f (o? ) 

X


X

ξi  +

ai ∈(S\O)∪L∪H

≥ (1 − ε)µ · kf (o? ) +

In this section we consider the more general problem of
maximizing a monotone submodular function under matroid constraints. Recall that a matroid is a pair (N, I)
where N is the ground set and I is a family of subsets
of N called independent that respects two axioms: (1)
A ∈ I, A0 ⊂ A =⇒ A0 ∈ I and (2) if A, B ∈ I and
|B| < |A| then ∃x ∈ A \ B, s.t. B ∪ {x} ∈ I. The rank
of the matroid is the size of the largest set in I. The cardinality constraint, is a special case of optimization under
matroid constraints, where the matroid is uniform.
Submodular maximization under matroid constraints.
The greedy algorithm for maximization under matroid constraints is a simple generalization of the uniform case: the
algorithm iteratively identifies the element whose marginal
contribution is maximal and adds it to the solution if it does
not not violate the matroid constraint (i.e. if adding the element to the set keeps the set in the family of feasible sets
I). This algorithm obtains an approximation ratio of 1/2. 2
More generally, for an intersection of P matroids, this algorithm obtains an approximation guarantee of 1/(1 + P ).

a∈N \S

Thus, for k ≥ 2/ε2 with probability 1 − e−

ai ∈S\O

The upper bound is tight. An obvious lower bound
holds for the degenerate case where in every stage the
marginal contribution of the element returned is a µ ∈ [0, 1]
approximation to the maximal marginal contribution with
probability 1. Clearly in this case, the approximation ratio is no better than µ (consider n = 2k elements where k
elements have value 1 and k elements have value µ).

X

X


f (o)-f (o? )

(2)

o∈H


f (o)-f (o? )

(3)

Stochastic greedy under intersection of matroids.
Consider an intersection of matroids, a monotone submodular function f defined over the independent sets, and an
uncertainty distribution D with mean µ. The stochastic
greedy algorithm begins with the solution S = ∅ and set of
elements not yet considered X = N . In every iteration the
algorithm maintains a solution S of elements that are in the
intersection of the P matroids and a value ξ ∼ D is sampled. The algorithm then considers an arbitrary element
a ∈ X whose marginal contribution is ξ maxx∈X fS (x),
and adds a to S if S ∪ a is independent in all P matroids,
and discards a from X.

o∈H


X
≥ (1 − ε)µ kf (o ) +
f (o)-f (o? )

!

?

o∈H

≥ (1 − ε)µf (O)
where inequality (2) is due to the fact that f (o? ) ≥ ξi f (o? )
since ξi ≤ 1; inequality (3) is an application of the Chernoff bound for k ≥ 2/ε2 µ; the last inequality is due to the
upper bound we established on f (O).

4.1. Stochastic greedy fails with high probability
We first show that unlike the special case of uniform matroids, even for a single matroid, it is generally impossible
to obtain high probability guarantees for maximization un2
We note that unlike the uniform case, here greedy is not optimal. The optimal guarantee of 1 − 1/e can be obtained via an
algorithm based on a continuous relaxation (Vondrák, 2008) or
through local search (Filmus & Ward, 2012).

Robust Guarantees of Stochastic Greedy Algorithms

der matroid constraints, even when the function is modular
and the rank of the matroid is sufficiently large.
Claim 5. Even for a modular function and arbitrarily large
k, a stochastic greedy algorithm with mean µ cannot obtain
an approximation better than 0 with probability greater
than µ + o(1), for maximization under matroid of rank k.
Proof. Consider the following example, where the ground
set has two types of elements A = {a1 , . . . , am }, and B =
{b1 , . . . , bk−1 } where m = k 2 . The rank of the matroid
is k, and a set is independent as long as it contains just a
single ai ∈ A. Define a modular function: f (a1 ) = 1, but
f (aj ) = 0 for j 6= 1, and also f (bj ) = 0 for any j ∈ [k−1].
The distribution returns 1 w.p. p < 1/2 and 0 otherwise.
In the first iteration of the algorithm, the element a1 is
correctly evaluated with probability p, and with probability 1 − p it is evaluated as having value 0, in which case
we may assume that a random element is selected instead.
Therefore, w.p. p the algorithm takes a1 , and obtains the
optimal solution. However, if this is not the case, then w.p.
m − 1/(m + k) = (k 2 − 1)/(k 2 + k) the algorithm chooses
an element from A whose value is 0. In this case, even
if a1 is later correctly evaluated it could not be considered
into the solution since its inclusion violates independence.
Hence, while the expected value of greedy is slightly larger
than p, with probability at least (1 − p) − o(1) the value of
the solution would be 0.
4.2. The guarantee holds in expectation
Although the approximation guarantee cannot hold with
high probability, we now show that in expectation stochastic greedy algorithms achieves the approximation guarantee of non-stochastic greedy when maximizing a monotone
submodular functions under an intersection of P matroids.
Theorem 6. Let F denote the intersection of P ≥ 1 matroids on the ground set N , and f : 2N → R be a monotone
submodular function. The stochastic greedy algorithm returns a solution S ∈ F s.t.:
µ
E[f (S)] ≥
OPT
(P + 1)
.
An equivalent algorithm. To simplify the analysis, it
will be useful to consider the equivalent algorithm, which
at every iteration when the existing solution is S, discards
all elements x for which S ∪ x ∈
/ F. The following claim
due to Nemhauser et al. is later employed in our analysis:
Claim 7P
(Prop. 2.2 in (Nemhauser et al., 1978)). If for
t−1
∀t ∈ [k] i=0 σi ≤ t and pi−1 ≥ pi , with σi , pi ≥ 0 then:
k−1
X
i=0

pi σi ≤

k−1
X
i=0

pi .

Algorithm 2 S TOCHASTIC -M ATROID -G REEDY
1: S ← ∅, X ← N
2: while X 6= S do
3:
X ← X \ {x : S ∪ {x} ∈
/ F}
4:
ξ ∼ D.
5:
S ← S ∪ arbitrary a s.t. fS (a) ≥ ξ maxx∈X fS (x)
6: end while

Proof of Lemma 6. Consider the value obtained by the
following procedure. An adversary chooses some maximal independent set a1 , . . . ak . Let Si = {a1 , a2 , . . . , ai }
with S0 = ∅, and for every i ∈ [k] let a?i be the element
that maximizes the marginal contribution given Si , where
the maximization is over elements a such that Si ∪ {a} is
independent in all P matroids. That is a?i is defined as:
max

Si ∪{a}∈F

fSi (a)

The value of the procedure is then:
k−1
X

fSi (a?i )

i=0

We will bound the value obtained by the procedure against
that of the optimal solution, and then argue that the value
obtained by the stochastic greedy is equivalent.
Let O denote the optimal solution. We have that:
X
f (O) ≤ f (O ∪ Sk ) ≤ f (Sk ) +
fSk (x)

(4)

x∈O\Sk

For a set S and a matroid Mp in the family F, we define
rp (S), called the rank of S in Mp to be the cardinality of
the largest subset of S which is independent in Mp , and
define spp (S), called the span of S in Mp by:
spp (S) = {a ∈ N : rp (S ∪ a) = rp (S)}
If S is independent in Mp , we have that rp (spp (S)) =
rp (S) = |S|. In particular, we have that rp (spp (Si )) = i
for every Si . Now in each 1 ≤ p ≤ P , since O is an
independent set in Mp we have:
rp (spp (Si ) ∩ (O)) = |spp (Si ) ∩ (O)|
which implies that |spp (Si ) ∩ (O)| ≤ i.
Define Ui = ∪P
p=1 spp (Si ), to be the set of elements which
are not part of the maximization in step i + 1 of the procedure, and hence cannot give value at that stage. We have:
i
|Ui ∩O| = |(∪P
p=1 spp (S ))∩O| ≤

P
X
p=1

|spp (S i )∩O| ≤ iP

Robust Guarantees of Stochastic Greedy Algorithms

Let Vi = (Ui \ Ui−1 ) ∩ O be the elements of O which are
not part of the maximization in step i, but were part of the
maximization in step i − 1. If x ∈ Vi then it must be that:
fSk (x) ≤ fSi (x) ≤ fSi (a?i )
since x was not chosen in step i. Hence, we can upper
bound:
X

fSk (x) ≤

=

fSi (a?i )

i=1 x∈Vi

x∈O\Sk
k
X

k X
X

|Vi |fSi (a? ) ≤ P

i=1

k
X

fSi (a? )

i=1

Pi
where the last inequality uses t=1 |Vt | = |Ui ∩ O| ≤
P i and the arithmetic claim proven in Claim 7 due
to (Nemhauser et al., 1978). Together with (4), we get:

search algorithms converge in polynomial time, the convention is to seek approximate local maxima. A solution S
is an α-approximate local maximum if no element ai in S
can be exchanged for another element aj not in S whose
marginal contribution to S−i is greater by a factor of α. It
is easy to show that an α-approximate local maximum is a
(1 + 1/α)−1 approximation (Filmus & Ward, 2012).
Stochastic local search. A natural question is whether
local search enjoys the same robustness guarantees as the
greedy algorithm. We say that a solution S is a stochastic local maximum up to approximation µ if no single element in S can be exchanged for another element not in S
whose expected marginal contribution is greater by a factor
µ. That is, S is a stochastic local maximum with mean µ if
for every ai ∈ S we have that:
E[fS−i (ai )] ≥ µ · max fS−i (x)
x∈S
/

f (O) ≤ (P + 1)

k
X

fSi (a?i )

i=1

Finally, note that S TOCHASTIC -M ATROID -G REEDY obtains a µ = Eξ∼D [ξ] approximation of the value of the
procedure, in expectation. In each stage, one can add the
element chosen by the algorithm to the procedure. Hence,
at each stage S TOCHASTIC -M ATROID -G REEDY and the
procedure have the same set of elements available, and the
same a?i which maximizes the marginal contribution.

5. Inapproximability of Local Search
In this section we consider variants of stochastic local
search algorithms. We show that unlike the greedy algorithm, stochastic local search algorithms can end up with
arbitrarily bad approximation guarantees.
Local search for submodular maximization. For N =
{a1 , . . . , an }, given a set of elements T ⊆ N we will use
T−i to denote the set without element ai , i.e. T−i = T \
{ai }. A solution S is a local maximum if no single element
ai in S can be exchanged for another element aj not in S
whose marginal contribution to S−i is greater. That is, S is
a local maximum if for every ai ∈ S we have that:
fS−i (ai ) ≥ max fS−i (x).
x∈S
/

It is not hard to show that for any monotone submodular function, if S is a local maximum it is a 1/2 approximation to the optimal solution. A local search algorithm begins with an arbitrarily set of size k, and at every stage exchanges one of its elements with the element
whose marginal contribution is maximal to the set, until it reaches a local maximum. To guarantee that local

If we have uncertaintiy modeled by a distribution D ⊆
[0, 1], a solution is a stochastic local maximum w.r.t D if
for every element ai in S we draw ξi ∼ D s.t.
fS−i (ai ) ≥ ξi · max fS−i (b)
b∈S
/

A stochastic local search algorithm will therefore begin
from an arbitrary solution S of size k, and at every iteration swap an element from the solution with an element
outside the solution if S is not a stochastic local maximum
w.r.t. D. More specifically, the stochastic local search algorithm selects an element ai from S and replaces it with
another element aj whose expected marginal contribution
to S−i is at least fS−i (ai )/ξi , and repeats this process until
no such elements are found. This is a similar abstraction of
stochastic greedy algorithms, applicable in settings when
one cannot evaluate the optimal marginal contribution exactly, but approximately well in expectation.
Consistent and inconsistent stochasticity. We consider
two approaches to model the way in which the random variables ξi are assigned to an element ai in the solution:
1. Consistent: For each element ai ∈ N , ξi is a random
variable drawn independently from D ⊆ [0, 1], and
fixed for the entire run of the algorithm;
2. Inconsistent: At each step of the algorithm, for every element ai ∈ S, ξi is a random variable drawn
independently from D.
Note that the solution converges, as the distribution D
makes the algorithm more conservative.

Robust Guarantees of Stochastic Greedy Algorithms

●

●

●

●

●

●

●

●

● ●
● ●
● ●
● ●
● ●
● ●

●

●

●

GREEDY
uniform
exponential
normal
RANDOM
●

●

●

●

●

●

● ●
● ●
● ●
● ●
● ●
● ●

● ● ● ● ●
● ● ● ● ● ● ●

LS
uniform
exponential
normal
RANDOM

●

●

●

●

●

●

GREEDY
APX−GREEDY w. apx 0.5
STOCHASTIC−GREEDY w. mean 0.75
STOCHASTIC−GREEDY w. mean 0.5
RANDOM

●

●

● ●

●

●
●

11

13

15

17

budget k

19

21

23

25

27

29

●

●

●

●

● ●

●

●

●

●

9

●

● ●

●

●

0
7

● ● ● ● ● ● ● ●

●

●

0

● ●

●

function value

●
●

●

●

●

●
●
●
●
● ● ●

●

●

function value

function value

●

5

●

●

●
●

●

3

●

200

● ● ●

●

●

1

●

● ●

200

●

200

●

function value

●

●

●

●
●
●

200

●

LS
APX−LS w. apx 0.5
STOCHASTIC−LS w. mean 0.75
STOCHASTIC−LS w. mean 0.5
RANDOM

0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

budget k

0
1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

budget k

1

3

5

7

9

11

13

15

17

19

21

23

25

27

29

budget k

Figure 1: Function value as a function of solution size for greedy and local search with uncertainty
Inapproximability of stochastic local search. We show
that in both consistent and inconsistent models, stochastic
local search performs poorly, even for modular functions.
Consider a setting where there are n elements, and a modular function. For every i > 1, we have f (ai ) = ε/i for
some negligible ε > 0 (e.g. ε = 2−n ), but f (a1 ) = 1. As
for D, w.p. 0.99 it returns 1, and 0 o.w. Assume k = 1.
Lemma 8. The expected approximation guarantee of
stochastic local search is at most 2−O(n) + ε.
Proof. At the first iteration, local search chooses an . If
ξ = 0, we are done, and this is a local maxima. Otherwise,
local search chooses an−1 . At iteration i local search starts
with ai , halts w.p. 0.01 (the probability that D outputs 0),
and otherwise continues. The probability that it will not
halt for n steps and reach ai is 0.99n = 2−O(n) .
We note that in the above proof we assumed that the local
search algorithm chooses an arbitrary element at every iteration. If one allows the stochastic local search to randomly
choose an element in every iteration a similar construction
shows an inapproximability of O( logn n ) + ε.

6. Experiments

and then pick a random element out of the elements that
have marginal contribution at least ξ maxa fS (a). The distribution D varies between the different lines. In the leftmost pane, APX (red line) depicts a D which is the constant distribution 0.5. In Stochastic greedy with mean 0.75,
D is the uniform distribution on [0.5, 1] (purple line), and
in Stochastic greedy with mean 0.5, D is the uniform distribution on [0, 1]. It is expected that APX will behave
smoothly, as D is a degenerate distribution in this case
(note that there is still randomization in which element to
choose at every stage out of the eligible elements). However, we see that the h.p. result kicks in, and the APX line
is similar (across many values of k) to stochastic greedy
with mean 0.5. Raising the mean to 0.75 makes stochastic greedy behave almost like greedy when k gets large,
so in some cases stochastic greedy makes the same choice
greedy would make.
In the second pane, The purple line (exponential) depicts
D as an exponential distribution with λ = 4, which gives
a mean of 0.25. The red line is uniform in [0, 5], and the
yellow is a Gaussian with µ = 0.25 and σ = 0.1. We see
that all graphs are further away from Greedy compared to
the leftmost pane, and that higher variance is generally not
a good thing, although the differences are small.

We applied the algorithms to an ego-network
from (Leskovec & Krevl, 2014). This network has
333 nodes and 5038 edges. The submodular function
we used is coverage, which models influence in social
networks. In order to emphasize the implications of having
results w.h.p, the graphs do not depict the average of many
runs, but instead each graph is a single run of the algorithm.
In greedy, we present the value of the solution at each
iteration k. In local search and in random we sort elements
of the solution according to marginal contributions.

The two right panes depict the same noise distributions as
the two left panes, but this time we use local search (or
stochastic local search) instead of greedy. It is easy to see
that D affects local search more than it affects greedy. The
plateau is caused since we sort the final solution and then
plot the elements, and since if some elements have a low
value of ξi they are likely to stay in the solution even if
they contribute very little, as in Lemma 8.

We start with greedy and describe the different distributions we used to model uncertainty. The same distributions
were used for local search. Both left panes include the
greedy algorithm without uncertainty (greedy, blue line),
and choosing a random set (random, black line). When
running stochastic greedy, we first sample a value ξ ∈ D,

A.H. was supported by ISF 1394/16; Y.S. was supported
by NSF grant CCF-1301976, CAREER CCF-1452961, a
Google Faculty Research Award, and a Facebook Faculty
Gift. We thank Andreas Krause for pointing the connection
between our result and (Mirzasoleiman et al., 2015).

7. Acknowledgements

Robust Guarantees of Stochastic Greedy Algorithms

References
Azaria, Amos, Hassidim, Avinatan, Kraus, Sarit, Eshkol,
Adi, Weintraub, Ofer, and Netanely, Irit. Movie recommender system for profit maximization. In Proceedings
of the 7th ACM conference on Recommender systems,
pp. 121–128. ACM, 2013.
Feige, Uriel. A threshold of ln n for approximating set
cover. Journal of the ACM, 45(4).
Filmus, Yuval and Ward, Justin. A tight combinatorial algorithm for submodular maximization subject to a matroid constraint. In FOCS, 2012.
Hassidim, Avinatan and Singer, Yaron. Submodular optimization under noise. In COLT, 2017.
Leskovec, Jure and Krevl, Andrej. SNAP Datasets: Stanford large network dataset collection. http://snap.
stanford.edu/data, June 2014.
Li, Chengtao, Sra, Suvrit, and Jegelka, Stefanie. Gaussian
quadrature for matrix inverse forms with applications. In
ICML, 2016.
Lindgren, Erik, Wu, Shanshan, and Dimakis, Alexandros G. Leveraging sparsity for efficient submodular
data summarization. In NIPS, 2016.
Lucic, Mario, Bachem, Olivier, Zadimoghaddam, Morteza,
and Krause, Andreas. Horizontally scalable submodular
maximization. In ICML, 2016.
Malioutov, Dmitry, Kumar, Abhishek, and Yen, Ian EnHsu. Large-scale submodular greedy exemplar selection
with structured similarity matrices. In UAI, 2016.
Mirzasoleiman, Baharan, Badanidiyuru, Ashwinkumar,
Karbasi, Amin, Vondrák, Jan, and Krause, Andreas.
Lazier than lazy greedy. In AAAI, 2015.
Nemhauser, George L and Wolsey, Leonard A. Best algorithms for approximating the maximum of a submodular
set function. Mathematics of operations research, 3(3):
177–188, 1978.
Nemhauser, George L, Wolsey, Laurence A, and Fisher,
Marshall L. An analysis of approximations for maximizing submodular set functions—i. Mathematical Programming, 14(1):265–294, 1978.
Sharma, Dravyansh, Kapoor, Ashish, and Deshpande,
Amit. On greedy maximization of entropy. In ICML,
2015.
Singla, Adish, Tschiatschek, Sebastian, and Krause, Andreas. Noisy submodular maximization via adaptive
sampling with applications to crowdsourced image collection summarization. In AAAI, 2016.

Vondrák, Jan. Optimal approximation for the submodular
welfare problem in the value oracle model. In STOC,
2008.
Zhuang, Hao, Rahman, Rameez, Hu, Xia, Guo, Tian, Hui,
Pan, and Aberer, Karl. Data summarization with social
contexts. In CIKM, 2016.

