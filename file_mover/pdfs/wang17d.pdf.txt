Robust Gaussian Graphical Model Estimation with Arbitrary Corruption
Lingxiao Wang 1 Quanquan Gu 1

Abstract
We study the problem of estimating the highdimensional Gaussian graphical model where the
data are arbitrarily corrupted. We propose a robust estimator for the sparse precision matrix in
the high- dimensional regime. At the core of our
method is a robust covariance matrix estimator,
which is based on truncated inner product. We
establish the statistical guarantee of our estimator on both estimation error and model selection
consistency. In particular, we show that provided
that the number of corrupted
n2 for each
p
p samples
variable satisfies n2 . n/ log d, where n is
the sample size and d is the number of variables,
the proposed robust precision matrix estimator
attains the same statistical rate as the standard estimator for Gaussian graphical models. In addition, we propose a hypothesis testing procedure
to assess the uncertainty of our robust estimator.
We demonstrate the effectiveness of our method
through extensive experiments on both synthetic
data and real-world genomic data.

1 Introduction
Gaussian graphical models (GGMs) have attracted increasing attention in recent years, especially in the field
of high-dimensional statistical learning. In Gaussian
graphical models, a d-dimensional random vector X =
(X1 , . . . , Xd )> follows a multivariate normal distribution
Nd (0, ⌃⇤ ). It corresponds to the vertex set V = {1, . . . , d}
of an undirected graph G = (V, E), where the edge set
E describes the conditional independence relationships between nodes X1 , . . . , Xd . It is well-known that the graph
G is encoded by the sparsity pattern of the precision matrix
⇥⇤ = ⌃⇤ 1 . More specifically, no edge connects Xi and
Xj if and only if ⇥⇤ij = 0. Consequently, estimation of
1

Department of Computer Science, University of Virginia,
Charlottesville, Virginia, USA. Correspondence to: Quanquan Gu
<qg5w@virginia.edu>.
Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

the precision matrix ⇥⇤ corresponds to parameter estimation, and specifying the non-zero set of ⇥⇤ corresponds to
graphical model selection (Cox & Wermuth, 1996).
In the high-dimensional settings, where the number of
variables d can exceed the number of observations n, a
large body of literature has studied the problem of precision matrix estimation in Gaussian graphical models and
their variants (Meinshausen & Bühlmann, 2006; Yuan &
Lin, 2007; Friedman et al., 2008; Banerjee et al., 2008;
Yuan, 2010; Cai et al., 2011; Wang et al., 2016; Xu &
Gu, 2016; Xu et al., 2016; 2017). For instance, Meinshausen & Bühlmann (2006) developed a neighborhood
pursuit approach for estimating conditional independence
relationship separately for each node in the graph. This
method estimates the precision matrix by solving a collection of sparse regression problems using Lasso in parallel. Yuan & Lin (2007); Friedman et al. (2008); Banerjee
et al. (2008) proposed a `1 norm regularized Gaussian negative log-likelihood method, which called Graphical Lasso
(GLasso), to directly estimate the precision matrix. More
recently, Yuan (2010); Cai et al. (2011) proposed the graphical Dantzig selector and CLIME, respectively. Both of
these methods can be solved by linear programming and
have more favorable theoretical properties than GLasso.
Note that most of the aforementioned methods rely on the
assumption that the observations follow a Gaussian distribution. There also exists some work, such as Ravikumar
et al. (2011), studied sub-Gaussian data under bounded
higher order moments. However, in many real-word applications, the data can follow a heavy-tailed distribution,
or may even be corrupted arbitrarily. In such cases, conventional methods yield inaccurate graph estimation even
if there are only a few contaminated observations due to
the lack of robustness. In order to address this issue, a large
body of literature (Liu et al., 2012; Finegold & Drton, 2011;
Hirose & Fujisawa, 2015; Sun & Li, 2012; Yang & Lozano,
2015; Balmand & Dalalyan, 2015; Öllerer & Croux, 2015;
Loh & Tan, 2015; Chen et al., 2015; Tarr et al., 2016) has
focused on providing more robust estimators for precision
matrices in the past years. However, most of these estimators were established under some specific contamination
models, thus they are not good at dealing with the situation
when data are arbitrarily corrupted.

Robust Gaussian Graphical Model Estimation with Arbitrary Corruption

In this paper, we propose a robust estimator to estimate
the precision matrix in high-dimensional GGMs with arbitrarily corrupted data. More specifically, we consider the
situation that the corrupted data can appear in any coordinates of the observations. This includes situations that
some observations are outliers or data follow some specific
contamination models as special cases. The definition of
the arbitrary corruption model will be presented in section
3. The key idea of our method is to use a robust covariance
matrix estimator, which remains accurate provided a controlled number of arbitrarily corrupted coordinates. Our
theory provides not only the spectral norm based estimation error of the proposed estimator, but also the model selection consistency guarantee. More importantly, we show
that provided that the number p
of corrupted
samples n2 for
p
each variable satisfies n2 . n/ log d, where n is the
sample size and d is the number of variables, the proposed
robust precision matrix estimator attains the same statistical rate as the standard estimator for Gaussian graphical
models. Beyond point estimation, we also propose a hypothesis testing procedure to assess the uncertainty of our
robust estimator with corrupted observations, and construct
the confidence interval for the point estimate. Thorough experiments on both synthetic data and real-world genomic
data corroborate the effectiveness of our method.
The remainder of this paper is organized as follows: In
Section 2, we discuss some more related work about the robust precision matrix estimation. Section 3 summarizes our
proposed estimation method and testing procedure in general and also introduces some necessary backgrounds. Section 4 presents our main results including estimation error
bound and inference property. Section 5 provides numerical results, for our method and a number of other methods,
of some simulated datasets and a real example on gene expression data. Section 6 concludes with discussion.
Notation Let A = [Aij ] 2 Rd⇥d be a d ⇥ d matrix
and x = [x1 , . . . , xd ]> 2 Rd be a d-dimensional vector. For 0 < q < 1, we define the `0 , `q and `1
Pd
vector norms as kxk0 =
i=1 1{xi 6= 0}, kxkq =
Pd
1
( i=1 |xi |q ) q , kxk1 = max1id |xi |, where 1{·} represents the indicator function. We use the following notations for the matrix `q , `max , `1,1 and `F norms: kAkq =
maxkxkq =1 kAxkq , kAk1,1 = maxij |Aij |, kAk1,1 =
Pd Pd
P
2 1/2
. We use
i=1
j=1 |Aij |, kAkF = (
ij |Aij | )
>
A⇤j = (A1j , . . . , Adj ) to denote the j-th column vector
of A and A⇤\j to denote the submatrix of A with the jth column A⇤j removed. We also denote by max (A) and
min (A) the largest and smallest eigenvalues of matrix A,
respectively. Furthermore, for a matrix ⇥ and sets of tuples
S, S1 , ⇥S1 ,S denotes the set of numbers (⇥jk )j2S1 ,k2S .
We define the maximum degree of a graph or row cardinality as s = max1in |{j 2 V | ⇥⇤ij 6= 0}|, where

V = {1, . . . , d} is the vertex set. Finally, for a sequence
d

of random variables Xn , we write Xn ! X, for some random variable X, if Xn converges in distribution to X.

2

Related Work

In recent years, some attempts have been made toward the
robust estimation of high-dimensional GGMs under different corruption models. For example, to deal with heavy
tailed distributions, Liu et al. (2012) developed a semiparametric approach called the nonparanormal SKEPTIC.
Finegold & Drton (2011) proposed a penalized likelihood
approach based on multivariate t-distributions. They also
proposed an alternative t-model which requires the use of
variational EM or Markov chain Monte Carlo algorithms.
Hirose & Fujisawa (2015) introduced a robust estimation
procedure for sparse precision matrices based on the penalized negative -likelihood function.
In order to address outliers, Sun & Li (2012) proposed
a robust estimation of GGMs via a robustified likelihood
function with `1 penalization. In particular, they first use
coordinate descent to efficiently estimate the structure of
the precision matrix. Then, based on the estimated structure, they re-estimate the parameters of the precision matrix using iterative proportional fitting algorithm to ensure the positive definiteness of their estimator. Yet their
method does not have any theoretical guarantee. Yang
& Lozano (2015) proposed a trimmed Graphical Lasso
method. Specifically, by adding weights to different data
points, they improved upon the original graphical Lasso
such that it is more robust to outliers. However, they did not
provide any model selection consistency guarantee. Balmand & Dalalyan (2015) also studied the problem of robustly estimating the covariance matrix when data are corrupted by outliers. In particular, they proposed to use a
modified scaled lasso procedure for covariance matrix estimation and provided the theoretical guarantee of their
method.
Another line of related work is Öllerer & Croux (2015);
Loh & Tan (2015); Chen et al. (2015); Tarr et al. (2016),
which studied the problem of robust precision matrix estimation in high dimensions under the ✏-contamination
model. In particular, under the cell-wise contamination
model, Tarr et al. (2016) evaluated the performance of the
Glasso and CLIME estimators together with a U-statistic
based robust covariance estimator for sparse precision matrix estimation. Under the same contamination model,
Öllerer & Croux (2015) provided an analysis for the robustness of these estimators in terms of breakdown behavior. Later on, from the point of statistical consistency,
Loh & Tan (2015) established the statistical error bounds
for these estimators. However, these methods (Öllerer &
Croux, 2015; Loh & Tan, 2015; Tarr et al., 2016) highly

Robust Gaussian Graphical Model Estimation with Arbitrary Corruption

depend on the specific cell-wise contamination structure
on the data matrix. Recently, inspired by Tukey’s depth
estimator (Tukey, 1975) for vector estimation, Chen et al.
(2015) introduced the concept of matrix depth and proposed a robust covariance matrix estimator using empirical depth function. They showed that their proposed estimator can achieve minimax optimal statistical rate under
Huber’s ✏-contamination model. However, it is computationally very expensive to compute the deepest depth of a
matrix even in a moderate dimension, which makes such
method infeasible in the high-dimensional regime.
All the aforementioned methods are limited to data with
heavy tails and outliers. Therefore, they are not suitable to
deal with data that are arbitrarily corrupted.

3 Problem Setup and Estimation Method
In this section, we first introduce the setup of our problem,
then we present our proposed estimation method and hypothesis testing procedure.
3.1 Problem Setup
Let X = (X1 , . . . , Xd )> be a d-dimensional multivariate Gaussian random vector with zero mean and covariance matrix ⌃⇤ . It is associated with an undirected graph
G = (V, E) with vertex set V = (1, . . . , d) corresponding to random variables and edge set E = {(j, k) | j 6=
k, ⇥⇤jk 6= 0} describing the connections of nodes, where
⇥⇤ = ⌃⇤ 1 is the precision matrix.
Suppose we have n i.i.d. observations X1 , . . . , Xn , each
of which is drawn from the multivariate Gaussian distribution Nd (0, ⌃⇤ ). Let X = [X1 , . . . , Xn ]> 2 Rn⇥d be the
data matrix and there may exist arbitrary corruption of the
data matrix X. More specifically, for each variable/column
of data matrix X, we allow at most n2 coordinates to be
arbitrarily corrupted, and we call this kind of corruption
model as the arbitrary corruption model. Note that under
the arbitrary corruption model, we do not require the corrupted entries lie in the same n2 rows. Clearly, a special
case of the arbitrary corruption model is the outlier model
where the corruption appears in n2 observations. Under
the arbitrary corruption model, n2 is the upper bound on
the number of corruptions for each variable, and under the
outlier model, n2 is the upper bound on the number of outliers. Specifically, under the outlier model, the set of row
indices {1, . . . , n} of the data matrix X is divided into two
disjoint subsets A and O with |A| = n1 , |O| = n2 , and
n = n1 + n2 . XA denotes samples drawn from the authentic distribution. XO denotes samples that are outliers.
In general, there is no constraint on the type of corruptions
in our setting except an upper bound on the number of corruptions, i.e., n2 . For example, these corruptions could be
drawn from other distributions or even be deterministic.

3.2 Estimation Method
Before we introduce our estimation method, we first introduce the truncated inner product which was proposed
by Chen et al. (2013). The truncated inner product hu, vin2
is defined as follows: given two n-dimensional vectors
u, v 2 Rn , and the truncation number n2 satisfying
n2  n, we first compute the quantity qi = ui vi , for
i = 1, . . . , n. Then we sort {|qi |}ni=1 and select the smallest (n n2 ) ones. Let ⌦ be the set of selected indices with
cardinality |⌦| = n nP
2 , then we have the truncated inner
product as hu, vin2 = i2⌦ qi .
The main idea of our estimation method is to use a robust
covariance matrix estimator which can mitigate the impact
of arbitrary corruptions. More specifically, given a data matrix X 2 Rn⇥d , which is arbitrarily corrupted, we obtain
b through a trunthe robust covariance matrix estimator ⌃
b
cation procedure that each element ⌃jk is calculated via
truncated inner product hX⇤j , X⇤k in2 /n1 . The motivation
of this truncation procedure is that the corrupted coordinates with large magnitude may heavily affect the precision
of our estimation results, and this simple truncation procedure can reduce such impact. Next, we introduce our robust
estimator, which is based on the robust covariance matrix
estimator and CLIME:
b = argmin k⇥k1,1 subject to k⌃⇥
b
⇥
Ik1,1  ,
⇥2Rd⇥d

(3.1)

b is the robust covariance matrix estimator obtained
where ⌃
through truncation, > 0 is a constraint parameter. We
refer to (3.1) as Robust CLIME (RCLIME). Note that here
we do not consider the Glasso type estimator since it requires the stringent incoherence condition on the covariance matrix to guarantee the model selection consistency.
Let ✓i⇤ = ⇥⇤⇤i denote the i-th column of ⇥⇤ . To estimate the precision matrix more efficiently, instead of solving (3.1), we can estimate each column of ⇥⇤ as follows:
✓b = argmin k✓k1
✓2Rd

b
subject to k⌃✓

ei k1  ,
(3.2)

for i = 1, . . . , d, and ei 2 Rd denotes a column vector that
the i-th element is 1 and others are 0. Note that the comb 1 = [✓b1 , . . . , ✓b1 ] of (3.2) is equivalent to
bined solution ⇥
1
d
the solution of (3.1) (Cai et al., 2011). In addition, since
b 1 is not symmetric, we need the following symmetriza⇥
tion procedure to get our robust estimator
b = arginf k⇥ ⇥
b 1 k1 ,
⇥
(3.3)
d
⇥2S++

d
where S++
= {A 2 Rd⇥d | A = A> , A
0} denotes
all d ⇥ d symmetric positive definite matrices. The symmetrization procedure in (3.3) can be solved by the projected gradient descent method, and in practice, we can use

Robust Gaussian Graphical Model Estimation with Arbitrary Corruption

many simple symmetrization methods, such as the method
provided in Cai et al. (2011).
3.3 Hypothesis Test
Based on the proposed robust estimator (3.1), we are interested in testing whether there is an edge between node j
and node k in GGMs (Jankova et al., 2015; Neykov et al.,
2015; Gu et al., 2015; Xu et al., 2016). More specifically,
we want to develop a procedure for the hypothesis test that
H0 : ⇥⇤jk = 0 versus H1 : ⇥⇤jk 6= 0. Let us assume that
the k-th column of the precision matrix ⇥⇤ to be the vector
✓k⇤ = (↵⇤ , ⇤> )> where ↵⇤ is the j-th element of the vector ✓k⇤ and ⇤ 2 Rd 1 is the remaining (d 1)-dimensional
vector. Thus it is equivalent to test the one dimensional
component H0 : ↵⇤ = 0 versus the non-restricted alternative H1 : ↵⇤ 6= 0. In this case, ⇤ are nuisance parameters. To this end, we first introduce the following estimation
b
equation projected (EEP) along the direction w:
b
b
b > ⌃✓
S(✓)
=w

ek ,

(3.4)

b is the the robust covariance matrix estimator and
where ⌃
b is the solution of the optimization problem (3.2) with
w
i = j. The motivation of projecting the estimation equation to a sparse direction (3.4) is to help us construct a
test statistic which has a tractable limiting distribution in
the high-dimensional regime. In high-dimensional settings,
b is not positive definite, we cannot solve the equation
⌃
b ✓b ek = 0 by taking the inverse of ⌃
b directly. There⌃
fore, given the sparsity assumption on ✓ ⇤ , the estimator
in (3.2) can address such ill-posed problem for solving the
b ✓b ek = 0 in high-dimensional setestimation equation ⌃
tings. Furthermore, projecting the estimation equation to
a certain direction (3.4) makes the limiting distribution of
✓b = (b
↵, b > )> in (3.2) tractable. More specifically, if we
b as the projection direction, then due to the
choose the w
b is a consistent estimator of w⇤ := ⇥⇤⇤j , the
fact that w
estimator b of the high-dimensional nuisance parameters
in (3.2) is asymptotically ignorable along this direction.
Therefore, we can solve the projected estimation equation
b
b ) = 0 to get an debiased estimator of ↵⇤ as follows:
S(↵,
↵
e=↵
b

b ✓b ek )
b > (⌃
w
,
b ⇤j
b >⌃
w

(3.5)

b is
where ✓b = (b
↵, b > )> is the estimator of ⇥⇤⇤k , and w
the estimator of ⇥⇤⇤j . Thus we define the following test
statistic built upon the debiased estimator ↵
e
p
⇤
b
Tn = n1 (e
↵ ↵ )/b,
(3.6)

where n is the number of observations, n2 is the upper
bound on the number of corruptions, n1 = n n2 , and
b2 = w
bj ✓bk + w
bk ✓bj , where w
bj , ✓bj denote the j-th eleb and ✓b respectively. Note that b2 is a consisments of w
tent estimator to 2 = wj⇤ ✓k⇤ + wk⇤ ✓j⇤ under the Gaussian

assumption of the data, where wj⇤ , ✓k⇤ are the j-th and kth columns of w⇤ and ✓ ⇤ respectively. We will show in
the next section that the proposed debiased estimator ↵
e is
consistent to ↵⇤ , and the test statistic Tbn is asymptotically
p
d
normal n1 (e
↵ ↵⇤ )/b ! N (0, 1) under the null hypothesis. Therefore, our asymptotic level-↵ test is given by
(
0 (⌘ accept H0 ) if |Tbn |  C↵ ,
(3.7)
n =
1 (⌘ reject H0 ) if |Tbn | > C↵ ,
1
where C↵ =
(1 ↵/2) is the (1 ↵/2)-quantile of the
standard normal distribution N (0, 1). Furthermore, we can
construct asymptoticplevel-↵ confidence intervals of ↵⇤ as
↵
e ± 1 (1 ↵/2)b/ n. Note that in practice, although we
have no idea about the exact upper bound on the number of
corruptions, i.e., n2 , we can use techniques such as crossvalidation to choose the best truncation number n2 .

4

Main Results

In this section, we present our main results and discuss connections with some related works. We start by stating some
assumptions, which are required in our analysis. We impose an important eigenvalue condition on the population
covariance matrix.
Assumption 4.1. There exist a constant  > 0 such that
0 < 1/ 

min (⌃

⇤

)

max (⌃

⇤

)   < 1.

This assumption can exclude singular or nearly singular covariance matrices, thus guarantee the uniqueness of ⇥⇤ .
In this paper, we consider the precision matrix ⇥⇤ that
belongs to a class of matrices U (s), i.e., U (s) = ⌦ 2
Pd
Rd⇥d ⌦
0, k⌦k1  M, max1id j=1 1{⌦ij 6=
0}  s , where ⌦
0 means ⌦ is positive definite
and s corresponds to the row cardinality. Note that this
sparse precision matrix class has been previously considered in Cai et al. (2011); Liu & Wang (2012); Zhao & Liu
(2013). In addition, it immediately implies that k⇥⇤⇤j k1 
k⇥⇤ k1  M , where ⇥⇤⇤j is the jth column vector of ⇥⇤ .

Now, we are ready to provide our main results. The first
one characterizes the performance of our robust estimator
under the arbitrary corruption model. It shows that even
if thep
upper bound on the number of corruptions n2 scales
with n, where n is the number of observations, our robust estimator can still recover the correct support. Note
that our results are derived under the arbitrary corruption
model. Since the outlier model is a special case of the arbitrary corruption model, our results can directly apply to the
outlier case.
Theorem 4.2. Under the arbitrary corruption model, suppose ⇥⇤ 2 U(s) and Assumption 4.1 is satisfied. In addition, assume the upper p
bound on the number of corruptions n2 satisfies n2  a n for some constant a
0. If

Robust Gaussian Graphical Model Estimation with Arbitrary Corruption

n 4a2 , and we choose
p the regularization parameter satisfying = CM 2
log d/n + n2 log d/n , then, with
b in (3.1) satprobability at least 1 C1 /d, the estimator ⇥
isfies
✓ r
◆
log d n2 s log d
⇤
2 2
b
k⇥ ⇥ k2  C2 M  s
+
. (4.1)
n
n

then the Robust CLIME can correctly identify the nonzero
entries of ⇥⇤ .

then the Robust CLIME can correctly identify nonzero entries of ⇥⇤ .

Next, we present the asymptotic results of our proposed test
statistics in (3.6), which verifies the effectiveness of our
testing procedure. Note that we consider the case that the
true observations are drawn from a Gaussian distribution.

Furthermore, if the nonzero entries of ⇥⇤ satisfy
✓r
◆
log d n2 log d
⇤
2 2
min
|⇥
|
C
M

+
,
3
ij
i6=j,⇥⇤
n
n
ij 6=0

Remark 4.3. According to (4.1), the estimation error of
our p
robust estimator consists of two terms. The first one
O(s log d/n) corresponds to the estimation error without
corruptions. The second extra term O(sn2 log d/n), which
is linear in n2 , is due to the effect of arbitrary corruption.
More specifically, if there is no corruption in our data, then
the second term becomes zero since n2 = 0. Therefore,
the
p
estimation error of our method reduces to O(s log d/n),
which matches the minimax optimal rate for sparse precision matrix estimation without corruptions in terms of
spectral norm (Yuan, 2010; Cai et al., 2011; Ravikumar
et al., 2011). In addition, (4.1) in Theorem 4.2 indicates
that our robust estimator can correctly recover the support
of ⇥⇤ even if the upper
p bound on the number of corruptions n2 scales with n/ log d, where n is the number of
observations. In addition, under the outlier model, this estimation result is comparable to the result provided by Yang
& Lozano (2015). In their study, they proved that the proposed estimator can successfully recover the true parameter
provided
that the upper bound of the number of outliers is
p
O( n). However, Yang & Lozano (2015) does not consider the case when the data is arbitrarily corrupted.
Furthermore, if the upperpbound
p on the number of corruptions n2 satisfies n2 . n/ log d, our robust estimator
can achieve the same statistical rate as the standard estimator for Gaussian graphical models. This is summarized in
the following corollary.
Corollary 4.4. Under the same conditions of Theorem 4.2,
if we further assume that the upper
p on the number
p bound
of corruptions n2 satisfies n2 . n/ log d, then for the
b in (3.1), we have, with probability at
robust estimator ⇥
least 1 C/d, that
r
⇤
2
2
b ⇥ k2  C1 M  s log d .
k⇥
n
Furthermore, if the nonzero entries of ⇥⇤ satisfy
p
min
|⇥⇤ij | C2 M 2 2 log d/n,
⇤
i6=j,⇥ij 6=0

Remark 4.5. Compared with Theorem 4.2, Corollary
4.4 implies that under a slightly stricter condition on
thepupper
p bound of the number of corruptions n2 =
O( n/ log d), our robust estimator can successfully recover the p
true parameter ⇥⇤ with guaranteed estimation
error O(s log d/n). Note that this error bound exactly
recover the spectral norm error bound for the case without
corruptions (Yuan, 2010; Cai et al., 2011; Ravikumar et al.,
2011), which demonstrates the superiority of our estimator.

Theorem 4.6.
p Suppose Assumption 4.1 is satisfied and
p
n1 sM 2 4 ( log d/n1 + n2 log d/n1 )2 = o(1), where
n1 = n n2 . If wepchoose regularization parameter satisfying = CM 2 ( log d/n1 + n2 log d/n1 ), then the test
statistic in (3.6) is asymptotically normal
p

n1 (e
↵
b

↵⇤ )

d

! N (0, 1),

where b2 = w
bj ✓bk + w
bk ✓bj , and ↵
e is defined in (3.5).

Remark 4.7. Theorem 4.6 provides us an efficient test
for the existence of an edge in GGMs, and gives us
an efficient interval estimation of ↵⇤ = ⇥⇤ij . In addition, Theorem 4.6 implies that if the upperpbound
p on
the number of corruptions n2 satisfies n2 . n/ log d
and the quantity
p M is a constant, then the assumption
p
4
n1 sM 2 p
( log d/n1 + n2 log d/n1 )2 = o(1) reduces
to s log d/ n = o(1),pwhich gives us the sparsity assumption that s = O( n log d). This requirement on
sparsity matches the best-known results for edge testing
in GGMs (Liu et al., 2013; Ren et al., 2015). More importantly,
p p Theorem 4.6 suggests that even when n2 =
O( n/ log d) out of n observations of each variable are
arbitrarily corrupted, our testing procedure is still efficient.

5

Experiments

In this section, we compare our robust estimator with
some existing methods, including trimmed Graphical
Lasso (tGLasso) (Yang & Lozano, 2015), t⇤ -Lasso
(tLasso) (Finegold & Drton, 2011), robust `1 penalized
likelihood (RLL) (Sun & Li, 2012), nonparanormal SKEPTIC (Liu et al., 2012), and pairwise based covariance estimator (spearC) (Loh & Tan, 2015) on some synthetic
datasets. Our comparisons focus on their performance in
both graph recovery and parameter estimation. The implementation of tLasso and RLL is based on the code provided
by authors. The implementation of other baseline algo-

Robust Gaussian Graphical Model Estimation with Arbitrary Corruption

rithms is based on R package huge1 . We conduct some
simulations to investigate the performance of our proposed
hypothesis testing procedure. Furthermore, we compare
our method with GLasso on a gene expression data.
5.1 Synthetic Data
In our numerical simulations, we consider the following
two settings: (i) n = 100, d = 100; and (ii) n = 200,
d = 400. We generate the true precision matrices based on
two graph structures: cluster and band. More specifically,
the precision matrices ⇥⇤ are generated by huge package,
and the magnitude of correlations is the default value (0.3)
in the huge generator. In order to incorporate corruptions,
we generate our observations by the following procedure.
For the arbitrary corruption model, we first generate the
n by d data matrix X from the Gaussian distribution
Nd (0, ⇥⇤ 1 ). Then, for each column of the data matrix,
we let np coordinates be arbitrarily corrupted, where we
consider the corruption rate p = 0.1 for small number of
corruptions and p = 0.2 for large number of corruptions. In
addition, each corrupted coordinate is generated by normal
distributions N (µ, ) as follows:
M1A : µ = 1,

= 1,

M2A : µ = 2,

(5.1)

= 1.

For the outlier model, we use the setup similar to Sun & Li
(2012); Yang & Lozano (2015). Specifically, we generate
each observation from the mixture model as follows:
Xi ⇠ (1

p)Nd (0, ⇥⇤

p
+ Nd ( µ, ⇥0
2

1

1

)

p
) + Nd (µ, ⇥0
2
for

1

)

i = 1, . . . , n,

where we consider the corruption rate p = 0.1 for small
number of corruptions and p = 0.2 for large number of
corruptions. Furthermore, each outlier is generated by nor1
mal distributions Nd (µ, ⇥0 ) as follows
M1O
M2O

>

0

(5.2)

>

0

(5.3)

: µ = (1, . . . , 1) , ⇥ = Id ,
: µ = (2, . . . , 2) , ⇥ = Id .

Note that under both corruption models, we set the corruption rate p 2 {0.1, 0.2}. In other words, we choose
the number of corruptions to be 10% and 20% of all observations. This is due
p to the threshold of the number of
corruptions n2 = O( n) suggested in our theorem.
Point Estimation: We choose tuning parameters of each
method as follow. For tGLasso, we choose n2 /n from
[0.5, 1], which is suggested by Yang & Lozano (2015). For
RLL, we choose
2 {0.005, 0.01, 0.02}, which is suggested by Sun & Li (2012). And for Robust CLIME, we
choose n2 around 15 (±5). Since the performance of t⇤ 1

http://cran.r-project.org/web/packages/huge

Lasso is similar to t-Lasso, we just show the results of t⇤ Lasso. All results we reported are their best performance
based on these parameters.
First, we use receiver operating characteristic (ROC)
curves to compare the overall performance of our method
with others in model selection over the full paths. For
the arbitrary corruption model, the ROC curves on cluster
graphs averaged over 50 simulations are shown in Figure 1.
We can observe that under the arbitrary corruption model,
as the number of corruptions increase, the advantage of our
approach becomes more significant. For the outlier model,
we also observe similar good performance of our method,
especially for outliers with large magnitude. Due to space
limit, the ROC curves for the outlier model can be found
in the longer version of this paper. These results indicate
that our method is very competitive in the graph recovery
problem with arbitrary corruptions.
Then, we evaluate the performance of our method and
some existing approaches in parameter estimation. For
model settings mentioned above, we choose the corruption
rate p = 0.1 for the purpose of comparisons. We generate a dataset as the training sample, and an independent
dataset from the same distribution as the test set. We set
n2 /n = 0.9 for tGLasso, = 0.01 for RLL, and n2 = np
for Robust CLIME. We also choose the tuning parameter
by grid search based on its performance on the training
sample and evaluate those estimators on the test set. Here
b ⇥⇤ k2 and Frobenius norm
we use Spectral norm error k⇥
⇤
b
error k⇥ ⇥ kF to compare the performance of different
methods in parameter estimation. Tables 1 and 2 summarize estimation error results in term of Spectral norm averaged over 50 simulations. These results demonstrate the
advantage of our method in parameter estimation. Other
comparison results in terms of Frobenius norm error are
deferred to the longer version of this paper.
Hypothesis Test: We investigate the finite sample performance of our proposed hypothesis testing procedure
through some simulation studies. We use the data generating process similar to Jankova et al. (2015); Neykov et al.
(2015), and we consider the case that there are some corruptions in our data. More specifically, for the aforementioned two settings, we consider the band graph structure
with band width 1 with the corresponding precision matrix ⇥⇤ generated by R package huge. The magnitude
of correlations is the default value in the huge generator.
In order to incorporate corruptions, we use the same approach described above to generate observations. Specifically, for the arbitrary corruption model, we generate samples through model M2A in (5.1) with p = 0.1, 0.2. For
the outlier model, we generate samples through model M2O
in (5.2) with p = 0.1, 0.2.
To check the validity of the type I error of our test, we run

Robust Gaussian Graphical Model Estimation with Arbitrary Corruption

0.4

0.6

0.8

1.0

1.0
0.8
glasso

spearC

0.2

0.2

0.2

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

FP

(a)

tslasso

rll

skeptic

glasso

spearC

rclime

0.0
0.0

FP

tglasso

0.0

0.2

0.2

skeptic

rclime

0.0

rclime

0.0

rclime

0.0

tslasso

rll

TP

spearC

tglasso

0.4

glasso

0.6

0.8
skeptic

TP

tslasso

rll

0.4

spearC

0.6

0.8
glasso

tglasso

0.4
skeptic

TP

0.6

0.8
0.6
TP

tslasso

rll

0.4

tglasso

cluster graph

1.0

cluster graph

1.0

cluster graph

1.0

cluster graph

0.6

0.8

1.0

0.0

0.2

0.4

FP

(b)

0.6

0.8

1.0

FP

(c)

(d)

Figure 1. ROC curves of different methods on cluster graphs under the arbitrary corruption model. (a): d = 400, n = 200, p = 0.1, µ =
1; (b): d = 400, n = 200, p = 0.2, µ = 1; (c): d = 400, n = 200, p = 0.1, µ = 2; (d): d = 400, n = 200, p = 0.2, µ = 2
Table 1. Quantitative comparisons of the GLasso, t⇤ Lasso, tGLasso, RLL, SKEPTIC, spearC and our Robust estimator on the cluster,
b ⇥⇤ k2 under the outlier model.
band graphs in terms of k⇥
Model
Band
Cluster

d

GLasso

t⇤ Lasso

tGLasso

RLL

SKEPTIC

spearC

Ours

100
400
100
400

5.803(0.107)
5.886(0.171)
5.537(0.071)
9.444(0.092)

4.180(0.129)
5.755(0.114)
5.318(0.031)
8.828(0.108)

2.755(0.217)
2.939(0.102)
4.944(0.093)
8.586(0.127)

3.639(0.315)
3.739(0.181)
5.004(0.110)
8.795(0.087)

5.579(0.177)
5.891(0.115)
5.529(0.061)
9.489(0.177)

4.071(0.133)
4.481(0.114)
5.283(0.098)
8.819(0.143)

2.471(0.110)
2.877(0.109)
4.776(0.127)
8.160(0.102)

Table 2. Quantitative comparisons of the GLasso, t⇤ Lasso, tGLasso, RLL, SKEPTIC, spearC and our Robust estimator on the cluster,
b ⇥⇤ k2 under arbitrary the corruption model.
band graphs in terms of k⇥
Model
Band
Cluster

d

GLasso

t⇤ Lasso

tGLasso

RLL

SKEPTIC

spearC

Ours

100
400
100
400

4.688(0.096)
4.763(0.127)
5.022(0.092)
7.133(0.127)

3.694(0.258)
3.886(0.219)
4.447(0.133)
6.798(0.181)

4.682(0.118)
4.768(0.095)
4.906(0.171)
7.408(0.112)

4.403(0.107)
4.584(0.183)
5.496(0.106)
9.050(0.209)

4.530(0.134)
4.586(0.107)
4.907(0.116)
6.840(0.161)

4.487(0.159)
4.552(0.128)
4.850(0.125)
6.804(0.139)

3.433(0.171)
3.581(0.144)
4.111(0.131)
6.428(0.177)

Normal Q−Q Plot

Normal Q−Q Plot

Normal Q−Q Plot

−2

−1

0

1

Theoretical Quantiles

(a)

2

3

−3

−2

−1

0

1

2

Theoretical Quantiles

(b)

3

3
2
1
−1

0

Sample Quantiles

1
0
−1

Sample Quantiles

−2

−3

−3

−2
−3

−2

0
−2

−1

Sample Quantiles

2
1
0
−1

Sample Quantiles

1

3

2

2

Normal Q−Q Plot

−3

−2

−1

0

1

Theoretical Quantiles

(c)

2

3

−3

−2

−1

0

1

2

3

Theoretical Quantiles

(d)

Figure 2. Q-Q plot of test statistic Tbn . (a-b): data generated from the outlier model with d = 100, n = 100 and d = 400, n = 200
respectively; (c,d): data generated from the arbitrary corruption model with d = 100, n = 100 and d = 400, n = 200 respectively.

500 simulations. The detail of our hypothesis testing procedure is described in Section 3.3. In the two different settings, we set n2 = 10 and n2 = 20 respectively, and we
choose the tuning parameters by cross-validations. Table 3 summarizes the empirical type I errors of our test in
different settings. We can observe that the empirical type I

errors are close to the significance level. Figure 2 shows the
Q-Q plots of our test statistic Tbn in (3.6) based on 500 simulations. These plots corroborate the asymptotic normality
of our test statistic. All these results demonstrate the advantage of our hypothesis testing procedure under the arbitrary
corruption model.

Robust Gaussian Graphical Model Estimation with Arbitrary Corruption
AACT1
DXPS1

DXPS2

AACT2

DXPS3

DXR

HMGS

MCT
HMGR1

HMGR2

CMK
MECPS

MK

HDS
MPDC1

MPDC2

HDR
IPPI1

IPPI2
UPPS1
DPPS2

GPPS

GPPS1,5,9
FPPS1

GPPS
2,6,8,10,11,12

PPDS1

FPPS2

PPDS2
DPPS1,3

GPPS3,4

Figure 3. Genetic network identified by Robust CLIME for the gene expression data of Arabidopsis thaliana. Solid edges: graph
estimated by Robust CLIME. Dotted arrows: known metabolic pathway. Left white figure and Right grey figure correspond to MEP and
MAV pathway respectively. Note that the arrow lines correspond to the known metabolic pathway, they do not mean directed networks.

Table 3. Empirical coverage of 95% confidence intervals and
Type I error at 0.05 significant level
Corruption model

d

Coverage

Width

Type I error

outlier

100
400

0.956
0.946

0.338
0.344

0.044
0.054

arbitrary

100
400

0.950
0.942

0.352
0.356

0.050
0.058

5.2 Gene Expression Data

the group MK, MPDC1, and FFPS2 in MAV pathway. And
in MEP path way, it also identifies the connection among
DXR, MCT, CMK and MECPS. Other methods such as
GLasso tends to estimate more links between two pathways
in order to identify these important relationships. These
edges between two pathways provided by GLasso might
be inaccurate relationships due to the lack of robustness.
The graph recovered by GLasso and the graph established
by Wille et al. (2004) can be found in the longer version of
this paper.

In this subsection, we use the gene expression data of
Arabidopsis thaliana, which was analyzed by Wille et al.
(2004) and later on by Finegold & Drton (2011); Hirose &
Fujisawa (2015), to illustrate the advantage of our method.
This data set includes n = 118 observations with 39 gene
expression levels. For this gene expression dataset, we preprocess it through R package limma3 . Figure 6 in Appendix illustrates the histogram of some rescaled gene expression data. It shows that some rescaled gene expressions
contain some expression levels with extreme large magnitude, which may be outliers. Therefore, we want to apply
our method to construct a network among these genes. For
Robust CLIME, we set n2 = 10 and adopt 5-fold crossvalidation to choose the tuning parameter .

6

The graph estimated by our method is given in Figure 3.
The dotted arrows and the solid undirected edges correspond to the known metabolic pathway and the graph estimated by Robust CLIME, respectively. We can see that our
approach identifies a similar graph to that obtained by previous analysis of Wille et al. (2004) but with fewer ”crosstalk” edges between two pathways. For example, our approach finds the important connection between AACT2 and

Acknowledgment

3

Available on http://bioconductor.org/packages/limma

Conclusions and Future Work

In this paper, for the Gaussian graphical model estimation
with arbitrary corruptions, we proposed a new estimator
for high-dimensional precision matrices based on the robust covariance matrix estimator. We not only provide the
estimation error bound of our robust estimator, but also
propose a hypothesis testing procedure to assess the uncertainty of our robust estimator with corrupted observations,
and construct the confidence interval for the point estimate.
However, most of the robust high dimensional estimators
as well as our proposed estimator are not invariant under
the group action (Davies et al., 2005; Draisma et al., 2013),
we will study this problem in our future work.

We would like to thank the anonymous reviewers for their
helpful comments. This research was sponsored in part
by the National Science Foundation IIS-1618948 and IIS1652539. The views and conclusions contained in this paper are those of the authors and should not be interpreted
as representing any funding agencies.

Robust Gaussian Graphical Model Estimation with Arbitrary Corruption

References
Balmand, Samuel and Dalalyan, Arnak. Convex programming approach to robust estimation of a multivariate
gaussian model. arXiv preprint arXiv:1512.04734, 2015.
Banerjee, O., Ghaoui, L. E., and d’Aspremont, A. Model
selection through sparse maximum likelihood estimation. 9(3):485–516, 2008.

Liu, Han, Han, Fang, Yuan, Ming, Lafferty, John, and
Wasserman, Larry. High-dimensional semiparametric
gaussian copula graphical models. The Annals of Statistics, pp. 2293–2326, 2012.
Liu, Weidong et al. Gaussian graphical model estimation
with false discovery rate control. The Annals of Statistics, 41(6):2948–2978, 2013.

Cai, T., Liu, W., and Luo, X. A constrained `1 minimization approach to sparse precision matrix estimation. 106
(494):594–607, 2011.

Loh, Po-Ling and Tan, Xin Lu. High-dimensional robust
precision matrix estimation: Cellwise corruption under ✏-contamination. arXiv preprint arXiv:1509.07229,
2015.

Chen, Mengjie, Gao, Chao, and Ren, Zhao. Robust covariance matrix estimation via matrix depth. arXiv preprint
arXiv:1506.00691, 2015.

Meinshausen, N. and Bühlmann, P. High dimensional
graphs and variable selection with the lasso. 34(3):1436–
1462, 2006.

Chen, Yudong, Caramanis, Constantine, and Mannor, Shie.
Robust high dimensional sparse regression and matching
pursuit. arXiv preprint arXiv:1301.2725, 2013.

Neykov, Matey, Ning, Yang, Liu, Jun S, and Liu, Han.
A unified theory of confidence regions and testing for
high dimensional estimating equations. arXiv preprint
arXiv:1510.08986, 2015.

Cox, David Roxbee and Wermuth, Nanny. Multivariate
dependencies: Models, analysis and interpretation, volume 67. CRC Press, 1996.
Davies, P Laurie, Gather, Ursula, et al. Breakdown and
groups. The Annals of Statistics, 33(3):977–1035, 2005.

Öllerer, Viktoria and Croux, Christophe. Robust highdimensional precision matrix estimation. In Modern
Nonparametric, Robust and Multivariate Methods, pp.
325–350. Springer, 2015.

Draisma, Jan, Kuhnt, Sonja, Zwiernik, Piotr, et al. Groups
acting on gaussian graphical models. The Annals of
Statistics, 41(4):1944–1969, 2013.

Raskutti, Garvesh, Wainwright, Martin J, and Yu, Bin. Restricted eigenvalue properties for correlated gaussian designs. The Journal of Machine Learning Research, 11:
2241–2259, 2010.

Finegold, Michael and Drton, Mathias. Robust graphical
modeling of gene networks using classical and alternative t-distributions. The Annals of Applied Statistics, pp.
1057–1080, 2011.

Ravikumar, P., Wainwright, M., Raskutti, G., and Yu, B.
High-dimensional covariance estimation by minimizing
`1 -penalized log-determinant divergence. 5:935–980,
2011.

Friedman, J., Hastie, T., and Tibshirani, R. Sparse inverse
covariance estimation with the graphical lasso. Biostatistics, 9(3):432–441, 2008.

Ren, Zhao, Sun, Tingni, Zhang, Cun-Hui, Zhou, Harrison H, et al. Asymptotic normality and optimalities in
estimation of large gaussian graphical models. The Annals of Statistics, 43(3):991–1026, 2015.

Gu, Quanquan, Cao, Yuan, Ning, Yang, and Liu,
Han. Local and global inference for high dimensional gaussian copula graphical models. arXiv preprint
arXiv:1502.02347, 2015.

Sun, Hokeun and Li, Hongzhe. Robust gaussian graphical
modeling via l1 penalization. Biometrics, 68(4):1197–
1206, 2012.

Hirose, Kei and Fujisawa, Hironori. Robust sparse gaussian
graphical modeling. arXiv preprint arXiv:1508.05571,
2015.

Tarr, Garth, Müller, Samuel, and Weber, Neville C. Robust
estimation of precision matrices under cellwise contamination. Computational Statistics & Data Analysis, 93:
404–420, 2016.

Jankova, Jana, van de Geer, Sara, et al. Confidence intervals for high-dimensional inverse covariance estimation.
Electronic Journal of Statistics, 9(1):1205–1229, 2015.

Tukey, John W. Mathematics and the picturing of data. In
Proceedings of the international congress of mathematicians, volume 2, pp. 523–531, 1975.

Liu, Han and Wang, Lie. Tiger: A tuning-insensitive approach for optimally estimating gaussian graphical models. arXiv preprint arXiv:1209.2437, 2012.

Vershynin, Roman. Introduction to the non-asymptotic
analysis of random matrices.
arXiv preprint
arXiv:1011.3027, 2010.

Robust Gaussian Graphical Model Estimation with Arbitrary Corruption

Wang, Lingxiao, Ren, Xiang, and Gu, Quanquan. Precision
matrix estimation in high dimensional gaussian graphical models with faster rates. In Proceedings of the 19th
International Conference on Artificial Intelligence and
Statistics, pp. 177–185, 2016.
Wille, Anja, Zimmermann, Philip, Vranová, Eva, Fürholz,
Andreas, Laule, Oliver, Bleuler, Stefan, Hennig, Lars,
Prelic, Amela, von Rohr, Peter, Thiele, Lothar, et al.
Sparse graphical gaussian modeling of the isoprenoid
gene network in arabidopsis thaliana. Genome Biol, 5
(11):R92, 2004.
Xu, Pan and Gu, Quanquan. Semiparametric differential
graph models. In Advances in Neural Information Processing Systems, pp. 1064–1072, 2016.
Xu, Pan, Tian, Lu, and Gu, Quanquan. Communicationefficient distributed estimation and inference for
transelliptical graphical models.
arXiv preprint
arXiv:1612.09297, 2016.
Xu, Pan, Zhang, Tingting, and Gu, Quanquan. Efficient
algorithm for sparse tensor-variate gaussian graphical
models via gradient descent. In Artificial Intelligence
and Statistics, pp. 923–932, 2017.
Yang, Eunho and Lozano, Aurélie C. Robust gaussian
graphical modeling with the trimmed graphical lasso. In
Advances in Neural Information Processing Systems, pp.
2584–2592, 2015.
Yuan, M. High dimensional inverse covariance matrix estimation via linear programming. 11(8):2261–2286, 2010.
Yuan, M. and Lin, Y. Model selection and estimation in
the gaussian graphical model. Biometrika, 94(1):19–35,
2007.
Zhao, Tuo and Liu, Han. Sparse inverse covariance estimation with calibration. In Advances in Neural Information
Processing Systems, pp. 2274–2282, 2013.

