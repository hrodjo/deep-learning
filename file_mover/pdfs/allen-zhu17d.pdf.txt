Follow the Compressed Leader:
Faster Online Learning of Eigenvectors and Faster MMWU

Zeyuan Allen-Zhu * 1 Yuanzhi Li * 2

Abstract
The online problem of computing the top eigenvector is fundamental to machine learning.
The famous matrix-multiplicative-weight-update
(MMWU) framework solves this online problem and gives optimal regret. However, since
MMWU runs very slow due to the computation of matrix exponentials, researchers proposed
the follow-the-perturbed-leader (FTPL)
frame√
work which is faster, but a factor d worse than
the optimal regret for dimension-d matrices. We
propose a follow-the-compressed-leader framework which, not only matches the optimal regret
of MMWU (up to polylog factors), but runs no
slower than FTPL. Our main idea is to “compress” the MMWU strategy to dimension 3 in
the adversarial setting, or dimension 1 in the
stochastic setting. This resolves an open question regarding how to obtain both (nearly) optimal and efficient algorithms for the online eigenvector problem.

1

Introduction

Finding leading eigenvectors of symmetric matrices is one
of the most primitive problems in machine learning. In this
paper, we study the online variant of this problem, which
is a learning game between a player and an adversary (Nie
et al., 2013; Kotłowski & Warmuth, 2015; Dwork et al.,
2014; Garber et al., 2015; Abernethy et al., 2015).
Online Eigenvector Problem. The player plays T unitnorm vectors w1 , . . . , wT ∈ Rd in a row; after playing wk ,
the adversary picks a feedback matrix Ak ∈ Rd×d that is
*

Equal contribution . Future version of this paper shall
be found at https://arxiv.org/abs/1701.01722.
1
Microsoft Research 2 Princeton University. Correspondence
to: Zeyuan Allen-Zhu <zeyuan@csail.mit.edu>, Yuanzhi Li
<yuanzhil@cs.princeton.edu>.
Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

symmetric and satisfies 0  Ak  I.1 Both these assumptions are for the sake of simplicity and can be relaxed.2 The
player then receives a gain
wk> Ak wk = Ak • wk wk> ∈ [0, 1] .
The regret minimization problem asks us the player to design a strategy to minimize regret, that is, the difference
between the total gain obtained by the player and that by
the a posteriori best fixed strategy u ∈ Rd :
minimize

max

PT

u∈Rd

k=1 Ak

• (uu> − wk wk> )

= λmax A1 + · · · + AT ) −

T
X

wk> Ak wk .

k=1

The name comes from the fact that the player chooses only
vectors in a row, but wants to compete against the leading
eigenvector in hindsight. To make this problem meaningful, the feedback matrix Ak , is not allowed to depend on
wk but can depend on w1 , . . . , wk−1 .
1.1

Known Results

The most famous solution to the online eigenvector problem is the matrix multiplicative-weight-update (MMWU)
method, which has also been used towards efficient algorithms for SDP, balanced separators, Ramanujan sparsifiers, and even in the proof of QIP = PSPACE.
k−1 )
MMWU. At iteration k, define Wk = Trexp(ηΣ
exp(ηΣk−1 )
where Σk−1 := A1 +· · ·+Ak−1 and η > 0 is the learning
rate. Then, compute its eigendecomposition
Pd
k−1 )
>
Wk = Trexp(ηΣ
j=1 pj · yj yj
exp(ηΣk−1 ) =

where vectors yj are normalized eigenvectors. Now, the
MMWU strategy instructs the player to choose wk = yj
1

We denote by A  B spectral dominance that is equivalent
to saying that A − B is positive semidefinite (PSD).
2
Firstly, all the results cited and stated in this paper, after scaling, generalize to the scenario when the eigenvalues of Ak are
in the range [l, r] for arbitrary l, r ∈ R. For notational simplicity, we have assumed l = 0 and r = 1 in this paper. Secondly,
if Ak is not symmetric or even rectangular, classical reductions
can turn such a problem into an equivalent online game with only
symmetric matrices (see Sec 2.1 of (Garber et al., 2015)).

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

√
√
each with probability pj . The best choice
√ η = log d/ T
yields a total expected regret O( T log d) (Orecchia,
2011), and this is optimal up to constant (Arora et al.,
2012). It requires some additional, but standard, effort to
turn this into a high-confidence result.
Unfortunately, the per-iteration running time of MMWU is
at least O(dω ) due to eigendecomposition, where dω is the
complexity for multiplying two d × d matrices.3
MMWU-JL. Some researchers also use the JohnsonLindenstrauss (JL) compression to reduce the dimension
of Wk from MMWU to make it more efficiently computable (Peng & Tangwongsan, 2012; Allen-Zhu et al.,
2016; 2015; Lee & Sun, 2015). Specifically, they compute
1/2
a sketch matrix Y = Wk Q using a random Q ∈ Rd×m ,
>
and then use YY to approximate Wk . If the dimension
2
e
m is O(1/σ
), this compression incurs an average regret
loss of σ. We call this method MMWU-JL for short.4
√
e T ), one must
Unfortunately, to maintain a total regret O(
let σ ≈ T −1/2 . Therefore, JL compresses the matrix expoe ), and is only useful when T ≤ d.
nential to dimension O(T
FTPL. Researchers also study the follow-the-perturbedleader (FTPL) strategy (Kotłowski & Warmuth, 2015;
Dwork et al., 2014; Garber et al., 2015; Abernethy et al.,
2015). Most notably, Garber, Hazan and Ma (Garber
et al., 2015) proposed to compute an (approximate) leading eigenvector of the matrix Σk−1 + rr> at iteration
k,
√
where r is a random vector whose norm is around dT .
√
e
Unfortunately,
√ the total regret of FTPL is O( dT ), which
is a factor d worse than the optimum
√ regret, and interesting only when T ≥ d. This factor d loss can indeed be
realized in practice, see Figure 1.
1.2

Our Main Results

We propose a follow-the-compressed-leader (FTCL) strategy that, at a high level, compresses the MMWU strategy to
e ) in
dimension m = 3 as opposed to dimension m = Θ(T
MMWU-JL. Our FTCL strategy has significant advantages
over previous results because:
√
e T ) which is optimal up to poly• FTCL has regret O(
√
log factors (as opposed to d in FTPL).
• Each iteration of FTCL is dominated by solving a logarithmic number of linear systems.
Since solving linear systems is generally no slower than
computing eigenvectors or matrix exponentials, the per3

In fact, it is known that eigendecomposition has complexity
O(dω ) when all the eigenvalues are distinct, and could possibly
go up to O(d3 ) when some eigenvalues are equal (Pan & Chen,
1999).
4
e notation to hide polylogaThrough the paper, we use the O
rithmic factors in T, d and 1/ε if applicable.

iteration complexity of FTCL is no slower than FTPL, and
much faster than MMWU and MMWU-JL. We shall make
this comparison more explicit in Section 3.
1.3

Our Side Result: Stochastic Online Eigenvector

We also study the special case of the online eigenvector
problem where the adversary is stochastic, meaning that
A1 , . . . , AT are chosen i.i.d. from a common distribution
whose expectation equals some matrix B, independent of
the player’s actions. For this problem,
• Garber et al. (Garber et al., 2015)
pshowed a block power
method gives a total regret O( T log(dT )), and runs
in O(nnz(ΣT )) time per iteration. (We denote nnz(M)
the time to multiply M to a vector.)
• Shamir (Shamir, √
2016) showed Oja’s algorithm5 √
has
a total regret O( dT log(T )), which is a factor d
worse than optimum.
In this paper, we√show that Oja’s algorithm in fact only has
T log d) for this stochastic setting, which
a total regret O( √
is optimal up to a log d factor. Most importantly, the k-th
iteration of Oja’s runs in only O(nnz(Ak )) time.
Example. Since in low-rank or sparse cases it usually
satisfies nnz(ΣT ) = d2 and nnz(Ak ) = O(d), our result
can be faster than block power method by a factor O(d).
Our proof relies on a compression view of Oja’s algorithm
which compresses MMWU to dimension m = 1. Our
proof is one-paged, indicating that FTCL might be a better framework of designing online algorithms for matrices.
1.4

Our Results in a More Refined Language

Denoting by λ := T1 λmax (A1 + · · · AT ), we have λ ≤ 1
according to the normalization Ak  I. In general, the
smaller λ is, the better a learning algorithm should behave.
In the previous subsections, we have followed the tradition and discussed our results and prior works assuming the
worst possibility of λ. This has indeed simplified notations.
If λ is much smaller than 1, our complexity bounds can
be improved to quantities that depend on λ. We call this
the λ-refined language. At a high level, for our FTCL, in
both the adversarial
settings, the total regret
√
√and stochastic
e T ) to O(
e λT ).
improves from O(
√
We have an information-theoretic lower bound of Ω( λT )
for the total regret in this λ-refined language, see full version. This lower bound even holds for the stochastic problem, even when the matrices Ak are of rank 1.
As for prior work, it has been recorded that (cf. Theorem
3.1 of (Allen-Zhu et al., 2015)) the√MMWU and MMWUJL methods have total regret O( λT log d). The block
5

Here is a simple description of Oja’s algorithm: beginning
with a random Gaussian vector u ∈ Rd , at each iteration k,
choose wk to be (I+ηAk−1 ) · · · (I+ηA1 )u after normalization.

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU
20

30
20

10
0

150

15

Total Regret

40

Total Regret

Total Regret

50

10
5
0

0

2000

4000

FTPL

6000

this paper

8000 10000
MMWU

(a) random

100
50
0

0

2000

FTPL

4000

6000

8000 10000

this paper

0

MMWU

(b) diagonal

2000

FTPL

4000

6000

8000 10000

this paper

MMWU

(c) diagonal+rotation

Figure 1: We generate synthetic data to verify that the total regret of FTPL can indeed be poorer than MMWU or our FTCL. We explain
how matrices Ak are chosen in Appendix A. We have d = 100 and the x-axis represents the number of iterations.
Paper
MMWU
MMWU-JL(T ≤ d only)
FTPL (T ≥ d only)
this paper

block power method
this paper

Total Regret
√
e T)
O(
√
e T)
O(
√
e dT )
O(
√
e T)
O(

√
e T)
O(
√
e T)
O(

Time Per Iteration
at least O(dω )
e )
Mexp ×O(T

Mev ×1
e
Theorem 1&2 Mlin ×O(1)

Minimum Total Time
for ε Average Regreta
e
O
e
O

e
O
e
Theorem 3 O
e
O

↓ stochastic online eigenvector only ↓

O nnz(Σ)

Theorem 4 O nnz(A)
Theorem 4

e
O
e
O

dω
ε2

1
nnz(Σ)
ε4.5

d1.5
nnz(Σ)
ε3.5

1
nnz(Σ) and
ε2.5
3
1
1
nnz(Σ) 4 nnz(A) 4
ε2.5




+ ε12 nnz(Σ)

1
nnz(Σ)
ε2

1
nnz(A)
ε2



Table 1: Comparison of known methods for the online eigenvector problem.
 We denote
	 by nnz(M) the time needed to multiply M to a
vector, by Σ = A1 + · · · + AT , and by nnz(A) = maxk∈[T ] nnz(Ak ) ≤ nnz(Σ).
•
•
•
•

e 1/2 ) · I.
Mexp is the time to compute e−M multiplied with a vector, where M ∈ Rd×d satisfies 0  M  O(T
ev
−3/2 1/2
M is the time to compute the leading eigenvector of matrix M to multiplicative accuracy O(T
d ) ∈ (0, 1).
e 1/2 ).
Mlin is the time to solve a linear system for matrix M ∈ Rd×d , where M is PSD and of condition number ≤ O(T
ev
exp
lin
If using iterative methods, the worst-case values M , M , M are



e min{T 34 d− 41 nnz(Σ), dω } ≥ Mexp = O
e min{T 14 nnz(Σ), dω } ≥ Mlin = O
e min{min{d, T 14 }nnz(Σ), dω } ,
Mev = O
where dω is the time needed to multiply two d × d matrices.

e T 14 nnz(Σ) 34 nnz(A) 41 + nnz(Σ) .
O
a

If using stochastic iterative methods, Mlin is at most

The total time complexity of the first Tε rounds where Tε is the earliest round to achieve an ε average regret.

power
√ method (for the stochastic setting) has total regret
e λT ), by modifying the proof in (Garber et al., 2015).
O(
To the best of our knowledge, FTPL has not been analyzed
in the λ-refined language. We compare with prior work in
Table 2 in the appendix for this λ-refined language.
1.5

Other Related Works

The multiplicative weight update (MWU) method is a simple but extremely powerful algorithmic tool that has been
repeatedly discovered in theory of computation, machine
learning, optimization, and game theory (see for instance
the survey (Arora et al., 2012) and the book (Cesa-Bianchi
& Lugosi, 2006)). Its natural matrix extension, matrixmultiplicative-weight-update (MMWU) (Orecchia, 2011),
has been used towards efficient algorithms for solving
semidefinite programs (Arora & Kale, 2007; Allen-Zhu

et al., 2016; Peng & Tangwongsan, 2012), balanced separators (Orecchia et al., 2012), Ramanujan sparsifiers (AllenZhu et al., 2015; Lee & Sun, 2015), and even in the proof of
QIP = PSPACE (Jain et al., 2011). Some authors also refer
to MMWU as the follow-the-regularized-leader strategy or
FTRL for short, because MMWU can be analyzed from a
mirror-descent view with the matrix entropy function as its
regularizer.
For the online eigenvector problem, √
if the feedback mae dT ) total regret of
trices Ak are only of rank-1, the O(
e 1/4 T 1/2 ). This is first shown
FTPL can be improved to O(d
by Dwork et al. (Dwork et al., 2014) and independently
by Kotłowski and Warmuth (Kotłowski & Warmuth, 2015).
Abernethy et al. showed FTPL strategies can be analyzed
using a FTRL framework (Abernethy et al., 2014).

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

Researchers also put efforts to understand high-rank variants of the online eigenvector problem. Nie et al. studied the high-rank variant using MMWU (Nie et al., 2013),
but their per-iteration complexity is also high due to eigendecomposition. Some authors study a very different online model for computing the top k eigenvectors (Boutsidis
et al., 2015; Karnin & Liberty, 2015): they wish to output
O(k · poly(1/ε)) vectors instead of k but with a good PCA
reconstruction error.
The stochastic online eigenvector problem is related but
different from streaming PCA (Hardt & Price, 2014; AllenZhu & Li, 2016b). In streaming PCA, we are given i.i.d.
random matrices with an expectation B and asked to find a
unit vector w with large w> Bw in the end, without worrying about the per-iteration gain. The cited papers use different techniques from ours and do not imply our result on
stochastic online eigenvector.
For the most efficient offline eigenvectors algorithms, we
refer interested readers to our paper (Allen-Zhu & Li,
2016a) (for PCA / SVD) and (Allen-Zhu & Li, 2017) (for
CCA and generalized eigendecomposition).
1.6

Roadmap

We introduce notations in Section 2, and compare the
per-iteration complexity of FTCL to prior work in
Section 3. We discuss high-level intuitions and techniques
in Section 4. We introduce a new trace inequality in
Section 5, and state our main FTCL result for an oblivious adversary in Section 6. We extend it to the adversarial
setting and discuss how to implement FTCL fast in the full
version of this paper. Finally, in Section 8 we provide our
FTCL result for a stochastic adversary.
Our results are stated directly in the λ-refined language.

2

Notations and Preliminaries

Pk
Define Σk := i=1 Ai for every k = 0, 1, . . . , T . Since
each Ak is positive semi-definite (PSD), we can find Pk ∈
Rd×d such that Ak = Pk P>
k ; we only use Pk for analysis purpose only. Given two matrices A, B ∈ Rd×d ,
we write A • B := Tr(A> B). We write A  B if
A, B are symmetric matrices and A − B is PSD. We write
[A]i,j the (i, j)-th entry of A. We use kMk2 to denote
the spectral norm of a matrix M. We use nnz(M) to denote time needed to multiply matrix M ∈ Rd×d with an
arbitrary vector in Rd . In particular, nnz(M) is at most d
plus the number of non-zero
elements
in M. We denote

	
nnz(A) := maxk∈[T ] nnz(Ak ) .
Suppose x1 , · · · , xt ∈ R are drawn
from the standard
Pt i.i.d.
2
Gaussian N (0, 1), then χ =
x
has
a chi-squared
i=1 i
distribution of t-degree freedom. χ−1 is called inverse-chisquared distribution of t-degree freedom. It is known that
1
for t ≥ 3.
E[χ−1 ] = t−2

3

Detailed Comparison to Prior Work

We compare the per-iteration complexity of our results
more closely to prior work.
In the stochastic setting, Oja’s method runs in time
nnz(Ak ) for iteration k, and therefore is clearly faster than
the block power method which runs in time nnz(Σk ).
In the adversarial setting, it is clear that the per-iteration
complexities of FTPL and FTCL are no greater than
MMWU, because computing the leading eigenvector and
the matrix inversion are both faster than computing the full
eigendecomposition. In the rest of this section, we compare
MMWU-JL, FTPL and FTCL more closely. They respectively have per-iteration complexities
e ) × Mexp , 1 × Mev , and O(1)
e
O(T
× Mlin
where
• In MMWU-JL, we denote by Mexp the time needed for
computing exp(ηΣk−1 /2) multiplied to a vector. Ree −1/2 ).
call that η = Θ(T
• In FTPL, following the tradition, we denote by Mev
the time needed for computing the top √
eigenvector of
Σk−1 + rr> , where the norm of r is O( dT ).
• In FTCL, we denote by Mlin the time needed for solving
a linear system with matrix M = cI − ηΣk−1 , where
e −1/2 ).
M  1e I and η = Θ(T
For exact computations, one may generally derive that
Mexp ≥ Mev ≥ Mlin . However, for large-scale applications,
one usually applies iterative methods for the three tasks. Iterative methods utilize matrix sparsity, and have running
times that depend on matrix properties.
Worst-case Complexity. We compute that:
1/4
e
• Mexp in the worst case is O(min{T
nnz(ΣT ), dω }).
The first is because if using Chebyshev approximation,
one can compute exp(ηΣk−1 /2) applied to a vector in

e kηΣk−1 k1/2 ·nnz(Σk−1 ) . The second
time at most O
2
is because one can compute the singular value decome ω ) and then compute the
position of Σk−1 in time O(d
matrix exp(ηΣk−1 /2) directly.
• Mev
in
the
worst
3/4 −1/4
e
O(min{T
d
nnz(ΣT ), dω }).

case

is

The first is so because, as proved in (Garber et al.,
2015), it suffices to compute the top eigenvector of
3
1
Σk−1 + rr> up to a multiplicative error O(T − 2 d 2 ).6
If one applies Lanczos
method, this is in time

e T 34 d− 14 nnz(ΣT ) . (Recall that it only works when
O
T ≥ d). The second is because the leading eigenvector of a d × d matrix can be computed directly in time
O(dω ).
6
A multiplicative error δ means to find x such that x> (Σk−1 +
rr> )x ≥ (1 − δ)λmax (Σk−1 + rr> ).

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

• Mlin
in
the
worst 
e min{min{T 41 , d}nnz(ΣT ), dω } .
O

is

TrWk = TrWk+1 = 1 to derive a relationship between
ck − ck+1 and the gain value Wk • Ak at this iteration.

The first is because our matrix M has a condition nume 1/2 ). If using conjugate graber at most O(ηT ) = O(T
dient (Shewchuk, 1994), one can solve a linear system

e min{T 41 , d}nnz(ΣT ) . The
for M in time at most O
second is because the inverse of a d × d matrix can be
computed directly in time O(dω ) (Bunch & Hopcroft,
1974).

More specifically, using the Golden-Thompson inequality
we have


Tr eck I+ηΣk ≤ Tr eck I+ηΣk−1 eηAk


= Tr Wk eηAk ≈ Tr eck I+ηΣk−1 + ηWk • Ak .

case

• Mlin
be
improved
	 to
 can
e min T 41 nnz(ΣT ) 34 nnz(A) 41 + nnz(ΣT ), dω
if
O
using stochastic iterative methods.
In sum, if using iterative methods, the worst case values of
Mlin , Mev , Mexp are on the same magnitude. Since the pere lin ), this is no slower
iteration cost of FTCL is only O(M
ev
than O(M ) of FTPL, and much faster than O(T × Mexp )
of MMWU-JL.
Practical Complexity. There are many algorithms to
compute leading eigenvectors, including Lanczos method,
shift-and-invert, and the (slower) power method. The performance may depend on other properties of the matrix,
including “how well-clustered the eigenvalues are.”
There are also numerous ways to compute matrix inversions, including conjugate gradient, accelerated coordinate
descent, Chebyshev method, accelerated SVRG, and many
others. Some of them also run faster when the eigenvalues
form clusters (Shewchuk, 1994).
In particular, for a random Gaussian matrix Σk−1 (with dimension 100 ∼ 5000), using the default scientific package
SciPy of Python, Mev is roughly 3 times of Mlin .
Total Worst-Case Complexity. Since FTPL requires d
times more iterations in order to achieve the same average
regret as FTCL or MMWU, in the last column of Table 1,
we also summarize the minimum total time complexity
needed to achieve an ε average regret.
Examples. If nnz(ΣT ) = d2 and nnz(A) = O(d), the
total complexity needed to achieve an ε average regret:
e 2 ε−2 + d1.75 ε−2.5 ) (us) O(d
e 3.5 ε−3.5 ) (FTPL)
O(d
e 2 ε−4.5 ) (MMWU-JL)
O(d

e 3 ε−2 ) (MMWU)
O(d

In the λ-refined setting, one can revise the complexity
bounds accordingly. We ignore the details in this short version and present them in Table 2 in the appendix.

4

High-Level Discussion of Our Techniques

Revisit MMWU. We first revisit the high-level idea behind the proof of MMWU. Recall Wk = exp(ck I +
ηΣk−1 ) where ck is the unique constant such that
TrWk = 1. The main proof step (see for instance Theorem 3.1 of (Allen-Zhu et al., 2015)) is to use the equality

One can also use convexity to show


Tr eck+1 I+ηΣk − Tr eck I+ηΣk ≤ ck+1 − ck .
Adding these two inequalities, and using the fact that
TrWk = TrWk+1 = 1, we immediately have ck −
ck+1 . ηWk •Ak . In other words, the gain value Wk •Ak
at iteration k, up to a factor η, is lower bounded by the
decrement of ck . On the other hand, it is easy to see
c1 − cT +1 ≥ ηλmax (ΣT ) − O(log d) from c1 = − log d
and the definition of cT +1 . Together, we can derive that
PT
k=1 Wk • Ak & λmax (ΣT ) .
In the rest of this section, we perform a thought experiment
to “modify” the above MMWU analysis step-by-step. In
the end, the intuition of our FTCL shall become clear to
the reader.
Thinking Step 1. We wish to choose a random Gaussian
vector u ∈ Rd and “compress” MMWU to dimension 1
in the direction of u. More specifically, we define Wk =
exp(ck I + ηΣk−1 ) but this time ck is the unique constant
such that Tr(Wk uu> ) = u> Wk u = 1. In such a case,
we wish to say that


Tr eck I+ηΣk uu> = Tr eck I+ηΣk−1 +ηAk uu>
(?)

≤ Tr e(ck I+ηΣk−1 )/2 uu> e(ck I+ηΣk−1 )/2 eηAk

1/2
1/2
= Tr Wk uu> Wk eηAk
1/2

1/2

≈ Tr(Wk uu> ) + ηWk uu> Wk

• Ak .

If the above inequality were true, then we could de1/2
fine wk := Wk u which is a unit vector (because
Tr(Wk uu> ) = 1) and the gain wk> Ak wk = wk wk> • Ak
would again be proportional to the change
of this new po
tential function Tr eck I+ηΣk−1 uu> . This idea almost
worked except that inequality (?) is false due to the noncommutativity of matrices.7
Perhaps the most “immediate” idea to fix this issue is to
use the randomness of uu> . Recall that E[uu> ] = I if we
choose properly normalize u, and therefore it “seems like”
we have E[Tr(Wk uu> )] = Tr(Wk ) and the inequality
will go through. Unfortunately, this idea fails for a fundamental reason: the normalization constant ck depends on
7
A analogy for this effect can be found in the inequality
Tr(eA ) ≤ Tr(eB ) for every A  B. This inequality becomes
false when multiplied with uu> and in general eA  eB is false.

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

u, so Wk is not independent from the randomness of u.8
Thinking Step 2. Since Gaussian vectors are rotationally
invariant, we switch wlog to the eigenbasis of Σk−1 so Wk
is a diagonal matrix. We make an important observation:9
ck depends only on |u1 |, . . . , |ud |,
but not on the 2d possible signs of u1 , . . . , ud .
For this reason, we can fix a diagonal matrix D and consider all random uu> which agree with D on its diagonal,10
All of such vectors u give the same normalization constant
ck , and it satisfies E[uu> |D] = D. This implies that we
can now study the conditional expected potential change


 
E Tr eck I+ηΣk uu> − Tr eck I+ηΣk−1 uu> D


= Tr eck I+ηΣk D − Tr eck I+ηΣk−1 D ,
or if we denote by B = ckI + ηΣk−1 , we
 want to study the
difference Tr eB+ηAk D − Tr eB D only in the special
case that D and B are simultaneously diagonalizable.

k
ThinkingStep 3. A usual way to bound Tr eB+ηA
D −

Tr eB D is to define f (η) := Tr eB+ηAk D and bound
f (η) by its Taylor series f (0) + f 0 (0)η + 12 f 00(0)η 2 + · · · .
The zero-order derivative f (0) is Tr eB D . The firstorder derivative f 0 (0) = Tr(Ak eB D) = eB/2 DeB/2 •Ak
behaves exactly in the way we hope, and this strongly relies
on the commutativity between B and D. Unfortunately,
higher-order derivatives f (k) (0) benefit less and less from
the commutativity between B and D due to the existence
of terms such as Ak eB DeB Ak D. For this reason, we need
to (1) truncate the Taylor series and (2) use different analytic tools. This motivates us to use the following regime
that can be viewed as a “low-degree” version of MMWU:
A Quick Detour. In a recent result, the authors of (AllenZhu et al., 2015) generalized MMWU to `1−1/q regularized strategies. For every q ≥ 2, they define Xk =
(ck I − ηΣk−1 )−q where ck is the unique constant such
that ck I − ηΣk−1  0 and TrXk = 1.11 This is a
generalization of MMWU because when q ≈ log d, the
matrix Xk behaves nearly the same as Wk ; in particular, it gives the same regret bound. The analysis behind
8
In fact, ck can be made almost independent from u if we
replace uu> with QQ> where Q is a random d × m matrix for
some very large m. That was the main idea behind MMWU-JL.
Pd
9
2
This is because, Tr(eck I−ηΣk−1 uu> ) =
i=1 |ui | ·

ck −ηλi
e
where λi is the i-th eigenvalue of Σk−1 .
10
That is, all random uu> such that kui k22 = Di,i for each
i ∈ [d]. For simplicity we also denote this event as D.
11
The name “`1−1/q strategies” comes from the following fact.
Recall MMWU naturally arises as the follow-the-regularizedleader strategy, where the regularizer is the matrix entropy. If
the entropy function is replaced with a negative `1−1/q norm, the
resulting strategy becomes Xk . We encourage interested readers
to see the introduction of (Allen-Zhu et al., 2015) for more background, but we shall make this present paper self-contained.

this new strategy is to keep
 track of the potential change in

Tr (ck I−ηΣk−1 )−(q−1) as opposed to Tr eck I+ηΣk−1 ,
and then use the so-called Lieb-Thirring inequality (see
Section 5) to replace the use of Golden-Thompson. (Note
that ck is choosen with respect to q but the potential is with
respect to q − 1.)
Thinking Step 4. Let us now replace MMWU strategies in our Thinking Steps 1,2,3 with `1−1/q regularized
strategies. Such strategies have two advantages: (1) they
help us overcome the issue for higher-order terms in Thinking Step 3, and (2) solving linear systems is more efficient
than computing matrices exponentials. We shall choose
q = Θ(log(dT )) in the end.
Specifically, we prepare a random vector u and define the
normalization constant ck to be the unique one satisfying
Tr (ck I − ηΣk−1 )−q uu> = Tr(Xk uu> ) = 1. At itera1/2
tion k, we let the player choose strategy Xk u which is a
unit vector.
If one goes through all the math carefully (using Woodbury
formula), this time we are entitled to upper bound the trace
difference of the form Tr (B+ηC)q−1 D −Tr Bq−1 D
where D is simultaneously diagonalizable with B but not
C. Similar to Thinking
Step 3, we can define f (η) :=

Tr (B + ηC)q−1 D and bound this polynomial f (η) using its Taylor expansion at point 0. Commutativity between
B and D helps us compute f 0 (0) = (q − 1)Tr(Bq−2 CD)
but again we cannot bound higher-derivatives directly. Fortunately, this time f (η) is a degree q − 1 polynomial so we
can use Markov brothers’ inequality to give an upper bound
on its higher-order terms. This is the place we lose a few
extra polylogarithmic factors in the total regret.
Thinking Step 5. Somehow necessarily, even the secondorder derivative f 00 (0) can depend on terms such as 1/Dii
where Dii = |ui |2 is the i-th diagonal entry of D. This
quantity, over the Gaussian random choice of ui , does not
have a bounded mean. More generally, the inverse chisquared distribution with degree t (recall Section 2) has a
bounded mean only when t ≥ 3. For this reason, instead
of picking a single random vector u ∈ Rd , we need to pick
three random vectors u1 , u2 , u3 ∈ Rd and replaceall the
>
>
occurrences of uu> with 13 u1 u>
1 + u2 u2 + u3 u3 in the
previous thinking steps. As a result, each Dii becomes a
chi-squared distribution of degree 3 so the issue goes away.
This is why we claimed in the introduction that
we can compress MMWU to dimension 3.
Thinking Step 6. Putting together previous
√ steps, we
obtain a FTCL strategy with total regret O( T log3 (dT )),
which is worse than MMWU only by a factor
O(log2.5 (dT )). We call this method FTCLobl and include its analysis in Section 6. However, FTCLobl only
works for an oblivious adversary (i.e., when A1 , . . . , AT

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

are fixed a priori) and gives an expected regret. To turn
it into a robust strategy against adversarial A1 , . . . , AT ,
and to make the regret bound work with high confidence,
we need to re-sample u1 , u2 , u3 every iteration. We call
this method FTCLadv . A careful but standard analysis with
Azuma inequality helps us reduce FTCLadv to FTCLobl . We
state this result in the full version.

Lemma 5.1. For every symmetric matrices A, B, D ∈
Rd×d , every integer k ≥ 1, every η ∗ ≥ 0, and every η ∈
[0, η ∗ /k 2 ], if A and D are commutative, then

Running Time. As long as q is an even integer, the computation of “(ck I − ηΣk−1 )−1 applied to a vector” (or
in other words, solving linear systems) becomes the bottleneck for each iteration of FTCLobl and FTCLadv . However, as long as q ≥ Ω(log(dT )), we show that the condition number of the matrix ck I − ηΣk−1 is at most ηT =
Θ(T 1/2 ). Conjugate gradient solves each such linear sys1/4
e
tem in worst-case time O(min{T
, d} × nnz(Σk−1 )).

6

Compress to 1-d in Stochastic Online Eigenvector. If
the adversary is stochastic, we observe that Oja’s algorithm
corresponds to a potential function Tr (I + ηAk ) · · · (I +
ηA1 )uu> (I + ηA1 ) · · · (I + ηAk ) . Because the matrices
are drawn from a common distribution, this potential behaves similar to the matrix exponential but compressed
to

dimension 1, namely Tr eη(A1 +···+Ak ) uu> . In fact, just
using linearity of expectation carefully, one can both upper and lower bound this potential. We state this result in
Section 8 (and it can be proved in one page!)

where the expectation is over player’s random choices
wk ∈ Rd (recall kwk k2 = 1).

5

A New Trace Inequality

Prior work on MMWU and its extensions rely heavily
on one of the following trace inequalities: the GoldenThompson inequality

Tr(eA+ηB ) ≤ Tr eA eηB
and the Lieb-Thirring inequality


Tr (A+ηB)k ≤ Tr Ak/2 (I+ηA−1/2 BA−1/2 )k Ak/2 .
Due to our compression framework in this paper, we need
inequalities of type

“ Tr(eA+ηB D) ≤ Tr eηB eA/2 DeA/2 ”

“ Tr (A + ηB)k D

≤ Tr (I + ηA−1/2 BA−1/2 )k Ak/2 DAk/2 ” (5.1)
which look almost like “generalizations” of GoldenThompson and Lieb-Thirring (by setting D = I). Unfortunately, such generalizations do not hold for an arbitrary D. For instance, if the first “generalization” holds
for every PSD matrix D then it would imply “ eA+ηB 
eA/2 eηB eA/2 ” which is a false inequality due to matrix
non-commutativity.
In this paper, we show that if D is commutative with A,
then the “generalization” (5.1) holds for the zeroth and first
order terms with respect to η. As for higher order terms,
we can control it using Markov brothers’ inequality. (Proof
see full paper.)

(A + ηB)k • D − Ak • D ≤ kηB • Ak−1 D
 2 2
n
o
ηk
(A + η 0 B)k • D − Ak • D .
max
+
η∗
η 0 ∈[0,η ∗ ]

Oblivious Online EV + Expected Regret

In this section we first focus on a simpler oblivious setting.
A1 , . . . , AT are T PSD matrices chosen by the adversary
in advance, and they do not depend on the player’s actions
in the T iterations. We are interested in upper bounding the
total expected regret
 PT
PT
>
λmax
k=1 Ak −
k=1 E[wk Ak wk ] ,

In the full version, we generalize this result to the full adversarial setting along with high-confidence regret.
Our algorithm FTCLobl is presented in Algorithm 1. It is
parameterized by an even integer q ≥ 2 and a learning rate
η > 0. It initializes with a rank-3 Wishart random matrix
U. For every k ∈ [T + 1], we denote by Xk := ck I −
−q
ηΣk−1
where ck > 0 is the unique constant s.t.12

ck I − ηΣk−1  0 and Tr Xk U = 1 .
At iteration k ∈ [T ], the player plays a random unit vec1/2
1/2
tor wk , among the three eigenvectors of Xk UXk . It
1/2
1/2
satisfies E[wk wk> ] = Xk UXk .
We prove the following theorem for the total regret of
FTCLobl (T, q, η) in the full version of this paper:
Theorem 1. If we have an oblivious adversary, there exists absolute
C > 1 such that if q ≥ 3 log(2dT )
 constant

1
obl
and η ∈ 0, 11q
(T, q, η) satisfies
3 , then FTCL
T
X
k=1

h
i

4
E wk> Ak wk ≥ 1 − Cηq 5 log(dT ) λmax (ΣT ) −
η

Corollary 6.1.

−3
Θ √log (dT )

If q

=

3 log(2dT ) and η

=

λmax (ΣT )

h
i
>
E
w
A
w
(λ-refined language)
k
k
k
k=1

p
≥ λmax (ΣT ) − O
λmax (ΣT ) log3 (dT ) ,

−3
or choosing the same q but η = Θ log √T(dT ) we have
h
i
√

PT
>
T log3 (dT ) .
k=1 E wk Ak wk ≥ λmax (ΣT )−O
(general language)
PT

12


This ck is unique because Tr Xk U is a strictly decreasing
function for ck > ηλmax (Σk−1 ).

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

Algorithm 1 FTCLobl (T, q, η)
Input: T , number of iterations; q ≥ 2, an even integer,
 theory-predicted choice q =pΘ(log(dT ))
η, the learning rate.
 theory-predicted choice η = log−3 (dT )/ λmax (ΣT )
1: Choose u1 , u2 , u3 ∈ Rd where the
 3d coordinates are i.i.d. drawn from N (0, 1).
>
>
2: U ← 13 u1 u>
+
u
u
+
u
u
2
3
1
2
3 .
3: for k ← 1 to P
T do
k−1
4:
Σk−1 ← i=1 Ai .

−q
5:
Denote by Xk ← ck I − ηΣk−1
where ck is the constant s.t. ck I − ηΣk−1  0 and Tr Xk U = 1 .
P
1/2
1/2
3
6:
Compute Xk UXk = j=1 pj · yj yj> where y1 , y2 , y3 are orthogonal unit vectors in Rd .
7:
Choose wk ← yj with probability pj .
 it satisfies p1 , p2 , p3 ≥ 0 and p1 + p2 + p3 = 1.
8:
Play strategy wk and receive matrix Ak .
9: end for

7

Missing Theorems

In the full version of this paper, we state Theorem 2, a similar result of Theorem 1 but (1) with a high-confidence regret bound and (2) for the adversarial setting: Ak may depend on the player’s strategies w1 , . . . , wk−1 . In the full
version, we also provide Theorem 3, which addresses the
worst-case complexity for implementing the matrix inversion steps in FTCLobl .

8

Stochastic Online Eigenvector

Consider the special case when the matrices A1 , . . . , AT
are generated i.i.d. from a common distribution whose expectation equals B. This is known as the stochastic online
eigenvector problem, and we wish to minimize the regret
PT
>
k=1 wk Ak wk − T · λmax (B) .
We revisit Oja’s algorithm: beginning with a random Gaussian vector u ∈ Rd , at each iteration k, let wk be (I +
ηAk−1 ) · · · (I + ηA1 )u after normalization. It is clear that
wk can be computed from wk−1 in time nnz(A).

√ p
Corollary 8.1. Choosing η = p/ 60T λmax (B), we
have with prob. ≥ 1 − p:
PT
>
k=1 wk Ak wk ≥ T · λmax (B)
p

T · λmax (B)
· log(d + log(1/p)) .
−O
√
p
(λ-refined language)
√ √
Choosing η = p/ 60T , we have with prob. ≥ 1 − p:
PT
>
k=1 wk Ak wk ≥ T · λmax (B)
√

T
− O √ · log(d + log(1/p)) . (general language)
p
The proof of Theorem 4 uses a potential function analysis
which is similar to the matrix exponential potential used in
MMWU, but compressed to dimension 1.

9

Conclusions

We give a new learning algorithm FTCL for the online
eigenvector problem. It matches the optimum regret obIn the full version, we prove the next theorem in one page:
tained by MMWU, but runs much faster. It matches the fast
Theorem 4. There
exists C > 1 such that, for every
per-iteration running time of FTPL, but has a much smaller
 p
p ∈ (0, 1), if η ∈ 0, p/(60T λmax (B)) in Oja’s algoregret. In the stochastic setting, our side result on Oja’s
rithm, we have with probability at least 1 − p:
algorithm also outperforms previous results. We believe
PT
log(d+log(1/p))
>
. our novel idea of “follow the compressed leader” may find
k=1 wk Ak wk ≥ (1−2η)T ·λmax (B)−C·
η
other applications in the future.

Acknowledgement
We thank Yin Tat Lee for discussing the problem regarding
how to compress MMWU to constant dimension in 2015.
We thank Elad Hazan for suggesting us the problem and
for several insightful discussions. We thank Dan Garber
and Tengyu Ma for clarifying some results of prior work
(Garber et al., 2015).

References
Abernethy, Jacob, Lee, Chansoo, Sinha, Abhinav, and
Tewari, Ambuj. Online linear optimization via smooth-

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

ing. In COLT, pp. 807–823, 2014.
Abernethy, Jacob, Lee, Chansoo, and Tewari, Ambuj.
Spectral smoothing via random matrix perturbations.
ArXiv e-prints, abs/1507.03032, 2015.
Allen-Zhu, Zeyuan and Li, Yuanzhi. LazySVD: Even
Faster SVD Decomposition Yet Without Agonizing
Pain. In NIPS, 2016a.

Cesa-Bianchi, Nicolo and Lugosi, Gabor. Prediction,
Learning, and Games. Cambridge University Press,
Cambridge, 2006. ISBN 9780511546921. doi: 10.1017/
CBO9780511546921.
Dwork, Cynthia, Talwar, Kunal, Thakurta, Abhradeep, and
Zhang, Li. Analyze gauss: optimal bounds for privacypreserving principal component analysis. In STOC, pp.
11–20. ACM, 2014.

Allen-Zhu, Zeyuan and Li, Yuanzhi. First Efficient Convergence for Streaming k-PCA: a Global, Gap-Free, and
Near-Optimal Rate. ArXiv e-prints, abs/1607.07837,
July 2016b.

Frostig, Roy, Ge, Rong, Kakade, Sham M., and Sidford,
Aaron. Un-regularizing: approximate proximal point
and faster stochastic algorithms for empirical risk minimization. In ICML, volume 37, pp. 1–28, 2015. URL
http://arxiv.org/abs/1506.07512.

Allen-Zhu, Zeyuan and Li, Yuanzhi. Doubly Accelerated
Methods for Faster CCA and Generalized Eigendecomposition. In Proceedings of the 34th International Conference on Machine Learning, ICML ’17, 2017.

Garber, Dan and Hazan, Elad. Fast and simple PCA via
convex optimization. ArXiv e-prints, September 2015.

Allen-Zhu, Zeyuan and Yuan, Yang. Improved SVRG
for Non-Strongly-Convex or Sum-of-Non-Convex Objectives. In ICML, 2016.
Allen-Zhu, Zeyuan, Liao, Zhenyu, and Orecchia, Lorenzo.
Spectral Sparsification and Regret Minimization Beyond Multiplicative Updates. In Proceedings of the
47th Annual ACM Symposium on Theory of Computing,
STOC ’15, 2015.
Allen-Zhu, Zeyuan, Lee, Yin Tat, and Orecchia, Lorenzo.
Using optimization to obtain a width-independent, parallel, simpler, and faster positive SDP solver. In Proceedings of the 27th ACM-SIAM Symposium on Discrete
Algorithms, SODA ’16, 2016.

Garber, Dan, Hazan, Elad, and Ma, Tengyu. Online learning of eigenvectors. In Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pp.
560–568, 2015.
Hardt, Moritz and Price, Eric. The noisy power method:
A meta algorithm with applications. In NIPS, pp. 2861–
2869, 2014.
Jain, Rahul, Ji, Zhengfeng, Upadhyay, Sarvagya, and Watrous, John. QIP = PSPACE. Journal of the ACM
(JACM), 58(6):30, 2011.
Karnin, Zohar and Liberty, Edo. Online pca with spectral
bounds. In Proceedings of the 28th Annual Conference
on Computational Learning Theory (COLT), pp. 505–
509, 2015.

Arora, Sanjeev and Kale, Satyen. A combinatorial, primaldual approach to semidefinite programs. In Proceedings
of the thirty-ninth annual ACM symposium on Theory of
computing - STOC ’07, pp. 227, New York, New York,
USA, 2007. ACM Press. ISBN 9781595936318. doi:
10.1145/1250790.1250823.

Kotłowski, Wojciech and Warmuth, Manfred K. Pca with
gaussian perturbations. ArXiv e-prints, abs/1506.04855,
2015.

Arora, Sanjeev, Hazan, Elad, and Kale, Satyen. The Multiplicative Weights Update Method: a Meta-Algorithm
and Applications. Theory of Computing, 8:121–164,
2012. doi: 10.4086/toc.2012.v008a006.

Lin, Hongzhou, Mairal, Julien, and Harchaoui, Zaid.
A Universal Catalyst for First-Order Optimization.
In NIPS, 2015. URL http://arxiv.org/pdf/
1506.02186v1.pdf.

Boutsidis, Christos, Garber, Dan, Karnin, Zohar, and Liberty, Edo. Online principal components analysis. In Proceedings of the Twenty-Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, pp. 887–901. SIAM, 2015.

Nesterov, Yurii. Introductory Lectures on Convex Programming Volume: A Basic course, volume I. Kluwer Academic Publishers, 2004. ISBN 1402075537.

Bunch, James R and Hopcroft, John E. Triangular factorization and inversion by fast matrix multiplication.
Mathematics of Computation, 28(125):231–236, 1974.

Lee, Yin Tat and Sun, He. Constructing linear-sized spectral sparsification in almost-linear time. In FOCS, pp.
250–269. IEEE, 2015.

Nie, Jiazhong, Kotłowski, Wojciech, and Warmuth, Manfred K. Online pca with optimal regrets. In International Conference on Algorithmic Learning Theory, pp.
98–112. Springer, 2013.

Follow the Compressed Leader: Faster Online Learning of Eigenvectors and Faster MMWU

Orecchia, Lorenzo. Fast Approximation Algorithms for
Graph Partitioning using Spectral and SemidefiniteProgramming Techniques. PhD thesis, EECS Department, University of California, Berkeley, May 2011.
Orecchia, Lorenzo, Sachdeva, Sushant, and Vishnoi,
Nisheeth K. Approximating the exponential, the lanczos
e
method and an O(m)-time
spectral algorithm for balanced separator. In STOC ’12. ACM Press, November
2012.
Pan, Victor Y and Chen, Zhao Q. The complexity of the
matrix eigenproblem. In Proceedings of the thirty-first
annual ACM symposium on Theory of computing, pp.
507–516. ACM, 1999.
Peng, Richard and Tangwongsan, Kanat. Faster and simpler width-independent parallel algorithms for positive
semidefinite programming. In Proceedinbgs of the 24th
ACM symposium on Parallelism in algorithms and architectures - SPAA ’12, pp. 101, New York, New York,
USA, January 2012.
Shalev-Shwartz, Shai. SDCA without Duality, Regularization, and Individual Convexity. In ICML, 2016.
Shamir, Ohad. Convergence of stochastic gradient descent
for pca. In ICML, 2016.
Shewchuk, Jonathan Richard. An introduction to the conjugate gradient method without the agonizing pain, 1994.
Wendel, J. G. Note on the gamma function. The American
Mathematical Monthly, 55(9):563–564, 1948.

