Exploiting Strong Convexity from Data with Primal-Dual
First-Order Algorithms
Jialei Wang 1 Lin Xiao 2

Abstract
We consider empirical risk minimization of linear predictors with convex loss functions. Such
problems can be reformulated as convex-concave
saddle point problems and solved by primal-dual
first-order algorithms. However, primal-dual algorithms often require explicit strongly convex
regularization in order to obtain fast linear convergence, and the required dual proximal mapping may not admit closed-form or efficient solution. In this paper, we develop both batch and
randomized primal-dual algorithms that can exploit strong convexity from data adaptively and
are capable of achieving linear convergence even
without regularization. We also present dual-free
variants of adaptive primal-dual algorithms that
do not need the dual proximal mapping, which
are especially suitable for logistic regression.

1. Introduction
We consider the problem of regularized empirical risk minimization (ERM) of linear predictors. Let a1 , . . . , an ∈ Rd
be the feature vectors of n data samples, φi : R → R be
a convex loss function associated with the linear prediction
aTi x, for i = 1, . . . , n, and g : Rd → R be a convex regularization function for the predictor x ∈ Rd . ERM amounts
to solving the following convex optimization problem:
o
n
Pn
def
min
P (x) = n1 i=1 φi (aTi x) + g(x) . (1)
x∈Rd

This formulation covers many well-known classification
and regression problems. For example, logistic regression is obtained by setting φi (z) = log(1 + exp(−bi z))
where bi ∈ {±1}. For linear regression problems, the loss

1
Department of Computer Science, The University of Chicago,
Chicago, Illinois 60637, USA. 2 Microsoft Research, Redmond,
Washington 98052, USA. Correspondence to: Jialei Wang
<jialei@uchicago.edu>, Lin Xiao <lin.xiao@microsoft.com>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

function is φi (z) = (1/2)(z − bi )2 , and we get ridge regression with g(x) = (λ/2)kxk22 and the elastic net with
g(x) = λ1 kxk1 + (λ2 /2)kxk22 .
Let A = [a1 , . . . , an ]T be the n by d data matrix. Throughout this paper, we make the following assumptions:
Assumption 1. The functions φi , g and matrix A satisfy:
• Each φi is δ-strongly convex and 1/γ-smooth where
γ > 0 and δ ≥ 0, and γδ ≤ 1;
• g is λ-strongly convex where λ ≥ 0;
p
• λ + δµ2 > 0, where µ = λmin (AT A).

The strong convexity and smoothness mentioned above are
with respect
√ to the standard Euclidean norm, denoted as
kxk = xT x. (See, e.g., Nesterov (2004, Sections 2.1.1
and 2.1.3) for the exact definitions.) We allow δ = 0, which
simply means φi is convex. Let R = maxi {kai k} and
assuming λ > 0, then R2 /(γλ) is a popular definition of
condition number for analyzing complexities of different
algorithms. The last condition above means that the primal
objective function P (x) is strongly convex, even if λ = 0.
There have been extensive research activities in recent
years on developing efficiently algorithms for solving problem (1). A broad class of randomized algorithms that exploit the finite sum structure in the ERM problem have
emerged as very competitive both in terms of theoretical
complexity and practical performance. They can be put
into three categories: primal, dual, and primal-dual.
Primal randomized algorithms work with the ERM problem (1) directly. They are modern versions of randomized incremental gradient methods (e.g., Bertsekas,
2012; Nedic & Bertsekas, 2001) equipped with variance
reduction techniques.
Each iteration of such algorithms only process one data point ai with complexity
O(d). They includes SAG (Roux et al., 2012), SAGA
(Defazio et al., 2014), and SVRG (Johnson & Zhang,
2013; Xiao & Zhang, 2014), which all achieve
 the iteration complexity O (n + R2 /(γλ)) log(1/ǫ) to find an ǫoptimal solution. In fact, they are capable of exploiting
the strong convexity from data, meaning that the condition
number R2 /(γλ) in the complexity can be replaced by the
more favorable one R2 /(γ(λ+δµ2 /n)). This improvement
can be achieved without explicit knowledge of µ from data.

Exploiting Strong Convexity from Data with Primal-Dual First-Order Algorithms

Dual algorithms solve Fenchel dual of (1) by maximizing

Pn
Pn
def
D(y) = n1 i=1 −φ∗i (yi ) − g ∗ − n1 i=1 yi ai
(2)
using randomized coordinate ascent algorithms. (Here φ∗i
and g ∗ denotes the conjugate functions of φi and g.) They
include SDCA (Shalev-Shwartz & Zhang, 2013), Nesterov
(2012) and Richtárik & Takáč (2014). They
 have the same
complexity O (n + R2 /(γλ)) log(1/ǫ) , but cannot exploit strong convexity, if any (when δµ2 > 0), from data.

Primal-dual algorithms solve the convex-concave saddle
point problem minx maxy L(x, y) where

Pn
def
L(x, y) = n1 i=1 yi hai , xi − φ∗i (yi ) + g(x). (3)

In particular, SPDC (Zhang & Xiao, 2015) achieves an
accelerated linear√convergence
rate with
 iteration com√
plexity O (n + nR/ γλ) log(1/ǫ) , which is better
than the aforementioned non-accelerated complexity when
R2 /(γλ) > n. Lan & Zhou (2015) developed dual-free
variants of accelerated primal-dual algorithms, but without considering the linear predictor structure in ERM.
Balamurugan & Bach (2016) extended SVRG and SAGA
to solving saddle point problems.
Accelerated primal and dual randomized algorithms have
also been developed. Nesterov (2012), Fercoq & Richtárik
(2015) and Lin et al. (2015b) developed accelerated coordinate gradient algorithms, which can be applied to solve the
dual problem (2). Allen-Zhu (2016) developed an accelerated variant of SVRG. Acceleration can also be obtained
et al., 2015a).  They
using the Catalyst framework√ (Lin √
all achieve the same O (n + nR/ γλ) log(1/ǫ) complexity. A common feature of accelerated algorithms is that
they require good estimate of the strong convexity parameter. This makes hard for them to exploit strong convexity
from data because the minimum singular value µ of the data
matrix A is very hard to estimate in general.
In this paper, we show that primal-dual algorithms are capable of exploiting strong convexity from data if the algorithm parameters (such as step sizes) are set appropriately.
While these optimal setting depends on the knowledge of
the convexity parameter µ from the data, we develop adaptive variants of primal-dual algorithms that can tune the parameter automatically. Such adaptive schemes rely critically on the capability of evaluating the primal-dual optimality gaps by primal-dual algorithms.
A major disadvantage of primal-dual algorithms is that the
required dual proximal mapping may not admit closedform or efficient solution. We follow the approach of
Lan & Zhou (2015) to derive dual-free variants of the
primal-dual algorithms customized for ERM problems with
the linear predictor structure, and show that they can also
exploit strong convexity from data with correct choices of
parameters or using an adaptation scheme.

Algorithm 1 Batch Primal-Dual (BPD) Algorithm
input: parameters τ , σ, θ, initial point (x̃(0) = x(0) , y (0) )
for t = 0, 1, 2, . . . do

y (t+1) = proxσf ∗ y (t) + σAx̃(t)

x(t+1) = proxτ g x(t) − τ AT y (t+1)
x̃(t+1) = x(t+1) + θ(x(t+1) − x(t) )
end for

2. Batch primal-dual algorithms
We first study batch primal-dual algorithms, by considering
a “batch” version of the ERM problem (1),

	
def
minx∈Rd P (x) = f (Ax) + g(x) .
(4)

where A ∈ Rn×d . We make the following assumptions:

Assumption 2. The functions f , g and matrix A satisfy:
• f is δ-strongly convex and 1/γ-smooth where γ > 0
and δ ≥ 0, and γδ ≤ 1;

• g is λ-strongly convex where λ ≥ 0;
p
• λ + δµ2 > 0, where µ = λmin (AT A).

Using conjugate functions, we can derive the dual of (4) as

	
def
maxy∈Rn D(y) = −f ∗ (y) − g ∗ (−AT y) , (5)

and the convex-concave saddle point formulation is

	
def
min maxn L(x, y) = g(x) + y T Ax − f ∗ (y) .
x∈Rd y∈R

(6)

We consider the primal-dual first-order algorithm proposed
by Chambolle & Pock (2011; 2016) for solving the saddle
point problem (6), given in Algorithm 1, where proxψ (·),
for any convex function ψ : Rn ∪ {∞}, is defined as

proxψ (β) = arg minn ψ(α) + (1/2)kα − βk2 .
α∈R

Assuming that f is smooth and g is strongly convex,
Chambolle & Pock (2011; 2016) showed that Algorithm 1
achieves accelerated linear convergence rate if λ > 0.
However, they did not consider the case where additional
or the sole source of strong convexity comes from f (Ax).
In the following theorem, we show how to set the parameters τ , σ and θ to exploit both sources of strong convexity
to achieve fast linear convergence.
Theorem 1. Suppose Assumption 2 holds and (x⋆ , y ⋆ ) is
the unique saddle point of L defined in (6). Let L = kAk =
p
λmax (AT A). If we set the parameters in Algorithm 1 as
q
q
2
γ
σ = L1 λ+δµ
, τ = L1 λ+δµ
(7)
2,
γ
and θ = max{θx , θy } where


µ2
1
δ
θx = 1 − (δ+2σ)
2
L
1+τ λ ,

θy =

1
1+σγ/2 ,

(8)

Exploiting Strong Convexity from Data with Primal-Dual First-Order Algorithms

then we have
1
2τ

+

λ
2



kx(t) − x⋆ k2 +

γ
(t)
4 ky

t

− y ⋆ k2 ≤ θ C,

L(x(t) , y ⋆ ) − L(x⋆ , y (t) ) ≤ θt C,


1
1
+ λ2 kx(0) −x⋆ k2 + 2σ
+ γ4 ky (0) −y ⋆ k2 .
where C = 2τ

The proof of Theorem 1 is given in Appendices B and C.
Here we give a detailed analysis of the convergence rate.
Substituting σ and τ in (7) into the expressions for θy and
θx in (8), and assuming γ(λ + δµ2 ) ≪ L2 , we have
−1
 √
q
2
γ(λ+δµ2 )
γ
λ
−
+
γδ
2
θx ≈ 1 − γδµ
2
L
L
L
λ+δµ2 ,
√
γ(λ+δµ2 )
1
θy = √
≈
1
−
.
2L
2
1+

γ(λ+δµ )/(2L)

Since the overall condition number of the problem is
L2
γ(λ+δµ2 ) , it is clear that θy is an accelerated convergence
rate. Next we examine θx in two special cases.
The case of δµ2 = 0 q
but λ > 0. In this case, we have
pγ
1
1
τ = L λ and σ = L λγ , and thus
θx = 1+√1γλ/L ≈ 1−

√

γλ
L ,

1
≈ 1−
θy = 1+√γλ/(2L)

√

γλ
2L .

√

λγ
. This
Therefore we have θ = max{θx , θy } ≈ 1 − 2L
indeed is an accelerated convergence rate, recovering the
result of Chambolle & Pock (2011; 2016).

The case of λ = 0 butq
δµ > 0.
pγ
µ
1
τ = Lµ δ and σ = L γδ , and
2

θx = 1 −

γδµ2
L2

·

In this case, we have

1
√
,
2 γδµ/L+γδ

θy ≈ 1 −

√

γδµ
2L .

2

1 L
Notice that γδ
µ2 is the condition number of f (Ax). Next
we assume µ ≪ L and examine how θx varies with γδ.

• If γδ ≈

µ2
L2 ,

meaning f is badly conditioned, then

θx ≈ 1 −

γδµ2
L2

·

√ 1
3 γδµ/L

=1−

√

γδµ
3L .

Algorithm 2 Adaptive Batch Primal-Dual (Ada-BPD)
input: problem constants λ, γ, δ, L and µ̂ > 0, initial
point (x(0) , y (0) ), and adaptation period T .
Compute σ, τ , and θ as in (7) and (8) using µ = µ̂
for t = 0, 1, 2, . . . do

y (t+1) = proxσf ∗ y (t) + σAx̃(t)

x(t+1) = proxτ g x(t) − τ AT y (t+1)
x̃(t+1) = x(t+1) + θ(x(t+1) − x(t) )
if mod(t + 1, T ) == 0 then

(σ, τ, θ) = BPD-Adapt {P (s) , D(s) }t+1
s=t−T
end if
end for
Algorithm 3 BPD-Adapt (simple heuristic)
input: previous estimate µ̂, adaption period T , primal and
dual objective values {P (s) , D(s) }ts=t−T
if P (t) −√D(t) < θT (P (t−T ) − D(t−T ) ) then
µ̂ := 2µ̂
else
√
µ̂ := µ̂/ 2
end if
Compute σ, τ , and θ as in (7) and (8) using µ = µ̂
output: new parameters (σ, τ, θ)

In summary, the extent of acceleration in the dominating
factor θx (which determines θ) depends on the relative size
of γδ and µ2 /L2 , i.e., the relative conditioning between
the function f and the matrix A. In general, we have full
acceleration if γδ ≤ µ2 /L2 . The theory predicts that the
acceleration degrades as the function f gets better conditioned. However, in our numerical experiments, we often
observe acceleration even if γδ gets closer to 1.
As explained in Chambolle & Pock (2011), Algorithm 1
is equivalent to a preconditioned ADMM. Deng & Yin
(2016) characterized various conditions for ADMM to obtain linear convergence, but did not derive the convergence
rate for the case we consider in this paper.

2

1 L
Because the overall condition number is γδ
µ2 , this is
an accelerated linear rate, and so is θ = max{θx , θy }.

• If γδ ≈

µ
L,

meaning f is mildly conditioned, then

θx ≈ 1 −

µ3
1
L3 2(µ/L)3/2 +µ/L

≈1−

µ2
L2 .

This represents a half-accelerated rate, because the
L3
1 L2
overall condition number is γδ
µ2 ≈ µ3 .

• If γδ = 1, i.e., f is a simple quadratic function, then
θx ≈ 1 −

µ2
1
L2 2µ/L+1

≈1−

µ2
L2 .

This rate does not have acceleration, because the overL2
1 L2
all condition number is γδ
µ2 ≈ µ2 .

2.1. Adaptive batch primal-dual algorithms
In practice, it is often very hard to obtain a good estimate
p of the problem-dependent constants, especially µ =
λmin (AT A), in order to apply the algorithmic parameters specified in Theorem 1. Here we explore heuristics
that can enable adaptive tuning of such parameters, which
often lead to much improved performance in practice.
A key observation is that the convergence rate of the BPD
algorithm changes monotonically with the overall convexity parameter λ + δµ2 , regardless of the extent of acceleration. In other words, the larger λ + δµ2 is, the faster the
convergence. Therefore, if we can monitor the progress of

Exploiting Strong Convexity from Data with Primal-Dual First-Order Algorithms

Algorithm 4 BPD-Adapt (robust heuristic)
input: previous rate estimate ρ > 0, ∆ = δ µ̂2 , period T ,
constants c < 1 and c > 1, and {P (s) , D(s) }ts=t−T
Compute new rate estimate ρ̂ =
if ρ̂ ≤ c ρ then
∆ := 2∆,
ρ := ρ̂
else if ρ̂ ≥ c ρ then
∆ := ∆/2, ρ := ρ̂
else
∆ := ∆
end if q
q
γ
σ = L1 λ+∆
τ = L1 λ+∆
γ ,

P (t) −D (t)
P (t−T ) −D (t−T )

Compute θ using (8) or set θ = 1
output: new parameters (σ, τ, θ)

Algorithm 5 Adaptive SPDC (Ada-SPDC)
input: parameters σ, τ , θ > 0, initial point (x(0) , y (0) ),
and adaptation period T .
Set x̃(0) = x(0)
for t = 0, 1, 2, . . . do
pick k ∈ {1, . . . , n} uniformly at random
for i ∈ {1, . . . , n} do
if i == k then


(t)
(t+1)
yk
= proxσφ∗k yk + σaTk x̃(t)
else
(t+1)
(t)
yi
= yi
end if
end for


(t+1)
(t)
x(t+1) = proxτ g x(t) − τ u(t) + (yk −yk )ak
(t+1)

u(t+1) = u(t) + n1 (yk

the convergence and compare it with the predicted convergence rate in Theorem 1, then we can adjust the estimated
parameters to exploit strong convexity from data. More
specifically, if the observed convergence rate is slower than
the predicted rate, then we should reduce the estimate of µ;
otherwise we should increase µ for faster convergence.
We formalize the above reasoning in Algorithm 2 (called
Ada-BPD). This algorithm maintains an estimate µ̂ of the
true constant µ, and adjust it every T iterations. We use
P (t) and D(t) to represent the primal and dual objective
values at P (x(t) ) and D(y (t) ), respectively. We give two
implementations of the tuning procedure BPD-Adapt: Algorithm 3 is a simple heuristic for tuning the
√ estimate
µ̂, where the increasing and decreasing factor 2 can be
changed to other values larger than 1. Algorithm 4 is a
more robust heuristic. It does not rely on the specific convergence rate θ established in Theorem 1. Instead, it simply
compares the current estimate of objective reduction rate ρ̂
with the previous estimate ρ. It also specifies a non-tuning
range of changes in ρ, specified by the interval [c, c].
The capability of accessing both the primal and dual objective values allows primal-dual algorithms to have good
estimate of the convergence rate, which enables effective
tuning heuristics. Automatic tuning of primal-dual algorithms have also been studied by, e.g., Malitsky & Pock
(2016) and Goldstein et al. (2013), but with different goals.

3. Randomized primal-dual algorithm
In this section, we come back to the ERM problem and consider its saddle-point formulation in (3). Due to its finite
sum structure in the dual variables yi , we can develope randomized algorithms to exploit strong convexity from data.
In particular, we extend the stochastic primal-dual coordinate (SPDC) algorithm by Zhang & Xiao (2015). SPDC is

(t)

− yk )ak

x̃(t+1) = x(t+1) + θ(x(t+1) − x(t) )

if mod(t + 1, T · n) = 0 then

(τ, σ, θ) = SPDC-Adapt {P (t−sn) , D(t−sn) }Ts=0
end if
end for
a special case of the Ada-SPDC algorithm in Algorithm 5,
by setting the adaption period T = ∞ (no adaption). The
following theorem is proved in Appendix E.
Theorem 2. Suppose Assumption 1 holds. Let (x⋆ , y ⋆ ) be
the saddle point of the function L defined in (3), and R =
max{ka1 k, . . . , kan k}. If we set T = ∞ in Algorithm 5
(no adaption) and let
q
q
γ
nλ+δµ2
1
1
,
σ
=
,
(9)
τ = 4R
2
nλ+δµ
4R
γ
and θ = max{θx , θy } where


τ σδµ2
1
θx = 1− 2n(σ+4δ)
1+τ λ , θy =

1+((n−1)/n)σγ/2
,
1+σγ/2

(10)

then we have
  (t)



λ
1
− x⋆ k2 + γ4 E ky (t) − y ⋆ k2 ≤ θt C,
2τ + 2 E kx


E L(x(t) , y ⋆ ) − L(x⋆ , y (t) ) ≤ θt C,


1
1
where C = 2τ
+ λ2 kx(0) −x⋆ k2 + 2σ
+ γ4 ky (0) −y ⋆ k2 .
The expectation E[·] is taken with respect to the history of
random indices drawn at each iteration.
Below we give a detailed discussion on the expected convergence rate established in Theorem 2.
The cases of σµ2 = 0 but
qλ > 0. In this case we have
pγ
1
1
nλ
and
σ
=
τ = 4R
nλ
4R
γ , and
θx =

1
1+τ λ

θy =

1+((n−1)/n)σγ/2
1+σγ/2

=1−

1+4R

√1

n/(λγ)

=1−

,

n+8R

√1

n/(λγ)

.

Exploiting Strong Convexity from Data with Primal-Dual First-Order Algorithms

Hence θ = θy . These recover the parameters and convergence rate of the standard SPDC (Zhang & Xiao, 2015).
The cases of σµ2 > 0 but
qλ = 0.
pγ
µ
δ
1
and
σ
=
τ = 4Rµ
δ
4R
γ , and
θx = 1 −

θy = 1 −

τ σδµ2
2n(σ+4δ)

In this case we have

γδµ2
1
√
32nR2 · γδµ/(4R)+4γδ .

−1
√
√
γδµ
γδµ
1 √
1
+
≈
1
−
8nR
8R
n+8nR/(µ γδ)

=1−

.

Since the objective is R2 /γ-smooth√ and δµ2 /n-strongly
γδµ
convex, θy is an accelerated rate if 8R
≪ 1 (otherwise
1
θy ≈ 1 − n ). For θx , we consider different situations:
•
•

√

γδµ
If µ ≥ R, then we have θx ≈ 1− nR
, which is an
accelerated rate. So is θ = max{θx , θy }.
√
γδµ
µ2
If µ < R and γδ ≈ R
2 , then θx ≈ 1− nR , which

represents an accelerated rate. The iteration complexe nR
√ ), which is better than that of
ity of SPDC is O(
µ γδ
e nR22 ).
SVRG in this case, which is O(
γδµ

2

µ
µ
, then we get θx ≈ 1− nR
• If µ < R and γδ ≈ R
2 . This
is a half-accelerated rate, because in this case SVRG
e nR33 ) iterations, versus O(
e nR22 ) for SPDC.
requires O(
µ
µ

• If µ < R and γδ ≈ 1, meaning the φi ’s are well
2
µ2
conditioned, then we get θx ≈ 1 − γδµ
nR2 ≈ 1 − nR2 ,
which is a non-accelerated rate. The corresponding
iteration complexity is the same as SVRG.

3.1. Parameter adaptation for SPDC
The SPDC-Adapt procedure called in Algorithm 5 follows
the same logics as the batch adaption schemes in Algorithms 3 and 4, and we omit the details here. One thing we
emphasize here is that the adaptation period T is in terms
of epochs, or number of passes over the data. In addition,
we only compute the primal and dual objective values after each pass or every few passes, because computing them
exactly usually need to take a full pass of the data.
Unlike the batch case where the duality gap decreases
monotonically, the duality gap for randomized algorithms
can fluctuate wildly.
So instead of using only the
two end values P (t−T n) − D(t−T n) and P (t) − D(t) ,
we can use more points to estimate the convergence
rate through a linear regression. Suppose the primaldual objective values for the last T + 1 passes are
(P (0), D(0)), (P (1), D(1)), . . . , (P (T ), D(T )), and we
need to estimate ρ (rate per pass) such that

P (t) − D(t) ≈ ρt P (0) − D(0) , t = 1, . . . , T.
We can turn it into a linear regression problem after taking
logarithm and obtain the estimate ρ̂ through
PT
P (t)−D(t)
1
log(ρ̂) = 12 +22 +···+T
2
t=1 t log P (0)−D(0) .

Algorithm 6 Dual-Free BPD Algorithm
input: parameters σ, τ , θ > 0, initial point (x(0) , y (0) )
Set x̃(0) = x(0) and v (0) = (f ∗ )′ (y (0) )
for t = 0, 1, 2, . . . do
(t)
(t)
v (t+1) = v +σAx̃
, y (t+1) = f ′ (v (t+1) )
1+σ

(t+1)
(t)
x
= proxτ g x − τ AT y (t+1)
x̃(t+1) = x(t+1) + θ(x(t+1) − x(t) )
end for

4. Dual-free Primal-dual algorithms
Compared with primal algorithms, one major disadvantage
of primal-dual algorithms is the requirement of computing
the proximal mapping of the dual function f ∗ or φ∗i , which
may not admit closed-formed solution or efficient computation. This is especially the case for logistic regression, one
of the most popular loss functions used in classification.
Lan & Zhou (2015) developed “dual-free” variants of
primal-dual algorithms that avoid computing the dual proximal mapping. Their main technique is to replace the Euclidean distance in the dual proximal mapping with a Bregman divergence defined over the dual loss function itself.
We show how to apply this approach to solve the structured ERM problems considered in this paper. They can
also exploit strong convexity from data if the algorithmic
parameters are set appropriately or adapted automatically.
4.1. Dual-free BPD algorithm
First, we consider the batch setting. We replace the dual
proximal mapping (computing y (t+1) ) in Algorithm 1 with

	
y (t+1) = arg min f ∗ (y)−y T Ax̃(t) + σ1 D(y, y (t) ) , (11)
y

where D is the Bregman divergence of a strictly convex
kernel function h, defined as
Dh (y, y (t) ) = h(y) − h(y (t) ) − h∇h(y (t) ), y − y (t) i.

Algorithm 1 is obtained in the Euclidean setting with
h(y) = 21 kyk2 and D(y, y (t) ) = 12 ky−y (t) k2 . Here we use
f ∗ as the kernel function, and show that it allows us to compute y (t+1) in (11) very efficiently. The following lemma
explains the details (Cf. Lan & Zhou, 2015, Lemma 1).
Lemma 1. Let the kernel h ≡ f ∗ in the Bregman divergence D. If we construct a sequence of vectors {v (t) } such
that v (0) = (f ∗ )′ (y (0) ) and for all t ≥ 0,
v (t+1) =

v (t) +σAx̃(t)
,
1+σ

(12)

then the solution to problem (11) is y (t+1) = f ′ (v (t+1) ).
Proof. Suppose v (t) = (f ∗ )′ (y (t) ) (true for t = 0), then
T

D(y, y (t) ) = f ∗ (y) − f ∗ (y (t) ) − v (t) (y − y (t) ).

Exploiting Strong Convexity from Data with Primal-Dual First-Order Algorithms

The solution to (11) can be written as
o
n
T 
y (t+1) = arg min f ∗ (y)−y T Ax̃(t) + σ1 f ∗ (y)−v (t) y
y
n

T o
= arg min 1 + σ1 f ∗ (y) − Ax̃(t) + σ1 v (t) y
y

n

T

o
y − f ∗ (y)
y
o
n
T
= arg max v (t+1) y − f ∗ (y) = f ′ (v (t+1) ),
= arg max

v (t) +σAx̃(t)
1+σ

where in the last equality we used the property of conjugate
function when f is strongly convex and smooth. Moreover,
v (t+1) = (f ′ )−1 (y (t+1) ) = (f ∗ )′ (y (t+1) ),
which completes the proof.
According to Lemma 1, we only need to provide initial
points such that v (0) = (f ∗ )′ (y (0) ) is easy to compute. We
do not need to compute (f ∗ )′ (y (t) ) directly for any t > 0,
because it is can be updated as v (t) in (12). Consequently,
we can update y (t) in the BPD algorithm using the gradient
f ′ (v (t) ), without the need of dual proximal mapping. The
resulting dual-free algorithm is given in Algorithm 6.
Theorem 3. Suppose Assumption 2 holds and let (x⋆ , y ⋆ )
be the unique saddle point of L defined in (6). If we set the
parameters in Algorithm 6 as
q
p
γ
τ = L1 λ+δµ
(13)
σ = L1 γ(λ + δµ2 ),
2,
θy =

1
1+σ/2 ,

(14)

then we have
1
2τ

+

λ
2



kx(t) − x⋆ k2 + 12 D(y ⋆ , y (t) ) ≤ θt C,

L(x(t) , y ⋆ ) − L(x⋆ , y (t) ) ≤ θt C,


1
+ λ2 kx(0) − x⋆ k2 + σ1 + 12 D(y ⋆ , y (0) ).
where C = 2τ

Theorem 3 is proved in Appendices B and D. Assuming
γ(λ + δµ2 ) ≪ L2 , we have
√
q
γ(λ+δµ2 )
γδµ2
γ
λ
θx ≈ 1 − 16L
,
θ
≈
1
−
.
2 − 2L
2
y
λ+δµ
4L
Again, we gain insights by consider the special cases:
√

γλ
4L

and θx ≈
• If δµ2 = 0 and λ > 0, then θy ≈ 1 −
√
γλ
1 − 2L
. So θ = max{θx , θy } is an accelerated rate.
√ 2
γδµ
2
• If δµ > 0 and λ = 0, then θy ≈ 1 − 4L and
2

input: parameters σ, τ , θ > 0, initial point (x(0) , y (0) ),
and adaptation period T .
(0)

2

γδµ
γδµ
θx ≈ 1 − 16L
2 . Thus θ = max{θx , θy } ≈ 1 − 16L2 is
not accelerated. This conclusion does not depends on
the relative sizes of γδ and µ2 /L2 , and it is the major
difference from the Euclidean case in Section 2.

(0)

Set x̃(0) = x(0) and vi = (φ∗i )′ (yi ) for i = 1, . . . , n
for t = 0, 1, 2, . . . do
pick k ∈ {1, . . . , n} uniformly at random
for i ∈ {1, . . . , n} do
if i == k then
(t+1)

y

and θ = max{θx , θy } where


τ σδµ2
1
θx = 1 − (4+2σ)
1+τ λ ,

Algorithm 7 Adaptive Dual-Free SPDC (ADF-SPDC)

v

(t)

+σaT x̃(t)

(t+1)

(t+1)

, yk
= φ′k (vk
)
vk
= k 1+σk
else
(t+1)
(t)
(t+1)
(t)
vi
= v i , yi
= yi
end if
end for


(t+1)
(t)
x(t+1) = proxτ g x(t) − τ u(t) + (yk −yk )ak
(t+1)

u(t+1) = u(t) + n1 (yk

(t)

− yk )ak

x̃(t+1) = x(t+1) + θ(x(t+1) − x(t) )

if mod(t + 1, T · n) = 0 then

(τ, σ, θ) = SPDC-Adapt {P (t−sn) , D(t−sn) }Ts=0
end if
end for
If both δµ2 > 0 and λ > 0, then the extent of acceleration
depends on their relative size. If λ is on the same order as
δµ2 or larger, then accelerated rate is obtained. If λ is much
smaller than δµ2 , then the theory predicts no acceleration.
4.2. Dual-free SPDC algorithm
Following the same approach, we can derive an Adaptive Dual-Free SPDC algorithm, given in Algorithm 7.
On related work, Shalev-Shwartz & Zhang (2016) and
(Shalev-Shwartz, 2016) introduced dual-free SDCA.
The following theorem characterizes the choice of algorithmic parameters that can exploit strong convexity from data
to achieve linear convergence (proof given in Appendix F).
Theorem 4. Suppose Assumption 1 holds. Let (x⋆ , y ⋆ ) be
the saddle point of L in (3) and R = max{ka1 k, . . . , kan k}.
If we set T = ∞ in Algorithm 7 (non adaption) and let
q
p
γ
1
1
σ = 4R
γ(nλ + δµ2 ), τ = 4R
(15)
nλ+δµ2 ,
and θ = max{θx , θy } where


τ σδµ2
1
θx = 1 − n(4+2σ)
1+τ λ ,

θy =

1+((n−1)/n)σ/2
,
1+σ/2

(16)
then we have


  (t)

λ
1
− x⋆ k2 + γ4 E D(y ⋆ , y (t) ) ≤ θt C,
2τ + 2 E kx


E L(x(t) , y ⋆ ) − L(x⋆ , y (t) ) ≤ θt C,


1
where C = 2τ
+ λ2 kx(0) − x⋆ k2 + σ1 + 12 D(y ⋆ , y (0) ).

Primal optimality gap

Exploiting Strong Convexity from Data with Primal-Dual First-Order Algorithms

10

Primal AG
BPD
Opt-BPD
Ada-BPD

-5

10 -10

0

20

40

60

10 -5

10 -5

10 -10

10 -10

80

0

100

Number of passes

200

300

400

500

0

Number of passes

synthetic1, λ = 1/n

200

400

600

800

1000

Number of passes

synthetic1, λ = 10−2 /n

synthetic1, λ = 10−4 /n

Primal optimality gap

Figure 1. Comparison of batch primal-dual algorithms for a ridge regression problem with n = 5000 and d = 3000.

SVRG
SAGA
Katyusha
SPDC
DF-SPDC
ADF-SPDC

10 0

10 -5

10

-10

10 0

10 0

10 -5

10 -5

10
0

20

40

60

-10

80

10
0

100

Number of passes

200

300

Number of passes

cpuact, λ = 1/n

cpuact, λ = 10−2 /n

400

-10

0

200

400

600

800

1000

Number of passes

cpuact, λ = 10−4 /n

Figure 2. Comparison of randomized algorithms for ridge regression problems.

Now we discuss the results of Theorem 4 in further details.
The cases
σµ2 = 0 but
p of
√ λ > 0. In this case we have
γ
1
1
nγλ, and
τ = 4R nλ and σ = 4R
θx = 1 −

1+4R

√1

n/(λγ)

,

θy = 1 −

n+8R

√1

n/(λγ)

.

The rate is the same as for SPDC in Zhang & Xiao (2015).
The cases
σµ2 > 0 but
λ = 0. In this case we have
pof
γ
µ √
1
τ = 4Rµ δ and σ = 4R
δγ, thus
θx = 1 −
θy =

τ σδµ2
2n(σ+4)

=1−

1+((n−1)/n)σ/2
1+σ/2

γδµ2
32nR2

=1−

·

√

1
,
γδµ/(4R)+4

1 √
.
n+8nR/(µ γδ)

We note that the primal function now is R2 /γ-smooth and
δµ2 /n-strongly convex. We discuss the following cases:
√
√
γδµ
• If γδµ > R, then we have θx ≈ 1 − 8nR
and
1
θy ≈ 1 − n . Therefore θ = max{θx , θy } ≈ 1 − n1 .
γδµ2
64nR2

• Otherwise, we have θx ≈ 1 −
and θy is of the
same order. This is not an accelerated rate, and we
have the same iteration complexity as SVRG.

Finally, we give concrete examples of how to compute the
(0)
(0)
initial points y (0) and v (0) such that vi = (φ∗i )′ (yi ).

• For squared loss, φi (α) = 21 (α − bi )2 and φ∗i (β) =
(0)
(0)
(0)
1 2
= (φ∗i )′ (yi ) = yi + bi .
2 β + bi β. So vi
• For logistic regression, we have bi ∈ {1, −1} and
φi (α) = log(1 + e−bi α ). The conjugate function is
φ∗i (β) = (−bi β) log(−bi β) + (1 + bi β) log(1 + bi β)
if bi β ∈ [−1, 0] and +∞ otherwise. We can choose
(0)
(0)
(0)
(0)
yi = − 12 bi and vi = 0 such that vi = (φ∗i )′ (yi ).
For logistic regression, we have δ = 0 over the full domain of φi . However, each φi is locally strongly convex
in bounded domain (Bach, 2014): if z ∈ [−B, B], then
we know δ = minz φi ′′ (z) ≥ exp(−B)/4. Therefore it
is well suitable for an adaptation scheme similar to Algorithm 4 that do not require knowledge of either δ or µ.

5. Preliminary experiments
We present preliminary experiments to demonstrate the effectiveness of our proposed algorithms. First, we consider
batch primal-dual algorithms for ridge regression over a
synthetic dataset. The data matrix A has sizes n = 5000
and d = 3000, and its entries are sampled from multivariate normal distribution with mean zero and covariance matrix Σij = 2|i−j|/2 . We normalize all datasets

Primal optimality gap

Exploiting Strong Convexity from Data with Primal-Dual First-Order Algorithms

10

10 0

SVRG
SAGA
Katyusha
SPDC
DF-SPDC
ADF-SPDC

-5

10 -5

10 -10

10 -5

10 -10

0

20

40

60

80

10 -10

0

Number of passes

Primal optimality gap

400

600

800

1000

0

200

Number of passes

synthetic2, λ = 1/n

400

600

800

1000

Number of passes

synthetic2, λ = 10−2 /n

SVRG
SAGA
Katyusha
SPDC
DF-SPDC
ADF-SPDC

10 -5

200

synthetic2, λ = 10−4 /n
10 0

10 -5

10
10 -10

-5

10 -10

0

20

40

60

Number of passes

rcv1, λ = 1/n

80

0

100

200

300

400

Number of passes

rcv1, λ = 10−2 /n

500

0

100

200

300

400

500

Number of passes

rcv1, λ = 10−4 /n

Figure 3. Comparison of randomized algorithms for logistic regression problems.

such that ai = ai / (maxj kaj k), to ensure the maximum
norm of the data points is 1. We use ℓ2 -regularization
g(x) = (λ/2)kxk2 with three choices of parameter λ: 1/n,
10−2 /n and 10−4 /n, which represent the strong, medium,
and weak levels of regularization, respectively.
Figure 1 shows the performance of four different algorithms: the primal accelerated gradient (Primal AG) algorithm (Nesterov, 2004) using λ as strong convexity parameter, the BPD algorithm (Algorithm 1) that uses the same
λ and µ2 δ = 0, the optimal BPD algorithm (Opt-BPD)
T
A)
that uses µ2 δ = λmin (A
≈ 0.022
computed from data,
n
n
and the Ada-BPD algorithm (Algorithm 2) with the robust
adaptation heuristic (Algorithm 4) with T = 10, c = 0.95
and c = 1.5. As expected, the performance of Primal-AG
is very similar to that of BPD, and Opt-BPD has the fastest
convergence. The Ada-BPD algorithm can partially exploit
strong convexity from data without knowledge of µ.
Next we compare DF-SPDC (Algorithm 5 without adaption) and ADF-SPDC (Algorithm 7 with adaption) against
several state-of-the-art randomized algorithms for ERM:
SVRG (Johnson & Zhang, 2013), SAGA (Defazio et al.,
2014) Katyusha (Allen-Zhu, 2016) and the standard SPDC
method (Zhang & Xiao, 2015). For SVRG and Katyusha
(an accelerated variant of SVRG), we choose the variance
reduction period as m = 2n. The step sizes of all algorithms are set as their original paper suggested. For

Ada-SPDC and ADF-SPDC, we use the robust adaptation
scheme with T = 10, c = 0.95 and c = 1.5.
We first compare these randomized algorithms for ridge regression over the cpuact data from the LibSVM website
(https://www.csie.ntu.edu.tw/˜cjlin/libsvm/).
The results are shown in Figure 2. With relatively strong
regularization λ = 1/n, all methods perform similarly as
predicted by theory. When λ becomes smaller, the nonaccelerated algorithms (SVRG and SAGA) automatically
exploit strong convexity from data, so they become faster
than the non-adaptive accelerated methods (Katyusha,
SPDC and DF-SPDC). The adaptive accelerated method,
ADF-SPDC, has the fastest convergence. This indicates
that our theoretical results, which predict no acceleration
in this case, may be further improved.
Finally we compare these algorithms for logistic regression on the rcv1 dataset (from LibSVM website) and another synthetic dataset with n = 5000 and d = 500,
generated similarly as before but with covariance matrix
Σij = 2|i−j|/100 . For the standard SPDC, we compute the
coordinate-wise dual proximal mapping using a few steps
of scalar Newton’s method to high precision. The dualfree SPDC algorithms only use gradients of the logistic
function. The results are presented in Figure 3. For both
datasets, the strong convexity from data is very weak, and
the accelerated algorithms performs better.

Exploiting Strong Convexity from Data with Primal-Dual First-Order Algorithms

References
Allen-Zhu, Zeyuan. Katyusha: Accelerated variance reduction for faster sgd. ArXiv e-print 1603.05953, 2016.
Bach, Francis. Adaptivity of averaged stochastic gradient
descent to local strong convexity for logistic regression.
Journal of Machine Learning Research, 15(1):595–627,
2014.
Balamurugan, Palaniappan and Bach, Francis. Stochastic
variance reduction methods for saddle-point problems.
In Advances in Neural Information Processing Systems
(NIPS) 29, pp. 1416–1424, 2016.
Bertsekas, Dimitri P. Incremental gradient, subgradient,
and proximal methods for convex optimization: A survey. In Sra, Suvrit, Nowozin, Sebastian, and Wright,
Stephen J. (eds.), Optimization for Machine Learning,
chapter 4, pp. 85–120. MIT Press, 2012.
Chambolle, Antonin and Pock, Thomas. A first-order
primal-dual algorithm for convex problems with applications to imaging. Journal of Mathematical Imaging
and Vision, 40(1):120–145, 2011.

Lin, Hongzhou, Mairal, Julien, and Harchaoui, Zaid. A
universal catalyst for first-order optimization. In Advances in Neural Information Processing Systems, pp.
3384–3392, 2015a.
Lin, Qihang, Lu, Zhaosong, and Xiao, Lin. An accelerated randomized proximal coordinate gradient method
and its application to regularized empirical risk minimization. SIAM Journal on Optimization, 25(4):2244–
2273, 2015b.
Malitsky, Yura and Pock, Thomas.
A first-order
primal-dual algorithm with linesearch. arXiv preprint
arXiv:1608.08883, 2016.
Nedic, Angelia and Bertsekas, Dimitri P. Incremental
subgradient methods for nondifferentiable optimization.
SIAM Journal on Optimization, 12(1):109–138, 2001.
Nesterov, Yurii. Introductory Lectures on Convex Optimization: A Basic Course. Kluwer, Boston, 2004.
Nesterov, Yurii. Efficiency of coordinate descent methods
on huge-scale optimization problems. SIAM Journal on
Optimization, 22(2):341–362, 2012.

Chambolle, Antonin and Pock, Thomas. On the ergodic
convergence rates of a first-order primal–dual algorithm.
Mathematical Programming, Series A, 159:253–287,
2016.

Richtárik, Peter and Takáč, Martin. Iteration complexity of
randomized block-coordinate descent methods for minimizing a composite function. Mathematical Programming, 144(1-2):1–38, 2014.

Defazio, Aaron, Bach, Francis, and Lacoste-Julien, Simon.
Saga: A fast incremental gradient method with support
for non-strongly convex composite objectives. In Advances in Neural Information Processing Systems, pp.
1646–1654, 2014.

Roux, Nicolas L, Schmidt, Mark, and Bach, Francis. A
stochastic gradient method with an exponential convergence rate for finite training sets. In Advances in Neural
Information Processing Systems, pp. 2663–2671, 2012.

Deng, Wei and Yin, Wotao. On the global and linear convergence of the generalized alternating direction method
of multipliers. Journal of Scientific Computing, 66(3):
889–916, 2016.

Shalev-Shwartz, Shai. SDCA without duality, regularization, and individual convexity. In Proceedings of The
33rd International Conference on Machine Learning,
pp. 747–754, 2016.

Fercoq, Oliver and Richtárik, Peter. Accelerated, parallel,
and proximal coordinate descent. SIAM Journal on Optimization, 25(4):1997–2023, 2015.

Shalev-Shwartz, Shai and Zhang, Tong. Stochastic dual coordinate ascent methods for regularized loss minimization. Journal of Machine Learning Research, 14(Feb):
567–599, 2013.

Goldstein, Tom, Li, Min, Yuan, Xiaoming, Esser, Ernie,
and Baraniuk, Richard. Adaptive primal-dual hybrid gradient methods for saddle-point problems. arXiv preprint
arXiv:1305.0546, 2013.

Shalev-Shwartz, Shai and Zhang, Tong. Accelerated proximal stochastic dual coordinate ascent for regularized loss
minimization. Mathematical Programming, 155(1-2):
105–145, 2016.

Johnson, Rie and Zhang, Tong. Accelerating stochastic
gradient descent using predictive variance reduction. In
Advances in Neural Information Processing Systems, pp.
315–323, 2013.

Xiao, Lin and Zhang, Tong. A proximal stochastic gradient method with progressive variance reduction. SIAM
Journal on Optimization, 24(4):2057–2075, 2014.

Lan, Guanghui and Zhou, Yi. An optimal randomized incremental gradient method.
arXiv preprint
arXiv:1507.02000, 2015.

Zhang, Yuchen and Xiao, Lin. Stochastic primal-dual coordinate method for regularized empirical risk minimization. In Proceedings of The 32nd International Conference on Machine Learning, pp. 353–361, 2015.

