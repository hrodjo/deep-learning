Learning Important Features Through Propagating Activation Differences

Avanti Shrikumar 1 Peyton Greenside 1 Anshul Kundaje 1

Abstract
The purported ‚Äúblack box‚Äù nature of neural
networks is a barrier to adoption in applications where interpretability is essential. Here
we present DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the
output prediction of a neural network on a specific input by backpropagating the contributions
of all neurons in the network to every feature
of the input. DeepLIFT compares the activation of each neuron to its ‚Äòreference activation‚Äô
and assigns contribution scores according to the
difference. By optionally giving separate consideration to positive and negative contributions,
DeepLIFT can also reveal dependencies which
are missed by other approaches. Scores can
be computed efficiently in a single backward
pass. We apply DeepLIFT to models trained
on MNIST and simulated genomic data, and
show significant advantages over gradient-based
methods. Video tutorial: http://goo.gl/
qKb7pL, code: http://goo.gl/RM8jvH.

1. Introduction
As neural networks become increasingly popular, their
black box reputation is a barrier to adoption when interpretability is paramount. Here, we present DeepLIFT
(Deep Learning Important FeaTures), a novel algorithm
to assign importance score to the inputs for a given output. Our approach is unique in two regards. First, it
frames the question of importance in terms of differences
from a ‚Äòreference‚Äô state, where the ‚Äòreference‚Äô is chosen
according to the problem at hand. In contrast to most
gradient-based methods, using a difference-from-reference
allows DeepLIFT to propagate an importance signal even
in situations where the gradient is zero and avoids artifacts
caused by discontinuities in the gradient. Second, by op1
Stanford University, Stanford, California, USA. Correspondence to: A Kundaje <akundaje@stanford.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

tionally giving separate consideration to the effects of positive and negative contributions at nonlinearities, DeepLIFT
can reveal dependencies missed by other approaches. As
DeepLIFT scores are computed using a backpropagationlike algorithm, they can be obtained efficiently in a single
backward pass after a prediction has been made.

2. Previous Work
This section provides a review of existing approaches to assign importance scores for a given task and input example.
2.1. Perturbation-Based Forward Propagation
Approaches
These approaches make perturbations to individual inputs
or neurons and observe the impact on later neurons in the
network. Zeiler & Fergus (Zeiler & Fergus, 2013) occluded
different segments of an input image and visualized the
change in the activations of later layers. ‚ÄúIn-silico mutagenesis‚Äù (Zhou & Troyanskaya, 2015) introduced virtual
mutations at individual positions in a genomic sequence
and quantified the their impact on the output. Zintgraf et
al. (Zintgraf et al., 2017) proposed a clever strategy for
analyzing the difference in a prediction after marginalizing
over each input patch. However, such methods can be computationally inefficient as each perturbation requires a separate forward propagation through the network. They may
also underestimate the importance of features that have saturated their contribution to the output (Fig. 1).
2.2. Backpropagation-Based Approaches
Unlike perturbation methods, backpropagation approaches
propagate an importance signal from an output neuron
backwards through the layers to the input in one pass, making them efficient. DeepLIFT is one such approach.
2.2.1. G RADIENTS , D ECONVOLUTIONAL N ETWORKS
AND G UIDED BACKPROPAGATION
Simonyan et al. (Simonyan et al., 2013) proposed using
the gradient of the output w.r.t. pixels of an input image
to compute a ‚Äúsaliency map‚Äù of the image in the context
of image classification tasks. The authors showed that this
was similar to deconvolutional networks (Zeiler & Fergus,

DeepLIFT: Learning Important Features Through Propagating Activation Differences

tor to an elementwise product between the saliency maps of
Simonyan et al. and the input (in other words, gradient √ó
input). In our experiments, we compare DeepLIFT to gradient √ó input as the latter is easily implemented on a GPU,
whereas LRP does not currently have GPU implementations available to our knowledge.

Figure 1. Perturbation-based approaches and gradient-based
approaches fail to model saturation. Illustrated is a simple network exhibiting saturation in the signal from its inputs. At the
point where i1 = 1 and i2 = 1, perturbing either i1 or i2 to 0 will
not produce a change in the output. Note that the gradient of the
output w.r.t the inputs is also zero when i1 + i2 > 1.

2013) except for the handling of the nonlinearity at rectified
linear units (ReLUs). When backpropagating importance
using gradients, the gradient coming into a ReLU during
the backward pass is zero‚Äôd out if the input to the ReLU
during the forward pass is negative. By contrast, when
backpropagating an importance signal in deconvolutional
networks, the importance signal coming into a ReLU during the backward pass is zero‚Äôd out if and only if it is negative, with no regard to sign of the input to the ReLU during the forward pass. Springenberg et al., (Springenberg
et al., 2014) combined these two approaches into Guided
Backpropagation, which zero‚Äôs out the importance signal
at a ReLU if either the input to the ReLU during the forward pass is negative or the importance signal during the
backward pass is negative. Guided Backpropagation can be
thought of as equivalent to computing gradients, with the
caveat that any gradients that become negative during the
backward pass are discarded at ReLUs. Due to the zero-ing
out of negative gradients, both guided backpropagation and
deconvolutional networks can fail to highlight inputs that
contribute negatively to the output. Additionally, none of
the three approaches would address the saturation problem
illustrated in Fig. 1, as the gradient of y w.r.t. h is negative
(causing Guided Backprop and deconvolutional networks
to assign zero importance), and the gradient of h w.r.t both
i1 and i2 is zero when i1 + i2 > 1 (causing both gradients
and Guided Backprop to be zero). Discontinuities in the
gradients can also cause undesirable artifacts (Fig. 2).
2.2.2. L AYERWISE R ELEVANCE P ROPAGATION AND
G RADIENT √ó INPUT
Bach et al. (Bach et al., 2015) proposed an approach for
propagating importance scores called Layerwise Relevance
Propagation (LRP). Shrikumar et al. and Kindermans et al.
(Shrikumar et al., 2016; Kindermans et al., 2016) showed
that absent modifications to deal with numerical stability,
the original LRP rules were equivalent within a scaling fac-

While gradient √ó input is often preferable to gradients
alone as it leverages the sign and strength of the input, it
still does not address the saturation problem in Fig. 1 or
the thresholding artifact in Fig. 2.
2.2.3. I NTEGRATED G RADIENTS
Instead of computing the gradients at only the current value
of the input, one can integrate the gradients as the inputs
are scaled up from some starting value (eg: all zeros) to
their current value (Sundararajan et al., 2016). This addressess the saturation and thresholding problems of Fig.
1 and Fig. 2, but numerically obtaining high-quality integrals adds computational overhead. Further, this approach
can still give misleading results (see Section 3.4.3).
2.3. Grad-CAM and Guided CAM
Grad-CAM (Selvaraju et al., 2016) computes a coarsegrained feature-importance map by associating the feature
maps in the final convolutional layer with particular classes
based on the gradients of each class w.r.t. each feature
map, and then using the weighted activations of the feature maps as an indication of which inputs are most important. To obtain more fine-grained feature importance, the
authors proposed performing an elementwise product between the scores obtained from Grad-CAM and the scores
obtained from Guided Backpropagation, termed Guided
Grad-CAM. However, this strategy inherits the limitations
of Guided Backpropagation caused by zero-ing out negative gradients during backpropagation. It is also specific to
convolutional neural networks.

3. The DeepLIFT Method
3.1. The DeepLIFT Philosophy
DeepLIFT explains the difference in output from some ‚Äòreference‚Äô output in terms of the difference of the input from
some ‚Äòreference‚Äô input. The ‚Äòreference‚Äô input represents
some default or ‚Äòneutral‚Äô input that is chosen according to
what is appropriate for the problem at hand (see Section
3.3 for more details). Formally, let t represent some target output neuron of interest and let x1 , x2 , ..., xn represent
some neurons in some intermediate layer or set of layers
that are necessary and sufficient to compute t. Let t0 represent the reference activation of t. We define the quantity
‚àÜt to be the difference-from-reference, that is ‚àÜt = t ‚àí t0 .
DeepLIFT assigns contribution scores C‚àÜxi ‚àÜt to ‚àÜxi s.t.:

DeepLIFT: Learning Important Features Through Propagating Activation Differences
n
X

C‚àÜxi ‚àÜt = ‚àÜt

(1)

i=1

We call Eq. 1 the summation-to-delta property. C‚àÜxi ‚àÜt
can be thought of as the amount of difference-fromreference in t that is attributed to or ‚Äòblamed‚Äô on the
difference-from-reference of xi . Note that when a neuron‚Äôs
transfer function is well-behaved, the output is locally linear in its inputs, providing additional motivation for Eq. 1.
‚àÇt
is zero. This alC‚àÜxi ‚àÜt can be non-zero even when ‚àÇx
i
lows DeepLIFT to address a fundamental limitation of gradients because, as illustrated in Fig. 1, a neuron can be signaling meaningful information even in the regime where its
gradient is zero. Another drawback of gradients addressed
by DeepLIFT is illustrated in Fig. 2, where the discontinuous nature of gradients causes sudden jumps in the importance score over infinitesimal changes in the input. By contrast, the difference-from-reference is continuous, allowing
DeepLIFT to avoid discontinuities caused by bias terms.

‚àÇt
idea of partial derivatives: the partial derivative ‚àÇx
is the
infinitesimal change in t caused by an infinitesimal change
in x, divided by the infinitesimal change in x. The multiplier is similar in spirit to a partial derivative, but over finite
differences instead of infinitesimal ones.

3.2.2. T HE C HAIN RULE F OR M ULTIPLIERS
Assume we have an input layer with neurons x1 , ..., xn , a
hidden layer with neurons y1 , ..., yn , and some target output neuron t. Given values for m‚àÜxi ‚àÜyj and m‚àÜyj ‚àÜt ,
the following definition of m‚àÜxi ‚àÜt is consistent with the
summation-to-delta property in Eq. 1 (see Appendix A for
the proof):
m‚àÜxi ‚àÜt =

X

m‚àÜxi ‚àÜyj m‚àÜyj ‚àÜt

(3)

j

We refer to Eq. 3 as the chain rule for multipliers. Given
the multipliers for each neuron to its immediate successors,
we can compute the multipliers for any neuron to a given
target neuron efficiently via backpropagation - analogous
to how the chain rule for partial derivatives allows us to
compute the gradient w.r.t. the output via backpropagation.
3.3. Defining the Reference
When formulating the DeepLIFT rules described in Section 3.5, we assume that the reference of a neuron is its
activation on the reference input. Formally, say we have a
neuron y with inputs x1 , x2 , ... such that y = f (x1 , x2 , ...).
Given the reference activations x01 , x02 , ... of the inputs, we
can calculate the reference activation y 0 of the output as:

Figure 2. Discontinuous gradients can produce misleading importance scores. Response of a single rectified linear unit with a
bias of ‚àí10. Both gradient and gradient√óinput have a discontinuity at x = 10; at x = 10 + , gradient√óinput assigns a contribution of 10 +  to x and ‚àí10 to the bias term ( is a small positive
number). When x < 10, contributions on x and the bias term are
both 0. By contrast, the difference-from-reference (red arrow, top
figure) gives a continuous increase in the contribution score.

3.2. Multipliers and the Chain Rule
3.2.1. D EFINITION OF M ULTIPLIERS
For a given input neuron x with difference-from-reference
‚àÜx, and target neuron t with difference-from-reference ‚àÜt
that we wish to compute the contribution to, we define the
multiplier m‚àÜx‚àÜt as:
m‚àÜx‚àÜt =

C‚àÜx‚àÜt
‚àÜx

(2)

In other words, the multiplier m‚àÜx‚àÜt is the contribution of
‚àÜx to ‚àÜt divided by ‚àÜx. Note the close analogy to the

y 0 = f (x01 , x02 , ...)

(4)

i.e. references for all neurons can be found by choosing a
reference input and propagating activations through the net.
The choice of a reference input is critical for obtaining
insightful results from DeepLIFT. In practice, choosing a
good reference would rely on domain-specific knowledge,
and in some cases it may be best to compute DeepLIFT
scores against multiple different references. As a guiding
principle, we can ask ourselves ‚Äúwhat am I interested in
measuring differences against?‚Äù. For MNIST, we use a reference input of all-zeros as this is the background of the images. For the binary classification tasks on DNA sequence
inputs (strings over the alphabet {A,C,G,T}), we obtained
sensible results using either a reference input containing the
expected frequencies of ACGT in the background (Fig. 5),
or by averaging the results over multiple reference inputs
for each sequence that are generated by shuffling each original sequence (Appendix J). For CIFAR10 data, we found
that using a blurred version of the original image as the

DeepLIFT: Learning Important Features Through Propagating Activation Differences

‚àÜy ‚àí =

reference highlighted outlines of key objects, while an allzeros reference highlighted hard-to-interpret pixels in the
background (Appendix L).
It is important to note that gradient√óinput implicitly uses a
reference of all-zeros (it is equivalent to a first-order Taylor
approximation of gradient√ó‚àÜinput where ‚àÜ is measured
w.r.t. an input of zeros). Similary, integrated gradients
(Section 2.2.3) requires the user to specify a starting point
for the integral, which is conceptually similar to specifying a reference for DeepLIFT. While Guided Backprop and
pure gradients don‚Äôt use a reference, we argue that this is
a limitation as these methods only describe the local behaviour of the output at the specific input value, without
considering how the output behaves over a range of inputs.
3.4. Separating Positive and Negative Contributions
We will see in Section 3.5.3 that, in some situations, it is
essential to treat positive and negative contributions differently. To do this, for every neuron y, we will introduce
‚àÜy + and ‚àÜy ‚àí to represent the positive and negative components of ‚àÜy, such that:
‚àÜy = ‚àÜy + + ‚àÜy ‚àí

X

1{wi ‚àÜxi < 0}wi ‚àÜxi

i

=

X

‚àí
1{wi ‚àÜxi < 0}wi (‚àÜx+
i + ‚àÜxi )

i

Which leads to the following choice for the contributions:
C‚àÜx+ ‚àÜy+ = 1{wi ‚àÜxi > 0}wi ‚àÜx+
i
i

C‚àÜx‚àí ‚àÜy+ = 1{wi ‚àÜxi > 0}wi ‚àÜx‚àí
i
i

C‚àÜx+ ‚àÜy‚àí = 1{wi ‚àÜxi < 0}wi ‚àÜx+
i
i

C‚àÜx‚àí ‚àÜy‚àí = 1{wi ‚àÜxi < 0}wi ‚àÜx‚àí
i
i

We can then find multipliers using the definition in Section
3.2.1, which gives m‚àÜx+ ‚àÜy+ = m‚àÜx‚àí ‚àÜy+ = 1{wi ‚àÜxi >
i
i
0}wi and m‚àÜx+ ‚àÜy‚àí = m‚àÜx‚àí ‚àÜy‚àí = 1{wi ‚àÜxi < 0}wi .
i

i

What about when ‚àÜxi = 0? While setting multipliers to 0
in this case would be consistent with summation-to-delta,
‚àí
it is possible that ‚àÜx+
i and ‚àÜxi are nonzero (and cancel
each other out), in which case setting the multiplier to 0
would fail to propagate importance to them. To avoid this,
we set m‚àÜx+ ‚àÜy+ = m‚àÜx+ ‚àÜy‚àí = 0.5wi when ‚àÜxi is 0
i
i
(similarly for ‚àÜx‚àí ). See Appendix B for how to compute
these multipliers using standard neural network ops.

C‚àÜy‚àÜt = C‚àÜy+ ‚àÜt + C‚àÜy‚àí ‚àÜt
3.5.2. T HE R ESCALE RULE
For linear neurons, ‚àÜy + and ‚àÜy ‚àí are found by writing ‚àÜy
as a sum of terms involving its inputs ‚àÜxi and grouping
positive and negative terms together. The importance of
this will become apparent when applying the RevealCancel
rule (Section 3.5.3), where for a given target neuron t we
may find that m‚àÜy+ ‚àÜt and m‚àÜy‚àí ‚àÜt differ. However, when
applying only the Linear or Rescale rules (Section 3.5.1
and Section 3.5.2), m‚àÜy‚àÜt = m‚àÜy+ ‚àÜt = m‚àÜy‚àí ‚àÜt .
3.5. Rules for Assigning Contribution Scores
We present the rules for assigning contribution scores for
each neuron to its immediate inputs. In conjunction with
the chain rule for multipliers (Section 3.2), these rules can
be used to find the contributions of any input (not just the
immediate inputs) to a target output via backpropagation.
3.5.1. T HE L INEAR RULE
This applies to Dense and Convolutional layers (excluding
nonlinearities). LetP
y be a linear function of its
Pinputs xi
such that y = b + i wi xi . We have ‚àÜy = i wi ‚àÜxi .
We define the positive and negative parts of ‚àÜy as:
‚àÜy + =

X

1{wi ‚àÜxi > 0}wi ‚àÜxi

i

=

X
i

‚àí
1{wi ‚àÜxi > 0}wi (‚àÜx+
i + ‚àÜxi )

This rule applies to nonlinear transformations that take a
single input, such as the ReLU, tanh or sigmoid operations.
Let neuron y be a nonlinear transformation of its input x
such that y = f (x). Because y has only one input, we
have by summation-to-delta that C‚àÜx‚àÜy = ‚àÜy, and conse‚àÜy
. For the Rescale rule, we set ‚àÜy +
quently m‚àÜx‚àÜy = ‚àÜx
‚àí
and ‚àÜy proportional to ‚àÜx+ and ‚àÜx‚àí as follows:
‚àÜy
‚àÜx+ = C‚àÜx+ ‚àÜy+
‚àÜx
‚àÜy
‚àÜy ‚àí =
‚àÜx‚àí = C‚àÜx‚àí ‚àÜy‚àí
‚àÜx
‚àÜy + =

Based on this, we get:
m‚àÜx+ ‚àÜy+ = m‚àÜx‚àí ‚àÜy‚àí = m‚àÜx‚àÜy =

‚àÜy
‚àÜx

In the case where x ‚Üí x0 , we have ‚àÜx ‚Üí 0 and ‚àÜy ‚Üí 0.
The definition of the multiplier approaches the derivative,
dy
dy
i.e. m‚àÜx‚àÜy ‚Üí dx
, where the dx
is evaluated at x = x0 .
We can thus use the gradient instead of the multiplier when
x is close to its reference to avoid numerical instability issues caused by having a small denominator.
Note that the Rescale rule addresses both the saturation
and the thresholding problems illustrated in Fig. 1 and
Fig. 2. In the case of Fig. 1, if i01 = i02 = 0, then
at i1 + i2 > 1 we have ‚àÜh = ‚àí1 and ‚àÜy = 1, giving

DeepLIFT: Learning Important Features Through Propagating Activation Differences
‚àÜy
dy
m‚àÜh‚àÜy = ‚àÜh
= ‚àí1 even though dh
= 0 (in other words,
using difference-from-reference allows information to flow
even when the gradient is zero). In the case of Fig. 2, assuming x0 = y 0 = 0, at x = 10 +  we have ‚àÜy = ,

and C‚àÜx‚àÜy = ‚àÜx √ó m‚àÜx‚àÜy = .
giving m‚àÜx‚àÜy = 10+
By contrast, gradient√óinput assigns a contribution of 10+
to x and ‚àí10 to the bias term (DeepLIFT never assigns importance to bias terms).

As revealed in previous work (Lundberg & Lee, 2016),
there is a connection between DeepLIFT and Shapely values. Briefly, the Shapely values measure the average
marginal effect of including an input over all possible orderings in which inputs can be included. If we define ‚Äúincluding‚Äù an input as setting it to its actual value instead of
its reference value, DeepLIFT can be thought of as a fast
approximation of the Shapely values. At the time, Lundberg & Lee cited a preprint of DeepLIFT which described
only the Linear and Rescale rules with no separate treatment of positive and negative contributions.
3.5.3. A N I MPROVED A PPROXIMATION OF THE
S HAPELY VALUES : T HE R EVEAL C ANCEL RULE
While the Rescale rule improves upon simply using gradients, there are still some situations where it can provide
misleading results. Consider the min(i1 , i2 ) operation depicted in Fig. 3, with reference values of i1 = 0 and i2 = 0.
Using the Rescale rule, all importance would be assigned
either to i1 or to i2 (whichever is smaller). This can obscure
the fact that both inputs are relevant for the min operation.
To understand why this occurs, consider the case when
i1 > i2 . We have h1 = (i1 ‚àí i2 ) > 0 and h2 =
max(0, h1 ) = h1 . By the Linear rule, we calculate that
C‚àÜi1 ‚àÜh1 = i1 and C‚àÜi2 ‚àÜh1 = ‚àíi2 . By the Rescale
2
rule, the multiplier m‚àÜh1 ‚àÜh2 is ‚àÜh
‚àÜh1 = 1, and thus
C‚àÜi1 ‚àÜh2 = m‚àÜh1 ‚àÜh2 C‚àÜi1 ‚àÜh1 = i1 and C‚àÜi2 ‚àÜh2 =
m‚àÜh1 ‚àÜh2 C‚àÜi2 ‚àÜh1 = ‚àíi2 . The total contribution of i1 to
the output o becomes (i1 ‚àí C‚àÜi1 ‚àÜh2 ) = (i1 ‚àí i1 ) = 0,
and the total contribution of i2 to o is ‚àíC‚àÜi2 ‚àÜh2 = i2 .
This calculation is misleading as it discounts the fact that
C‚àÜi2 ‚àÜh2 would be 0 if i1 were 0 - in other words, it ignores a dependency induced between i1 and i2 that comes
from i2 canceling out i1 in the nonlinear neuron h2 . A
similar failure occurs when i1 < i2 ; the Rescale rule results in C‚àÜi1 ‚àÜo = i1 and C‚àÜi2 ‚àÜo = 0. Note that gradients, gradient√óinput, Guided Backpropagation and integrated gradients would also assign all importance to either
i1 or i2 , because for any given input the gradient is zero for
one of i1 or i2 (see Appendix C for a detailed calculation).
One way to address this is by treating the positive and
negative contributions separately. We again consider the
nonlinear neuron y = f (x). Instead of assuming that
‚àÜy + and ‚àÜy ‚àí are proportional to ‚àÜx+ and ‚àÜx‚àí and that

m‚àÜx+ ‚àÜy+ = m‚àÜx‚àí ‚àÜy‚àí = m‚àÜx‚àÜy (as is done for the
Rescale rule), we define them as follows:

1
f (x0 + ‚àÜx+ ) ‚àí f (x0 )
‚àÜy + =
2

1
f (x0 + ‚àÜx‚àí + ‚àÜx+ ) ‚àí f (x0 + ‚àÜx‚àí )
+
2

1
‚àí
‚àÜy =
f (x0 + ‚àÜx‚àí ) ‚àí f (x0 )
2

1
+
f (x0 + ‚àÜx+ + ‚àÜx‚àí ) ‚àí f (x0 + ‚àÜx+ )
2
C‚àÜx+ y+
‚àÜy ‚àí
‚àÜy +
=
; m‚àÜx‚àí ‚àÜy‚àí =
m‚àÜx+ ‚àÜy+ =
+
+
‚àÜx
‚àÜx
‚àÜx‚àí
In other words, we set ‚àÜy + to the average impact of ‚àÜx+
after no terms have been added and after ‚àÜx‚àí has been
added, and we set ‚àÜy ‚àí to the average impact of ‚àÜx‚àí after
no terms have been added and after ‚àÜx+ has been added.
This can be thought of as the Shapely values of ‚àÜx+ and
‚àÜx‚àí contributing to y.
By considering the impact of the positive terms in the absence of negative terms, and the impact of negative terms
in the absence of positive terms, we alleviate some of the
issues that arise from positive and negative terms canceling
each other out. In the case of Fig. 3, RevealCancel would
assign a contribution of 0.5 min(i1 , i2 ) to both inputs (see
Appendix C for a detailed calculation).
While the RevealCancel rule also avoids the saturation and
thresholding pitfalls illustrated in Fig. 1 and Fig. 2, there
are some circumstances where we might prefer to use the
Rescale rule. Specifically, consider a thresholded ReLU
where ‚àÜy > 0 iff ‚àÜx ‚â• b. If ‚àÜx < b merely indicates
noise, we would want to assign contributions of 0 to both
‚àÜx+ and ‚àÜx‚àí (as done by the Rescale rule) to mitigate the
noise. RevealCancel may assign nonzero contributions by
considering ‚àÜx+ in the absence of ‚àÜx‚àí and vice versa.

Figure 3. Network computing o = min(i1 , i2 ). Assume i01 =
dy
i02 = 0. When i1 < i2 then di
= 0, and when i2 < i1 then
2
do
= 0. Using any of the backpropagation approaches described
di1
in Section 2.2 would result in importance assigned either exclusively to i1 or i2 . With the RevealCancel rule, the net assigns
0.5 min(i1 , i2 ) importance to both inputs.

3.6. Choice of Target Layer
In the case of softmax or sigmoid outputs, we may prefer to compute contributions to the linear layer preceding
the final nonlinearity rather than the final nonlinearity itself. This would be to avoid an attentuation caused by the

DeepLIFT: Learning Important Features Through Propagating Activation Differences

summation-to-delta property described in Section 3.1. For
example, consider a sigmoid output o = œÉ(y), where y is
the logit of the sigmoid function. Assume y = x1 + x2 ,
where x01 = x02 = 0. When x1 = 50 and x2 = 0, the
output o saturates at very close to 1 and the contributions
of x1 and x2 are 0.5 and 0 respectively. However, when
x1 = 100 and x2 = 100, the output o is still very close
to 0, but the contributions of x1 and x2 are now both 0.25.
This can be misleading when comparing scores across different inputs because a stronger contribution to the logit
would not always translate into a higher DeepLIFT score.
To avoid this, we compute contributions to y rather than o.
Adjustments for Softmax Layers
If we compute contributions to the linear layer preceding
the softmax rather than the softmax output, an issue that
could arise is that the final softmax output involves a normalization over all classes, but the linear layer before the
softmax does not. To address this, we can normalize the
contributions to the linear layer by subtracting the mean
contribution to all classes. Formally, if n is the number of
classes, C‚àÜx‚àÜci represents the unnormalized contribution
0
to class ci in the linear layer and C‚àÜx‚àÜc
represents the
i
normalized contribution, we have:

Sxi diff > 0. We then evaluate the change in the log-odds
score between classes co and ct for the original image and
the image with the pixels erased.
As shown in Fig. 4, DeepLIFT with the RevealCancel rule
outperformed the other backpropagation-based methods.
Integrated gradients (Section 2.2.3) computed numerically
over either 5 or 10 intervals produced results comparable
to each other, suggesting that adding more intervals would
not change the result. Integrated gradients also performed
comparably to gradient*input, suggesting that saturation
and thresholding failure modes are not common on MNIST
data. Guided Backprop discards negative gradients during
backpropagation, perhaps explaining its poor performance
at discriminating between classes. We also explored using
the Rescale rule instead of RevealCancel on various layers
and found that it degraded performance (Appendix E).

n

0
C‚àÜx‚àÜc
= C‚àÜx‚àÜci ‚àí
i

1X
C‚àÜx‚àÜcj
n j=1

(5)

As a justification for this normalization, we note that subtracting a fixed value from all the inputs to the softmax
leaves the output of the softmax unchanged.

4. Results
4.1. Digit Classification (MNIST)
We train a convolutional neural network on MNIST (LeCun et al., 1999) using Keras (Chollet, 2015) to perform
digit classification and obtain 99.2% test-set accuracy. The
architecture consists of two convolutional layers, followed
by a fully connected layer, followed by the softmax output
layer (see Appendix D for full details on model architecture and training). We used convolutions with stride > 1
instead of pooling layers, which did not result in a drop in
performance as is consistent with previous work (Springenberg et al., 2014). For DeepLIFT and integrated gradients,
we used a reference input of all zeros.
To evaluate importance scores obtained by different methods, we design the following task: given an image that originally belongs to class co , we identify which pixels to erase
to convert the image to some target class ct . We do this by
finding Sxi diff = Sxi co ‚àí Sxi ct (where Sxi c is the score for
pixel xi and class c) and erasing up to 157 pixels (20% of
the image) ranked in descending order of Sxi diff for which

Figure 4. DeepLIFT with the RevealCancel rule better identifies pixels to convert one digit to another. Top: result of masking pixels ranked as most important for the original class (8) relative to the target class (3 or 6). Importance scores for class 8, 3 and
6 are also shown. The selected image had the highest change in
log-odds scores for the 8‚Üí6 conversion using gradient*input or
integrated gradients to rank pixels. Bottom: boxplots of increase
in log-odds scores of target vs. original class after the mask is applied, for 1K images belonging to the original class in the testing
set. ‚ÄúIntegrated gradients-n‚Äù refers to numerically integrating the
gradients over n evenly-spaced intervals using the midpoint rule.

DeepLIFT: Learning Important Features Through Propagating Activation Differences

Figure 5. DeepLIFT with RevealCancel gives qualitatively desirable behavior on TAL-GATA simulation. (a) Scatter plots of importance score vs. strength of TAL1 motif match for different tasks and methods (see Appendix G for GATA1). For each region, top 5
motif matches are plotted. X-axes: log-odds of TAL1 motif match vs. background. Y-axes: total importance assigned to the match for
specified task. Red dots are from regions where both TAL1 and GATA1 motifs were inserted during simulation; blue have GATA1 only,
green have TAL1 only, black have no motifs inserted. ‚ÄúDeepLIFT-fc-RC-conv-RS‚Äù refers to using RevealCancel on the fully-connected
layer and Rescale on the convolutional layers, which appears to reduce noise relative to using RevealCancel on all layers. (b) proportion
of strong matches (log-odds > 7) to TAL1 motif in regions containing both TAL1 and GATA1 that had total score ‚â§ 0 for task 0; Guided
Backprop√óinp and DeepLIFT with RevealCancel have no false negatives, but Guided Backprop has false positives for Task 1 (Panel (a))

4.2. Classifying Regulatory DNA (Genomics)
Next, we compared the importance scoring methods when
applied to classification tasks on DNA sequence inputs
(strings over the alphabet {A,C,G,T}). The human genome
has millions of DNA sequence elements ( 200-1000 in
length) containing specific combinations of short functional words to which regulatory proteins (RPs) bind to
regulate gene activity. Each RP (e.g. GATA1) has binding
affinity to specific collections of short DNA words (motifs) (e.g. GATAA and GATTA). A key problem in computational genomics is the discovery of motifs in regulatory
DNA elements that give rise to distinct molecular signatures (labels) which can be measured experimentally. Here,
in order to benchmark DeepLIFT and competing methods
to uncover predictive patterns in DNA sequences, we design a simple simulation that captures the essence of the
motif discovery problem described above.
Background DNA sequences of length 200 were generated by sampling the letters ACGT at each position with

probabilities 0.3, 0.2, 0.2 and 0.3 respectively. Motif instances were randomly sampled from previously known
probabilistic motif models (See Appendix F) of two RPs
named GATA1 and TAL1 (Fig. 6a)(Kheradpour & Kellis, 2014), and 0-3 instances of a given motif were inserted at random non-overlapping positions in the DNA sequences. We trained a multi-task neural network with two
convolutional layers, global average pooling and one fullyconnected layer on 3 binary classification tasks. Positive
labeled sequences in task 1 represented ‚Äúboth GATA1 and
TAL1 present‚Äù, task 2 represented ‚ÄúGATA1 present‚Äù and
in task 3 represented ‚ÄúTAL1 present‚Äù. 14 of sequences had
both GATA1 and TAL1 motifs (labeled 111), 14 had only
GATA1 (labeled 010), 14 had only TAL1 (labeled 001), and
1
4 had no motifs (labeled 000). Details of the simulation,
network architecture and predictive performance are given
in Appendix F. For DeepLIFT and integrated gradients,
we used a reference input that had the expected frequencies
of ACGT at each position (i.e. we set the ACGT channel
axis to 0.3, 0.2, 0.2, 0.3; see Appendix J for results using

DeepLIFT: Learning Important Features Through Propagating Activation Differences

shuffled sequences as a reference). For fair comparison,
this reference was also used for gradient√óinput and Guided
Backprop√óinput (‚Äúinput‚Äù is more accurately called ‚àÜinput
where ‚àÜ measured w.r.t the reference). For DNA sequence
inputs, we found Guided Backprop√óinput performed better
than vanilla Guided Backprop; thus, we used the former.
Given a particular subsequence, it is possible to compute
the log-odds score that the subsequence was sampled from
a particular motif vs. originating from the background
distribution of ACGT. To evaluate different importancescoring methods, we found the top 5 matches (as ranked
by their log-odds score) to each motif for each sequence
from the test set, as well as the total importance allocated
to the match by different importance-scoring methods for
each task. The results are shown in Fig. 5 (for TAL1) and
Appendix E (for GATA1). Ideally, we expect an importance scoring method to show the following properties: (1)
high scores for TAL1 motifs on task 2 and (2) low scores
for TAL1 on task 1, with (3) higher scores corresponding to
stronger log-odds matches; analogous pattern for GATA1
motifs (high for task 1, low for task 2); (4) high scores for
both TAL1 and GATA1 motifs for task 0, with (5) higher
scores on sequences containing both kinds of motifs vs. sequences containing only one kind (revealing cooperativity;
corresponds to red dots lying above green dots in Fig. 5).
We observe Guided Backprop√óinput fails (2) by assigning
positive importance to TAL1 on task 1 (see Appendix H
for an example sequence). It fails property (4) by failing
to identify cooperativity in task 0 (red dots overlay green
dots). Both Guided Backprop√óinput and gradient√óinput
show suboptimal behavior regarding property (3), in that
there is a sudden increase in importance when the log-odds
score is around 7, but little differentiation at higher logodds scores (by contrast, the other methods show a more
gradual increase). As a result, Guided Backprop√óinput and
gradient√óinput can assign unduly high importance to weak
motif matches (Fig. 6). This is a practical consequence of
the thresholding problem from Fig. 2. The large discontinuous jumps in gradient also result in inflated scores (note
the scale on the y-axes) relative to other methods.
We explored three versions of DeepLIFT: Rescale at all
nonlinearities (DeepLIFT-Rescale), RevealCancel at all
nonlinearities (DeepLIFT-RevealCancel), and Rescale at
convolutional layers with RevealCancel at the fully connected layer (DeepLIFT-fc-RC-conv-RS). In contrast to the
results on MNIST, we found that DeepLIFT-fc-RC-convRS reduced noise relative to pure RevealCancel. We think
this is because of the noise-suppression property discussed
in Section 3.5.3; if the convolutional layers act like motif detectors, the input to convolutional neurons that do not
fire may just represent noise and importance should not be
propagated to them (see Fig. 6 for an example sequence).

Gradient√óinp, integrated gradients and DeepLIFT-Rescale
occasionally miss relevance of TAL1 for Task 0 (Fig. 5b),
which is corrected by using RevealCancel on the fully connected layer (see example sequence in Fig. 6). Note that
the RevealCancel scores seem to be tiered. As illustrated
in Appendix I, this is related to having multiple instances
of a given motif in a sequence (eg: when there are multiple
TAL1 motifs, the importance assigned to the presence of
TAL1 is distributed across all the motifs).

Figure 6. RevealCancel highlights both TAL1 and GATA1 motifs for Task 0. (a) PWM representations of the GATA1 motif
and TAL1 motif used in the simulation (b) Scores for example sequence containing both TAL1 and GATA1 motifs. Letter height
reflects the score. Blue box is location of embedded GATA1 motif, green box is location of embedded TAL1 motif. Red underline
is chance occurrence of weak match to TAL1 (CAGTTG instead
of CAGATG). Both TAL1 and GATA1 motifs should be highlighted for Task 0. RevealCancel on only the fully-connected
layer reduces noise compared to RevealCancel on all layers.

5. Conclusion
We have presented DeepLIFT, a novel approach for computing importance scores based on explaining the difference of the output from some ‚Äòreference‚Äô output in terms
of differences of the inputs from their ‚Äòreference‚Äô inputs.
Using the difference-from-reference allows information to
propagate even when the gradient is zero (Fig. 1), which
could prove especially useful in Recurrent Neural Networks where saturating activations like sigmoid or tanh are
popular. DeepLIFT avoids placing potentially misleading
importance on bias terms (in contrast to gradient*input see Fig. 2). By allowing separate treatment of positive and
negative contributions, the DeepLIFT-RevealCancel rule
can identify dependencies missed by other methods (Fig.
3). Open questions include how to apply DeepLIFT to
RNNs, how to compute a good reference empirically from
the data, and how best to propagate importance through
‚Äòmax‚Äô operations (as in Maxout or Maxpooling neurons)
beyond simply using the gradients.

DeepLIFT: Learning Important Features Through Propagating Activation Differences

References
Bach, Sebastian, Binder, Alexander, Montavon, GreÃÅgoire,
Klauschen, Frederick, MuÃàller, Klaus-Robert, and
Samek, Wojciech. On Pixel-Wise explanations for
Non-Linear classifier decisions by Layer-Wise relevance
propagation. PLoS One, 10(7):e0130140, 10 July 2015.
Chollet, Franois. keras. https://github.com/
fchollet/keras, 2015.

Zeiler, Matthew D. and Fergus, Rob.
Visualizing
and understanding convolutional networks.
CoRR,
abs/1311.2901, 2013. URL http://arxiv.org/
abs/1311.2901.
Zhou, Jian and Troyanskaya, Olga G. Predicting effects of
noncoding variants with deep learning-based sequence
model. Nat Methods, 12:931‚Äì4, 2015 Oct 2015. ISSN
1548-7105. doi: 10.1038/nmeth.3547.

Kheradpour, Pouya and Kellis, Manolis. Systematic discovery and characterization of regulatory motifs in encode tf binding experiments. Nucleic acids research, 42
(5):2976‚Äì2987, 2014.

Zintgraf, Luisa M, Cohen, Taco S, Adel, Tameem,
and Welling, Max.
Visualizing deep neural network decisions: Prediction difference analysis. ICLR,
2017. URL https://openreview.net/pdf?
id=BJ5UeU9xx.

Kindermans, Pieter-Jan, Schtt, Kristof, Mller, KlausRobert, and Dhne, Sven. Investigating the influence of
noise and distractors on the interpretation of neural networks. CoRR, abs/1611.07270, 2016. URL https:
//arxiv.org/abs/1611.07270.

6. Acknowledgements

LeCun, Yann, Cortes, Corinna, and Burges, Christopher J.C. The mnist database of handwritten digits. http://yann.lecun.com/exdb/mnist/,
1999.

7. Funding

Lundberg, Scott and Lee, Su-In. An unexpected unity
among methods for interpreting model predictions.
CoRR, abs/1611.07478, 2016. URL http://arxiv.
org/abs/1611.07478.
Selvaraju, Ramprasaath R., Das, Abhishek, Vedantam, Ramakrishna, Cogswell, Michael, Parikh, Devi, and Batra, Dhruv. Grad-cam: Why did you say that? visual
explanations from deep networks via gradient-based localization. CoRR, abs/1610.02391, 2016. URL http:
//arxiv.org/abs/1610.02391.
Shrikumar, Avanti, Greenside, Peyton, Shcherbina, Anna,
and Kundaje, Anshul. Not just a black box: Learning
important features through propagating activation differences. arXiv preprint arXiv:1605.01713, 2016.
Simonyan, Karen, Vedaldi, Andrea, and Zisserman, Andrew. Deep inside convolutional networks: Visualising
image classification models and saliency maps. arXiv
preprint arXiv:1312.6034, 2013.
Springenberg, Jost Tobias, Dosovitskiy, Alexey, Brox,
Thomas, and Riedmiller, Martin A. Striving for simplicity: The all convolutional net. CoRR, abs/1412.6806,
2014.
URL http://arxiv.org/abs/1412.
6806.
Sundararajan, Mukund, Taly, Ankur, and Yan, Qiqi. Gradients of counterfactuals. CoRR, abs/1611.02639, 2016.
URL http://arxiv.org/abs/1611.02639.

We thank Anna Shcherbina for early experiments applying
DeepLIFT to image data and beta-testing.

AS is supported by a Howard Hughes Medical Institute
International Student Research Fellowship and a Bio-X
Bowes Fellowship. PG is supported by a Bio-X Stanford
Interdisciplinary Graduate Fellowship. AK was supported
by NIH grants DP2-GM-123485 and 1R01ES025009-02.

8. Author Contributions
AS & PG conceptualized DeepLIFT. AS implemented
DeepLIFT. AS ran experiments on MNIST. AS & PG ran
experiments on genomic data. AK provided guidance and
feedback. AS, PG and AK wrote the manuscript.

