Doubly Greedy Primal-Dual Coordinate Descent
for Sparse Empirical Risk Minimization
Qi Lei 1 Ian E.H. Yen 2 Chao-yuan Wu 3 Inderjit S. Dhillon 1 3 4 Pradeep Ravikumar 2

Abstract
We consider the popular problem of sparse empirical risk minimization with linear predictors and
a large number of both features and observations.
With a convex-concave saddle point objective reformulation, we propose a Doubly Greedy PrimalDual Coordinate Descent algorithm that is able to
exploit sparsity in both primal and dual variables.
It enjoys a low cost per iteration and our theoretical analysis shows that it converges linearly
with a good iteration complexity, provided that
the set of primal variables is sparse. We then extend this algorithm further to leverage active sets.
The resulting new algorithm is even faster, and
experiments on large-scale Multi-class data sets
show that our algorithm achieves up to 30 times
speedup on several state-of-the-art optimization
methods.

1. Introduction
Regularized empirical risk minimization with linear predictors is a key workhorse in machine learning. It has the
following general form:
(
)
n
X
def 1
>
min P (x) =
(1)
i (ai x) + g(x)
n i=1
x2Rd

where ai 2 Rd is one of the n data samples with d features.
i : R ! R is a convex loss function of the linear predictor
d
a>
i x, for i = 1, · · · , n, and g : R ! R is a convex
regularization function for the coefficient vector x 2 Rd .
The loss function i assigns a cost to the difference between
the linear predictor a>
i x and the associated label bi .
With continuous and discrete bi , (1) captures regression and
classification problems respectively. As a popular instance,
1

Department of ICES, University of Texas, Austin 2 Department
of CS, Carnegie Mellon University, Pittsburgh 3 Department of
CS, University of Texas, Austin 4 Amazon/A9, Palo Alto. Correspondence to: Qi Lei <leiqi@ices.utexas.edu>, Ian E.H. Yen
<eyan@cs.cmu.edu>.
Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by
the author(s).

when i (z) = max{0, 1 bi z} and g(x) = µ/2kxk22 , (1)
reduces to the linear SVM (support vector machine) classification problem. While setting i (z) = log(1 + exp( bi z)),
we obtain the logistic regression problem.
We are interested in developing efficient algorithms for solving this general problem (1) for the setting where the coefficient vector x is assumed to be sparse. Applications
where such a sparsity is natural include large-scale multiclass/multi-label classification, low-degree polynomial data
mapping (Chang et al., 2010), n-gram feature mapping (Sonnenburg & Franc, 2010), and random feature kernel machines (Rahimi & Recht, 2007), specifically with a sparsity
constraint on the random features (Yen et al., 2014).
Our paper is organized as follows: In Section 2 we review
existing algorithms to solve the primal, dual as well as
primal-dual formulations of the problem (1). In Section
3, we present our Doubly Greedy Primal-Dual Coordinate
Descent method for the convex-concave saddle point formulation of the problem (1). We propose an alternative method
that is more efficient in practice with the use of incrementally increased active sets in both primal and dual variables.
In Section 4 we show linear convergence for our proposed
algorithm, and demonstrate the advantages of greedy methods with sparse variables. Finally in Section 5 we compare
the performance of our method with other state-of-the-art
methods on some real-world datasets, both with respect to
time and iterations.

2. Formulation and related work
Notations: We use A to denote the data matrix, with rows
Ai = ai corresponding to samples, and the column Aj
corresponding to features. We use [n] to compactly denote
{1, 2, · · · n}. Throughout the paper, k · k denotes l2 -norm
unless otherwise specified.
Assumptions: In order to establish equivalence of the primal, dual problem and the convex-concave saddle point
formulation, we make the following assumptions.
• g, the regularization for primal variable, is assumed to
be µ-strongly convex, formally,
µ
g(y) g(x) + hrg(x), y xi + ky xk2 ,
2
for any sub-gradient rg(x) 2 @g(x), x, y 2 Rd . We

Doubly Greedy Primal-dual Coordinate Descent for Sparse Empirical Risk Minimization

•

also assume
P that g has decomposable structure, i.e.,
g(x) = i gi (xi ).
i

is 1 -smooth, for i 2 [n]:

i (y)



i (x) +

0
x) + (y x)2 , x, y
i (x)(y
2
0
i is Lipschitz continuous,
1

or equivalently,
0
| 0i (x)
i (y)|  |x

2R

i.e.,

y|.

2.1. Primal, dual and primal-dual formulations
Under the assumption of strongly convex regularization g
and smooth loss function i , minimizing (1) is equivalent
to maximizing its dual formulation:

max

y2Rn

(

D(y) ⌘

A> y
g⇤ (
)
n

n

1X
n i=1

⇤
i (yi )

)

(2)

or the unique solution for the following convex-concave
saddle point problem:
(
)
n
1 >
1X ⇤
max min L(x, y) = g(x) + y Ax
(yi )
y2Rn x2Rd
n
n i=1 i
(3)
Note that i (a>
i x) in (1) is also smooth with respect to
0
>
>
x, since rx i (a>
i x) =
i (ai x)ai , therefore i (ai x)
2
is R / -smooth with respect to x, where R is defined as
R = maxi kai k2 . (Zhang & Xiao, 2014) thus defined the
condition number for the primal-dual form as:
2
def R
=
.
µ
We share this definition in this paper. The commonly used
condition number for the gradient descent of the primal form
is simply (R2 / + µ)/µ = 1 + , see (Nesterov, 2004).
2.2. Related work
There has been a long line of work over the years to derive
fast solvers for the generic optimization problem (1). In
Table 1, we review the time complexity to achieve ✏ error
with respect to either primal, dual or primal-dual optimality
for existing methods.
Primal (accelerated) gradient descent (Nesterov,
2004;
p
2005) require O((1+) log(1/✏)) (or O((1+ ) log(1/✏))
if accelerated) iterations to achieve primal error less than ✏.
Note that 1 +  is the condition number of (1). Since each iteration takes O(nd) operations, the overall time
p complexity
is O(nd (1 + ) log(1/✏)) (or O(nd (1 + ) log(1/✏))
if accelerated). Due to the large per iteration cost for
large n, stochastic variants that separately optimize each
i have proved more popular in big data settings. Examples include SGD (Bottou, 2010), SAG (Schmidt et al.,
2013), SVRG (Johnson & Zhang, 2013), SAGA (Defazio et al., 2014), MISO (Mairal, 2015) and their accel-

erated versions (Xiao & Zhang, 2014). The stochastic
scheme of optimizing individual i is similar to updating each dual coordinate individually. Their time complexity thus matches that of dual coordinate descent methods (Hsieh et al., 2008; Shalev-Shwartz & Zhang, 2013b;
Yang, 2013; Qu et al., 2014), which enjoy a time complexity
of O(nd (1+/n) log(1/✏)), and a further acceleration step
(Shalev-Shwartz & Zhang,
p2016; 2013a) will improve the
complexity to O(nd (1 + /n) log(1/✏)). These stochastic methods have a lower per iteration cost of O(d), but each
step optimizes terms that are much less well-conditioned,
and consequently have
pa larger iteration complexity, for
instance of O(n (1 + /n) log(1/✏)) in the accelerated
case.

With the primal-dual formulation, (Zhang & Xiao, 2014)
introduce a novel stochastic primal-dual coordinate method
(SPDC), whichp
with acceleration achieves a time complexity
of O(nd (1 + /n) log(1/✏)), matching that of accelerated stochastic dual coordinate descent methods.

However, in practice, SPDC could lead to more expensive
computations for sparse data matrices due to dense updates.
For some special choices of the model, (Zhang & Xiao,
2014) provided efficient implementation for sparse feature
structures, but the average update time for each coordinate
is still much longer than that of dual coordinate descent.
Moreover, they cannot exploit intermediate sparse iterates
by methods such as shrinking technique (Hsieh et al., 2008).
We note moreover that acceleration is not always practically
useful in many real-world settings, other than in extremely
ill-conditioned
p situations. In particular,  is typically of
the order of n or n as shown in (Bousquet & Elisseeff,
2002; Zhang
p & Xiao, 2014), and therefore the conditioning
of O(1 + /n) is not necessarily much better than O(1 +
/n). Our experiments also corroborate this, showing that
vanilla dual coordinate descent under reasonable precision
or condition number is not improved upon by SDPC.
Therefore we raise the following question: Does the primaldual formulation have other good properties that could be
leveraged to improve optimization performance?
For instance, some recent work with the primal-dual formulation updates stochastically sampled coordinates (Yu et al.,
2015), which has a reduced cost per iteration, provided the
data admits a low-rank factorization or when the proximal
mapping for primal and dual variables are relatively computational expensive, which however may not hold in practice,
so that the the noise caused by this preprocessing could hurt
test performance. Moreover, even when their assumptions
hold, their low-rank matrix factorization step itself may
dominate the total computation time.

Doubly Greedy Primal-dual Coordinate Descent for Sparse Empirical Risk Minimization

2.3. Our Contribution

approaches to exploit primal or dual sparsity.

In this paper, we try to address the key question above in
the setting of empirical risk minimization problems with
very large n and d, and where the set of primal (and/or dual)
variables are assumed to be sparse. We then show that the
primal-dual formulation of the problem allows for naturally
leveraging available primal and/or dual sparsity.

In this paper, we propose a Doubly Greedy Primal-Dual
(DGPD) Coordinate method that greedily selects and updates both primal and dual variables. This method enjoys
an overall low time complexity under a sparsity assumption
on the primal variables:

Table 1. Basic summary of running-time complexity of existing
methods and our method (DGPD). n is the number of samples, d is
the dimension of samples and primal variables,  is the condition
number for primal-dual coordinate algorithms. For our method, s is
the upper bound of sparsity in its primal variables; For DSPDC(Yu
et al., 2015), A is assumed to factorized as U V, U 2 Rn⇥k , V 2
i k1
Rk⇥d , and 1 = maxi ka
2 [ d , ].
µ
Time complexity
Extra assumption
GD
O(dn(1 + ) log 1✏ )
p
AGD
O(dn(1 + ) log 1✏ )
SGD
O(d(1 + ) 1✏ )
MISO
SDCA
O(dn(1 + np) log 1✏ ), or
SVRG
O(dn(1 + n ) log 1✏ )
SAG(A)
if accelerated
p
SPDC
O(dn(1 + n ) log 1✏ )
p
DSPDC
O(kn(1 + d n1 ) log 1✏ )
A is factorized
ours
O(s(d + n)(1 + n ) log 1✏ )
x is sparse

In Table 1, we review the total time complexity to achieve ✏
accuracy. We can see that all algorithms that achieve a linear
convergence rate require running time that has a factor nd,
and in particular, none of their convergence rates involve
the sparsity of the primal or dual variables.
There have been some attempts to modify existing primal
or dual coordinate approaches in order to exploit sparsity
of either primal or dual variables, but these do not perform
very well in practice. One popular approach uses a shrinking
heuristic in updating dual coordinates (Hsieh et al., 2008),
which however still requires complexity linear to the number
of coordinates d and does not guarantee rate of convergence.
(Nutini et al., 2015) consider the idea of searching more important active coordinates to update in each iteration. Their
greedy updates yield an iteration complexity linear in 1/µ1
instead of d/µ, where µ and µ1 are the parameters of strong
convexity with respect to L2 and L1 norms respectively.
However, with the commonly used L2 regularization term
µk · k2 that is used to ensure µ-strong convexity, the term is
exactly µ1 = µd l1 -strongly convex. Moreover, in practice,
searching active coordinates causes considerable overhead.
While there have been some strategies proposed to address
this such as (Dhillon et al., 2011) that leverages nearest
neighbor search to reduce the searching time, these have
further requirements on the data structure used to store the
data. Overall, it thus remains to more carefully study the
optimization problem in order to facilitate the use of greedy

Theorem 2.1. Main result: (informal) For the empirical
risk minimization problem (1) with l1 + l2 regularization,
there exists an algorithm (DGPD) that achieves ✏ error in
O(s(n + d)(1 + n ) log 1✏ )) time, where s is an upper bound
of the sparsity of the primal variables.

3. The Doubly Greedy Primal-Dual (DGPD)
Coordinate Descent method
Coordinate-wise updates are most natural when g is separable, as is assumed for instance in the Stochastic Primal-Dual
Coordinate method of (Zhang & Xiao, 2014). In this paper, to exploit sparsity in primal variables, we additionally
focus on the case where g(x) = µ2 kxk2 + kxk1 . With
respect to the loss function , it is assumed to be 1 -smooth
and convex. For instance, setting i as the smooth hinge
loss(Shalev-Shwartz & Zhang, 2013b):
8
0
if bi z 1
<
1
b
z
if bi z  0
(z)
=
i
i
: 12
( 2 bi z)2 otherwise,
the smoothness parameter = 12 . For the logit function
i (z) = log(1 + exp( bi z), the smoothness parameter
= 4.
When iterates are sparse, it is more efficient to perform
greedy coordinate descent. We will provide a brief theoretical vignette of this phenomenon in Section 4.1. With this
motivation, our proposed method Doubly Greedy PrimalDual Coordinate Descent (DGPD) greedily selects and updates both the primal and dual variables, one coordinate a
time. Our overall method is detailed in Algorithm 1.
In Algorithm 1, we start from all zero vectors x(0) , z (0) 2
Rn , and y (0) , w(0) 2 Rd , where x(0) , and y (0) are the
iterates for primal and dual variables, and w(0) and z (0) are
two auxiliary vectors, maintained as w ⌘ Ax and z ⌘ A> y
to cache and reduce computations.
Primal Updates. In each iteration, we first compute the
optimal primal variable x̄(t 1) for the current y (t 1) , i.e.,
x̄(t 1) = arg min L(x, y (t 1) ) ) Eqn.(4)
x

Then, we only update the coordinate j (t) that will decrease
L(x, y) the most, i.e.,
(t 1)

j (t) = arg min L(x(t) +(x̄k
k2[d]

(t)

xk )ek , y (t

1)

) ) Eqn.(5)

Both two processes cost O(d) operations. Afterwards, we
update the value of w with Eqn. (6) such that w(t) = Ax(t)

Doubly Greedy Primal-dual Coordinate Descent for Sparse Empirical Risk Minimization

Algorithm 1 Doubly Greedy Primal-Dual Coordinate method
1: Input: Training data A 2 Rn⇥d , dual step size ⌘ > 0.
2: Initialize: x(0)
0 2 Rd , y (0)
0 2 Rn , w(0) ⌘ Ax = 0 2 Rn , z (0) ⌘ A> y = 0 2 Rd
3: for t = 1, 2, · · · , T do
4:
Choose greedily the primal coordinate to update:
1 (t 1)
(t)
x̄k
arg min
z
↵ + gk (↵) , 8k 2 [d]
↵
n k
1 (t 1) (t)
(t 1)
(t)
(t
j (t)
arg min
z
(x̄k
xk
) + gk (x̄k ) gk (xk
n k
k2[d]
(
(t)
x̄k
if k = j (t) ,
(t)
xk
(t 1)
xk
otherwise.
5:
Update w to maintain the value of Ax:
6:

w(t)
Choose greedily the dual coordinate to update:
i(t)
(t)

yk
7:

(

w(t

1)

(t)

+ (xj
(t 1)

arg max |wk
k2[n]

arg max
(t 1)
yk

1 (t)
w
n k

⇤
k(

)

(t 1)

xj
1
(
n

(4)
1)

)

)Aj

(6)

⇤ 0 (t 1)
)|
k ) (yk

1
(
2⌘

(t 1) 2

yk

(5)

)

(7)
if k = i(t)
otherwise.

(8)

Update z to maintain the value of A> y
z (t)

z (t

1)

8: end for
9: Output: x(T ) , y (T )

in O(d) or O(nnz(Aj )) operations. This greedy choice
of j (t) and aggressive update induces a sufficient primal
progress, as shown in Lemma A.1.
Dual Updates. We note that the updates are not exactly
symmetric in the primal x and dual y variables. The updates for the dual variables y do follow along similar lines
as x, except that we use the Gauss-Southwell rule to select
variables, and introduce a step size ⌘. This is motivated
by our convergence analysis, which shows that each primal
update step yields a large descent in the objective, while
each dual update only ascends the dual objective modulo
an error term. This required a subtle analysis to show that
the error terms were canceled out in the end by the progress
made in the primal updates. But to proceed with such an
analysis required the use of a step size in the dual updates,
to balance the progress made in the dual updates, and the
error term it introduced. Note moreover, that we are using
the Gauss-Southwell rule to choose the variable to optimize
in the dual variables y, while we simply use the coordinate that causes the most function descent in the primal
variables x. This is because our choice of step size in the
dual updates required computations that are shared with our
current approach of selecting the optimal primal variable.
This does incur more overhead when compared to the Gauss
Southwell rule however, so that we simply use the latter for
optimizing y.
The most significant feature in our method is that we select

(t)

+ (yi(t)

(t 1)

yi(t) )Ai(t)

(9)

and update one coordinate in both the primal and dual coordinates greedily. With a simple trick that maintains the
value of w ⌘ Ax and z ⌘ A> y (Lei et al., 2016), we
are able to select and update primal and dual coordinates
in O(n) and O(d) operations respectively. This happens
when computing the value of Ax and A> y, which are the
bottleneck in computing the gradient or updating the variables. An extension to choose and update a batch of primal
and dual coordinate is straightforward. We provide further
discussions on the designing of Algorithm 1 in Section 4.
In this paper, we have not incorporated an extrapolation/acceleration scheme to our algorithm. As noted earlier,
in practice the condition number  is usually comparable to
n, thus adding an extrapolation
term that reduces the conp
ditioning from /n to /n is not necessarily materially
advantageous in real applications. Meanwhile, an extrapolation step usually worsens the stability of the algorithm, and
is not easily combined with incorporating greedy updates,
which is crucial to the leveraging the primal or dual sparsity
structure in this paper. We thus defer an accelerated extension of our algorithm incorporating extrapolation term to
future work.
For Algorithm 1, each iteration can be seen to have a cost
of O(n + d), while in Section 4 we show that the iteration complexity for our method is O((1 + n )s log(1/✏))
assuming that the primal variables are s-sparse. Therefore the overall time complexity for our algorithm is
O (1 + n )s(n + d) log(1/✏) , which is cheaper than the

Doubly Greedy Primal-dual Coordinate Descent for Sparse Empirical Risk Minimization

time complexity
of even the accelerated SPDC algorithm
p
O (1 + n )nd log(1/✏) except for extremely ill conditioned cases.

significantly.

3.1. A Practical Extension of DGPD

In this section, we introduce the primal gap p and dual gap
d and analyze the convergence rate in terms of their sum,
which we call primal and dual sub-optimality = p + d .

In real application settings, Algorithm 1 has some drawbacks. When data is sparse, we still require O(n) and O(d)
operations to update primal and dual variables. Even when
the data is dense, to find the greedy coordinate and to update
it requires comparable time complexity, which suggests we
should find some ways to eliminate overhead in practice.
To resolve these issues, we introduce the Doubly Greedy
Primal-Dual Coordinate method with Active Sets in Algorithm 2. We make use of what we call active sets, that
contains the newly selected coordinates as well as the current non-zero variables. We construct these active sets Ax
and Ay for both primal and dual variables. Initially, they
are set as empty sets. In each iteration, we recurrently select
coordinates outside the active sets with the Gauss-Southwell
rule, and add them to Ax and Ay . We then optimize all the
variables within the active sets. Once a primal/dual variable
gets set to 0, we can drop it from the corresponding active
sets. This practice keeps the active sets Ax and Ay as the
support of primal and dual variables. Notice gk0 (xk ) is 0
when xk is zero, so that the variable selection step for primal
variables can be simplified as stated in (10).
Now the time complexity per iteration becomes |Ax |n +
|Ay |d. The sparsity in primal variables is encouraged by the
choice of `1 + `2 regularization. Meanwhile, as shown by
(Yen et al., 2016), a sparse set of primal variables usually
induces a sparse set of dual variables. Therefore |Ax | ⌧ d
and |Ay | ⌧ n in practice, and the cost per iteration is
sub-linear to nd. We present further details in Section 3.2.
3.2. Efficient Implementation for Sparse Data Matrix
Suppose we are given a sparse data matrix A with number
of non-zero elements of each column and each row bounded
by nnzy and nnzx respectively, one can further reduce the
cost for computing (10) and (12) from O(d|Ay | + n|Ax |)
to O(nnzx |Ay | + nnzy |Ax |) by storing both {Ai }ni=1 and
{Aj }dj=1 as sparse vectors and computing A> y and Ax as
X
X
A> y =
A>
Aj x j .
i yi , Ax =
(14)
i2Ay

j2Ax

In our implementation, whenever the active sets Ay , Ax
are expanded, we further maintain a submatrix [A]A which
contains only rows in Ay and columnsP
in Ax , so the primal
and dual updates (11), (13) only cost i2Ay nnz([Ai ]Ax ).
This results in each update costing less than the search
steps, and therefore, in practice, one can conduct multiple
rounds of updates (11), (13) before conducting the search
(10), (12), which in our experiment speeds up convergence

4. Convergence Analysis

Definition 4.1. For the following convex-concave funcPn
def
tion L(x, y) = g(x) + n1 y > Ax n1 i=1 ⇤i (yi ), with
def

its primal form P (x) = miny L(x, y), and dual form
def

D(y) = maxx L(x, y), we define the primal gap at iteration t as
(t) def
p =

L(x(t+1) , y (t) )
, the dual gap at iteration t as
(t) def
d =

D⇤

D(y (t) )

D(y (t) )

and sub-optimality as

(t) def

=

(t)
p

+

(t)
d .

Theorem 4.2. Suppose in (1), g is µ-strongly convex
(`1 + `2 ) regularization, and i is 1 -smooth. Let R =
maxi2[n] kai k2 . Then DGPD achieves
2n
(t+1)
(t)

,
(15)
2n + ⌘
if step size ⌘ (t) satisfies that
2n2 µ
⌘ (t) 
(16)
(t)
kx(t) x̄ k0 (5R2 + n µ)
Suppose kx(t) x̄(t) k0  s, if we choose step size ⌘ =
2n2 µ
(5R2 +n µ)s , then it requires

1
O(s( + 1) log )
n
✏
iterations for achieving ✏ primal and dual sub-optimality.1
Proof sketch: The proof analysis is straightforward with
the introduction of primal and dual sub-optimality . We
divide the proof into primal-dual progress, primal progress,
and dual progress.
• Primal-Dual Progress (Lemma A.2).


(t)
(t)
p
d +
(t+1)
t

L(x

(

(t 1)
+
d
t
t

(t 1)
)
p

, y ) L(x , y )
1
+⌘( hAi(t) , x(t) x̄(t) i)2
n
1
1 ⇤ 0 (t) 2
⌘( hAi(t) , x̄(t) i
( (t) ) (yi(t) )) (17)
n
n i

1
This result can be easily connected to traditional convergence
analysis in primal or dual form. Notice  ✏ is sufficient requirement that dual gap d = D⇤ D(y)  ✏, therefore the dual
variable y (t) converges to optimal y ⇤ with the same convergence
rate.

Doubly Greedy Primal-dual Coordinate Descent for Sparse Empirical Risk Minimization

Algorithm 2 Doubly Greedy Primal-Dual Coordinate method with Active Sets
1: Input: Training data A 2 Rn⇥d , dual step size ⌘ > 0.
(0)

(0)

2: Initialize: x(0)
0 2 Rd , y (0)
0 2 Rn , A x
?, Ay
?
3: for t
1, 2, · · · , T do
(t)
4:
Update the active set Ax greedily based on the optimal primal variable x̄(t

1 k (t
arg min
hA , y
↵
n
(t 1)
arg max |x̄k
|

(t)
x̄k

j (t)

1)

5:

1)
A(t
x

[ {j

(t)

}

and update x in its active set.

i↵ + gk (↵) , 8k 2 [d]
(10)

k2[d]

A(t)
x

1)

(

(t)
xj

(t 1)

x̄j
(t
xj

1)

(t)

Update the active set Ay greedily based on the value of ry L(x(t) , y (t
1 ⇤ 0 (t 1)
i(t)
arg max |hAk , x(t) i
( k ) (yk
)|.
n
(t 1)
k2[n] A

,
,

1)

(t)

if j 2 Ax
(t)
if j 2
/ Ax

(11)

) and update y in its active set.
(12)

y

A(t)
y
(t)

yi

6:

1)
A(t
[ {i(t) }
y
(
arg max n1 hAi , x(t) i
(t 1)

yi
,
Kick out 0 variables from active sets.
A(t)
A(t)
y
y

7: end for
8: Output: x(T ) , y (T )

[
(t)

i,yi =0

{i},

This lemma connects the descent in PD sub-optimality with
primal progress and dual progress. The third term and
the second terms respectively represent the potential dual
progress if we used the optimal x̄(t) , and the irrelevant part
generated from the difference between x̄(t) and x(t) .
• Primal Progress (Lemma A.1).

L(x(t) , y (t) ) L(x(t+1) , y (t) )

kx(t)

1
n

⇤
i(

A(t)
x

1

This inequality simply demonstrates function loss from primal update is at least a ratio of primal gap.
• Dual Progress (Lemma A.3).
1
( hAi(t) , x(t) x̄(t) i)2
n
1
1 ⇤ 0 (t) 2
( hAi(t) , x̄(t) i
( (t) ) (yi(t) ))
n
n i
5R2 (t)
(t)

kx
x̄(t) k2
(19)
d +
2n
2n2
Finally, we establish the relation between the dual progress
in our algorithm with dual gap and difference between x̄(t)
and x(t) . Now we can prove our main theorem 4.2.

(t)

if i 2 Ay

) ,

(13)

(t)

[
(t)

if i 2
/ Ay

j,xj =0

{j}

2

(t)
d

(t 1)
d

L(x(t+1) , y t )

+

(t)
p

(t 1)
p

L(xt , y t )



+ bkx(t) x̄(t) k2
2
L(x(t+1) , y t ) L(xt , y t )

=

(1

(t)
p

(18)

A(t)
x

(t 1)

yk

(t)
For cleaner notation, write a = ⌘2n , b = 5⌘R
2n2 . kx̄
(t)
x k0  s. By combining (18) and (19) to (17), we get:


1
x̄(t) k0

1
2⌘ (

)

+b L(x(t) , y (t) )

a

(t)
d

a

(t)
d

L(x̄(t) , y (t) )

b) L(x(t+1) , y t )

L(xt , y t )

a

(t)
d

+b L(x(t+1) , y t ) L(x̄(t) , y t )
1 b (t)
(t)

a d
s 1 p
+b L(x(t+1) , y t ) L(x̄(t) , y t )
1 b
(t)
=
b (t)
a d
p
s 1
Here the second inequality comes from strong convexity of
L(·, y (t) ). The fourth inequality comes from Lemma A.1.

Therefore when a  s1 1b b, or sufficiently a  (s(1 +
1
(t 1)
5/n)) 1 , we get (t)  1+a
. Since a < 1,
1/a
(t)
(a + 1)
 1/2, therefore
 (1 + a) t (0) 

Doubly Greedy Primal-dual Coordinate Descent for Sparse Empirical Risk Minimization

2

at
(T )

. Therefore when T
 ✏.
(0)

O(s(1 + /n) log2

(0)

✏

),

4.1. Analysis on greedy methods for sparse iterates
In this section, we give a simple analysis of the greedy variable selection rule showing that when iterate and minimizer
of a generic optimization problem are sparse, its convergence rate is faster than choosing random coordinates. We
define the optimization problem in the space of Rn :
minn f (x)
x2R

, where f is µ-strongly convex L-smooth:
|ri f (x + ↵ei ) ri f (x)|  L|↵|, 8x 2 Rn
Under this setting, a random coordinate descent method with
µ
step size L1 , achieves E[f (x+ ) f ⇤ ]  (1 nL
) f (x)
f ⇤ , where x+ is the next iterate of x.
Under the assumption that the current iterate x and the
optimal x⇤ are both k-sparse, we thereby conduct greedy
coordinate descent rule, i.e., x+ = x + ⌘ei⇤ , where ⌘, i⇤
satisfies f (x+⌘ei⇤ ) = mini, f (x+ ei ). With L-Lipchitz
continuity, we have:
f (x + ⌘ei⇤ ) f (x)
L 2
 min hrf (x), ei i +
,i
2
L
= min hrf (x), ei i + k ei k21
,i
2
L
= min hrf (x), xi + k xk21
x
2
L
 min f (x + x) f (x) + k xk21
x
2
L 2 ⇤
⇤
 min f (x + (x
x)) f (x) +
kx
xk21
0 1
2
L 2 ⇤
 min
(f ⇤ f (x)) +
kx
xk21
0 1
2
The last two inequalities are obtained by constraining x
to be of the form (x⇤ x) and by the convexity of f . For
the k-sparse x, and x⇤ , x x⇤ is at most 2k-sparse, and for
any 2k-sparse vector a, kak21  2kkak22 . Hereby we obtain:
L 2 ⇤
min
(f ⇤ f (x)) +
kx
xk21
0 1
2
 min
(f ⇤ f (x)) + Lk 2 kx⇤ xk22
0 1



min

0 1

(f ⇤

f (x))

2kL
µ

2

(f ⇤

f (x))

µ
(f ⇤ f (x))
8kL
µ
Therefore f (x+ ) f ⇤  (1 8kL
)(f (x) f ⇤ ), and when
k ⌧ n, this convergence rate could be much better than
randomized coordinate descent.
=

5. Experiment
In this section, we implement the Doubly-Greedy PrimalDual Coordinate Descent algorithm with Active Sets, and
compare its performance with other state-of-the-art methods
for `1 +`2 -regularized Empirical Risk minimization, including Primal Randomized Coordinate Descent (PrimalRCD)
(Richtárik & Takác, 2014), Dual Randomized Coordinate
Descent (DualRCD, i.e., SDCA) (Shalev-Shwartz & Zhang,
2013b) and the Stochastic Primal-Dual Coordinate Method
(SPDC) (Zhang & Xiao, 2014).
We conduct experiments on large-scale multi-class data sets
with linear and non-linear feature mappings, as shown in
Table 2. For Mnist and Aloi we use Random Fourier (RF)
and Random Binning (RB) feature proposed in (Rahimi &
Recht, 2007) to approximate effect of RBF Gaussian kernel
and Laplacian Kernel respectively. The features generated
by Random Fourier are dense, while Random Binning gives
highly sparse data.
We give results for 2 {0.1, 0.01} and µ 2 {1, 0.1, 0.01},
where Figure 1 shows results for = 0.1, µ = 0.01 and
others can be found in Appendix B. In the above six figures,
we compare the running time with objective function. While
in the below figures, the x-axis is number of iterations. For
the baseline methods, one iteration is one pass over all the
variables, and for our method, it is several (5) passes over
the active sets. From the figures, we can see that in all
cases, DGPD has better performance than other methods.
Notice for clear presentation purposes we use log-scale for
Mnist-RB-time, Aloi-RB-time and RCV-time, where our
algorithm achieves improvements over others of orders of
magnitude.
The result shows that, by exploiting sparsity in both the
primal and dual, DGPD has much less cost per iteration
and thus is considerably faster in terms of training time,
while by maintaining an active set it does not sacrifice much
in terms of convergence rate. Note since in practice we
perform multiple updates after each search, the convergence
rate (measured in outer iterations) can be sometimes even
better than DualRCD.

6. Acknowledgements
I.D. acknowledges the support of NSF via CCF-1320746,
IIS-1546452, and CCF-1564000. P.R. acknowledges the
support of ARO via W911NF-12-1-0390 and NSF via IIS1149803, IIS-1320894, IIS-1447574, and DMS-1264033,
and NIH via R01 GM117594-01 as part of the Joint
DMS/NIGMS Initiative to Support Research at the Interface
of the Biological and Mathematical Sciences.

Doubly Greedy Primal-dual Coordinate Descent for Sparse Empirical Risk Minimization

Table 2. Data statistics and number of non-zero primal & dual variables from DGPD (w/

Data set
Mnist-RF
Aloi-RF
Mnist-RB
Aloi-RB
RCV1-Regions
Sector

#features
10,000
10,000
1,572,556
636,910
47,236
55,197

#nonzero/sample
10,000
10,000
1,000
200
68.38
162.94

#train samples
58,000
90,000
58,000
90,000
199,328
7,793

#test samples
2,000
8,000
2,000
8,000
23,149
961

= 0.1, µ = 0.01).

#classes
10
1,000
10
1,000
225
105

#nz-primal
1,730
891
1,733
1,032
1,123
610

#nz-dual
2,000
1,428
1,208
782
1,447
655

RCV-Time
Mnist-RF-Time

Aloi-RF-Time
DGPD
DualRCD
PrimalRCD
SPDC-dense

10 -10
DGPD
DualRCD
PrimalRCD
SPDC-dense

100

200

300

400

500

600

700

800

900

relative primal objective

10 -5

relative primal objective

relative primal objective

10 -2
10

-5

10 -10

DGPD
DualRCD
PrimalRCD
SPDC-dense

10 -15

1000

100

200

300

400

time

500

600

700

800

900

10 -4

10 -6

10 -8

10 -2

1000

10 0

Mnist-RB-Time

10 2

time

time

Aloi-RB-Time
Sector-Time

10

10 -2

10 -3

10 -4

DGPD
DualRCD
PrimalRCD
SPDC

-1

10 -2

10 -3

10 -4

10 0

10 2

10 0

time

DGPD
DualRCD
PrimalRCD
SPDC-dense

10 -15
600

800

10

10

0

200

600

800

1000

-2

10

-4

10

-6

10

-8

0

50

100

10

Sector-Iteration
DGPD
DualRCD
PrimalRCD
SPDC

DGPD
DualRCD
PrimalRCD
SPDC

-2

10 -3

10 -4

-4

60

80

100

150

iter

relative primal objective

relative primal objective

relative primal objective

400

10 -1

10 -3

iter

10

Aloi-RB-Iteration

10 -2

15

DGPD
DualRCD
PrimalRCD
SPDC-dense

iter

10 -1

40

10

DGPD
DualRCD
PrimalRCD
SPDC-dense

-15

1000

DGPD
DualRCD
PrimalRCD
SPDC

20

5

RCV-Iteration

-10

Mnist-RB-Iteration

0

0

time

10 -5

iter

10

10 -10

10 -15

10 2

relative primal objective

relative primal objective

relative primal objective

10 -10

400

-5

Aloi-RF-Iteration

10 -5

200

10

time

Mnist-RF-Iteration

0

DGPD
DualRCD
PrimalRCD
SPDC

relative primal objective

-1

relative primal objective

relative primal objective

10

DGPD
DualRCD
PrimalRCD
SPDC

10

-5

10

-6

0

50

100

150

200

10 -5

10 -10

10 -15

0

200

iter

Figure 1. Relative Objective versus Time (the upper 2 rows) and versus # iterations (the lower 2 rows) for

400

600

800

iter

= 0.1, µ = 0.01.

1000

Doubly Greedy Primal-dual Coordinate Descent for Sparse Empirical Risk Minimization

References
Bottou, Léon. Large-scale machine learning with stochastic gradient descent. In Proceedings of COMPSTAT’2010, pp. 177–186.
Springer, 2010.
Bousquet, Olivier and Elisseeff, André. Stability and generalization. The Journal of Machine Learning Research, 2:499–526,
2002.
Chang, Yin-Wen, Hsieh, Cho-Jui, Chang, Kai-Wei, Ringgaard,
Michael, and Lin, Chih-Jen. Training and testing low-degree
polynomial data mappings via linear svm. The Journal of Machine Learning Research, 11:1471–1490, 2010.
Chen, Jie, Wu, Lingfei, Audhkhasi, Kartik, Kingsbury, Brian, and
Ramabhadrari, Bhuvana. Efficient one-vs-one kernel ridge regression for speech recognition. In Acoustics, Speech and Signal
Processing (ICASSP), 2016 IEEE International Conference on,
pp. 2454–2458. IEEE, 2016.

Richtárik, Peter and Takác, Martin. Iteration complexity of randomized block-coordinate descent methods for minimizing a
composite function. Mathematical Programming, 144(1-2):
1–38, 2014.
Schmidt, Mark, Le Roux, Nicolas, and Bach, Francis. Minimizing
finite sums with the stochastic average gradient. Mathematical
Programming, pp. 1–30, 2013.
Shalev-Shwartz, Shai and Zhang, Tong. Accelerated mini-batch
stochastic dual coordinate ascent. In Advances in Neural Information Processing Systems, pp. 378–385, 2013a.
Shalev-Shwartz, Shai and Zhang, Tong. Stochastic dual coordinate
ascent methods for regularized loss. The Journal of Machine
Learning Research, 14(1):567–599, 2013b.
Shalev-Shwartz, Shai and Zhang, Tong. Accelerated proximal
stochastic dual coordinate ascent for regularized loss minimization. Mathematical Programming, 155(1-2):105–145, 2016.

Defazio, Aaron, Bach, Francis, and Lacoste-Julien, Simon. Saga:
A fast incremental gradient method with support for nonstrongly convex composite objectives. In Advances in Neural
Information Processing Systems, pp. 1646–1654, 2014.

Sonnenburg, Sören and Franc, Vojtech. Coffin: A computational
framework for linear svms. In Proceedings of the 27th International Conference on Machine Learning (ICML-10), pp.
999–1006, 2010.

Dhillon, Inderjit S, Ravikumar, Pradeep K, and Tewari, Ambuj.
Nearest neighbor based greedy coordinate descent. In Advances
in Neural Information Processing Systems, pp. 2160–2168,
2011.

Wu, Lingfei, Yen, Ian EH, Chen, Jie, and Yan, Rui. Revisiting
random binning features: Fast convergence and strong parallelizability. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
pp. 1265–1274. ACM, 2016.

Hsieh, Cho-Jui, Chang, Kai-Wei, Lin, Chih-Jen, Keerthi, S Sathiya,
and Sundararajan, Sellamanickam. A dual coordinate descent
method for large-scale linear svm. In Proceedings of the 25th
international conference on Machine learning, pp. 408–415.
ACM, 2008.

Xiao, Lin and Zhang, Tong. A proximal stochastic gradient method
with progressive variance reduction. SIAM Journal on Optimization, 24(4):2057–2075, 2014.

Johnson, Rie and Zhang, Tong. Accelerating stochastic gradient
descent using predictive variance reduction. In Advances in
Neural Information Processing Systems, pp. 315–323, 2013.
Lei, Qi, Zhong, Kai, and Dhillon, Inderjit S. Coordinate-wise
power method. In Advances in Neural Information Processing
Systems, pp. 2056–2064, 2016.
Mairal, Julien. Incremental majorization-minimization optimization with application to large-scale machine learning. SIAM
Journal on Optimization, 25(2):829–855, 2015.
Nesterov, Y. Introductory Lectures on Convex Optimization: A
Basic Course. Springer Science & Business Media, 2004.
Nesterov, Yu. Smooth minimization of non-smooth functions.
Mathematical programming, 103(1):127–152, 2005.
Nutini, Julie, Schmidt, Mark, Laradji, Issam H, Friedlander,
Michael, and Koepke, Hoyt. Coordinate descent converges
faster with the gauss-southwell rule than random selection.
arXiv preprint arXiv:1506.00552, 2015.
Qu, Zheng, Richtárik, Peter, and Zhang, Tong. Randomized
dual coordinate ascent with arbitrary sampling. arXiv preprint
arXiv:1411.5873, 2014.
Rahimi, Ali and Recht, Benjamin. Random features for large-scale
kernel machines. In Advances in neural information processing
systems, pp. 1177–1184, 2007.

Yang, Tianbao. Trading computation for communication: Distributed stochastic dual coordinate ascent. In Advances in Neural Information Processing Systems, pp. 629–637, 2013.
Yen, Ian EH, Huang, Xiangru, Zhong, Kai, Ravikumar, Pradeep,
and Dhillon, Inderjit S. Pd-sparse: A primal and dual sparse
approach to extreme multiclass and multilabel classification. In
Proceedings of the 33nd International Conference on Machine
Learning, 2016.
Yen, Ian En-Hsu, Lin, Ting-Wei, Lin, Shou-De, Ravikumar,
Pradeep K, and Dhillon, Inderjit S. Sparse random feature
algorithm as coordinate descent in hilbert space. In Advances in
Neural Information Processing Systems, pp. 2456–2464, 2014.
Yu, Adams Wei, Lin, Qihang, and Yang, Tianbao. Doubly stochastic primal-dual coordinate method for empirical risk minimization and bilinear saddle-point problem. arXiv preprint
arXiv:1508.03390, 2015.
Zhang, Yuchen and Xiao, Lin. Stochastic primal-dual coordinate
method for regularized empirical risk minimization. arXiv
preprint arXiv:1409.3257, 2014.

