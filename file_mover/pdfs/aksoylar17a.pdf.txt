Connected Subgraph Detection with Mirror Descent on SDPs
Cem Aksoylar 1 Lorenzo Orecchia 1 Venkatesh Saligrama 1

Abstract
We propose a novel, computationally efficient
mirror-descent based optimization framework for
subgraph detection in graph-structured data. Our
aim is to discover anomalous patterns present in
a connected subgraph of a given graph. This
problem arises in many applications such as detection of network intrusions, community detection, detection of anomalous events in surveillance videos or disease outbreaks. Since optimization over connected subgraphs is a combinatorial and computationally difficult problem, we
propose a convex relaxation that offers a principled approach to incorporating connectivity and
conductance constraints on candidate subgraphs.
We develop a novel efficient algorithm to solve
the relaxed problem, establish convergence guarantees and demonstrate its feasibility and performance with experiments on real and very large
simulated networks.

1. Introduction
We consider the problem of connected subgraph detection, motivated by statistical anomaly detection on networks where the aim is to determine whether there exists
a set of connected nodes that exhibit anomalous signal values. One example of network anomaly detection is disease outbreak detection (Patil et al., 2003), where the nodes
are associated with counties that are linked by geographical
neighborhood and signal values on nodes depict the number of patients related to a disease. In the existence of a
disease outbreak that spreads geographically, higher signal
values would be present on certain counties that are neighbors of each other, therefore constituting a subgraph structure. Similar problems in different research areas also exist,
such as detection of intrusions in communication or sensor
networks, community detection or video surveillance.
*
Equal contribution 1 Boston University, Massachusetts, USA.
Correspondence to: Venkatesh Saligrama <srv@bu.edu>.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

The detection or estimation of arbitrary connected subgraphs over graph-structured signals is an example of a
structured signal recovery problem and generalizes many
useful types of structures such as intervals or paths
(Addario-Berry et al., 2010; Arias-Castro et al., 2008).
While the existence of structure in terms of connectivity
leads to better statistical complexity in detecting or recovering the anomalous sets compared to arbitrary subsets, efficient characterization of sets obeying the connectivity constraint is important for obtaining practical algorithms for
detection and estimation. In this paper we aim to characterize the space of arbitrary connected subsets of nodes in
a graph via spectral relaxation and propose efficient optimization algorithms that exploit this characterization.
Related work and contributions: Subgraph detection is
a difficult problem since connected subgraphs represent a
combinatorial structure and systematic approaches to characterizing the space of connected subgraphs of a given
graph are relatively recent. Traditional approaches to this
problem usually consider parametric methods, which originate from the scan statistics literature (Glaz et al., 2001)
and consider scanning for specific shapes such as rectangles, circles or neighborhood balls on graphs (Patil et al.,
2003; Kulldorff et al., 2006; Priebe et al., 2005). More recently nonparametric approaches have been considered for
subgraphs with arbitrary shapes on general graphs such as
the simulated annealing approach of (Duczmal & Assuncao, 2004), however it is a heuristic method without statistical or computational guarantees. There is also a line
of work focused on statistical analysis with nonparametric shapes (Addario-Berry et al., 2010; Arias-Castro et al.,
2008; 2012) but are computationally intractable.
More recently, (Qian et al., 2014; Qian & Saligrama, 2014)
proposed linear matrix inequalities as a way to characterize the connectivity of subsets of nodes exactly. This approach is the similar to ours where we also consider an
SDP relaxation with LMI constraints, however we take a
different approach to formulating the problem and its relaxation, with the goal to obtain a convex optimization program that is amenable to efficient iterative methods. In
contrast, the aforementioned method is only applicable to
small problem sizes. Another notable work in this area is
the spectral scan statistic approach proposed by (Sharpnack
et al., 2016), which presents a computationally tractable al-

Connected Subgraph Detection with Mirror Descent on SDPs

gorithm with consistency guarantees. However this method
aims to obtain graph partitions with small conductance and
balanced sizes, in contrast to our formulation that guarantees connected subgraphs. In recent work, (Wu et al.,
2016) consider nonparametric statistics for signals in addition to nonparametric shapes, obtaining a computationally
tractable algorithm by heuristically approximating the underlying graph with trees.
The contribution of this paper is twofold: First, we develop
a convex relaxation of the subgraph detection problem that
results in an semidefinite optimization formulation, with
provable guarantees on the connectivity of the resulting solutions related to the internal conductance of the subgraph.
Second, we propose an efficient iterative framework for optimizing the SDP that scales well with large problem sizes,
and show computational guarantees. One of the major differences of our formulation to those of (Qian et al., 2014;
Qian & Saligrama, 2014) is that prior work enforce a number of constraints that scale with the problem size, whereas
ours only considers a constant number of constraints. Also,
while aforementioned work utilized generalized convex optimization solvers, our formulation allows us to propose
specialized and efficient iterative algorithms.

2. Connected Subgraph Detection
In this section we define the notation and introduce the two
statistical models that we consider for the connected subgraph detection problem. Let G = (V, E) denote an undirected unweighted connected graph with n nodes that is
provided as input to the problem. For i 2 V , we write di
for the degree of vertex i in G and let d be an upper bound
on all di . For a subset S ✓ V , the notation Vol(S)
P indicates the volume measure of S, i.e., Vol(S) =
i2S di .
We also denote by GS = (S, ES ) the subgraph induced by
the subset S. For an input root vertex r 2 V , we write
⇤r = {S ✓ V : r 2 S, GS is connected in G}. Indicator
vectors with notation 1S are defined as n ⇥ 1 vectors with
i-th index 1 if i 2 S and zero otherwise.
We consider observations xv 2 R associated with each
node v 2 V in the graph G. We are concerned with optimization problems of the form

Elevated mean detection: Here, the aim is to detect the
existence of a subgraph S 2 ⇤r comprising of nodes with
an elevated mean compared to the other nodes. A simple
example is the Gaussian elevated mean model, where xv =
µ1{v 2 S} + zv for µ > 0 and zv ⇠ N (0, 2 ). Another
example we consider is the Poisson variant, where xv ⇠
Poisson((1+µ1{v 2 S}) ). We consider the optimization
(1) with the scan statistic
1 X
c1 (S) = p
xi ,
(2)
|S| i2S
which can be shown to correspond to the generalized likelihood ratio test (GLRT) for the Gaussian detection problem,
while also encouraging graph-sparse solutions.

Correlation detection: Another example is the problem
of detecting and estimating a subgraph with correlated
signal values. The canonical statistical model that has
been investigated for this problem is where the signals
are jointly Gaussian random variables X1 , . . . , Xn , where
cov(Xi , Xj ) = 1 if i = j, ⇢ if i, j 2 S and zero otherwise
(Arias-Castro et al., 2012). Note that while related work
consider arbitrary k-sets or special shapes such as intervals
for S, we allow arbitrary connected subgraphs. One simple test for detecting or estimating a correlated subgraph
induced by set S is (1) with the scan statistic
1 X ˆ
c2 (S) =
⌃ij ,
(3)
|S|
i,j2S

ˆ is the estimated covariance matrix which can eiwhere ⌃
ther be defined by a single observation xx> when p = 1 or
multiple observations for p > 1.
Characterizing subgraph connectivity: Rather than focusing on exactly characterizing the connectedness of an
induced subgraph GS , we aim to enforce it by lower bounding the conductance of cuts within GS . For a weighted
graph G = (V, E, w), the conductance of a cut S is:
G (S)

p

max c(S),

S2⇤r

(1)

for a cost function c(·) which depends on xS = {xv }v2S .
We remark that this is a difficult problem due to the combinatorial nature of the constraint, in fact variants of the
prize-collecting Steiner tree problem which is known to be
NP-hard (Johnson et al., 2000) can be reduced to the above
formulation. Below we provide two examples of the setup
that we consider, namely elevated mean detection and correlation detection.

=

w(S, V \ S)
,
Vol(S)

where w(S, V \ S) is the total weight of edges connecting nodes in S to nodes in V \ S. The graph conductance is the lowest conductance among cuts containing at most half of the volume of the graph, i.e., G =
minS⇢V :Vol(S)Vol(V )/2 G (S). Conductance is a natural
graph-partitioning objective because of its intimate connection with the behavior of random walks. It is also widely
used in practice in the design of clustering and segmentation algorithms. We can use conductance to ensure subgraph connectivity by imposing the following constraints1
1

Note that for technical reasons, the conductance GS on the
induced graph GS still employs the definition of volume given by
the larger graph G.

Connected Subgraph Detection with Mirror Descent on SDPs

on the integral solution S:
GS (T )

=

w(T, S \ T )
Vol(T )

> 0,

8T ✓ S \ {r}. (4)

For sufficiently small, i.e., < 1/Vol(V ), this requirement is equivalent to the connectivity condition on GS . It
is useful to notice at this stage that the condition in constraint (4) is stronger than a lower bound on the conductance of the induced subgraph GS . Indeed, for an unweighted graph the constraint (4) implies
GS

=

min
U ✓S:Vol(U )

Vol(S)
2

|E(U, S \ U )|
Vol(U )

3. Relaxation
We next consider a convex relaxation of the objectives of
(2) and (3) as a linear functional of positive semidefinite
matrix variable M . We remark that in the case that x
0 (e.g. the Poisson model), maximizing the scan statistic
c1 (S) is equivalent to maximizing its square
!2
X
1
1 X
c21 (S) =
xi
=
xi xj ,
(5)
|S|
|S|
i,j2S

which has the same form as the statistic c2 (S). Defining
the indicator vector u = 1S and noting that ui = u2i we
can write the quadratic integer program (IP) as
P
i,j xi xj ui uj
P 2
max
.
(6)
u2{0,1}n ,{i:ui =1}2⇤r
i ui

We relax this IP to a semidefinite program (SDP) by turning each element ui to a vector vi 2 Rn such that scalar
multiplication is transformed to inner product and we have
hvi , vj i = 1 if i, j 2 S and zero otherwise. Moreover, we
also enforce non-negativity by requiring that hvi , vj i
0
for all i, j 2 V . We then have
P
i,j xi xj hvi , vj i
P
max
.
(7)
n
2
vi 2R ,{i:|vi |>0}2⇤r
i |vi |
hvi ,vj i 0, 8i,j2V

Using the the Gram matrix M = V V ⌫ 0 instead of the
vectors vi ’s and fixing the trace of M , I · M to 1 w.l.o.g.
(due to the homogeneity of the ratio in the objective), we
obtain the relaxation
>

M2

max

n ,M

0

C ·M

s.t.

{i : |Mii | > 0} 2 ⇤r ,

Next, we propose a novel SDP formulation of the connected subgraph constraint {i : |Mii | > 0} 2 ⇤r , as a
single linear matrix inequality based on a spectral relaxation of the integral conductance constraint of (4).
3.1. Spectral Graph Theory

,

where E(U, S \U ) is the set of edges between sets of nodes
U and S \ U . However, our constraint is stronger than
requiring the induced conductance of GS to be , as the
bound also holds for subsets T ⇢ S comprising more than
half the volume of GS . In the appendix, we provide a brief
comparison with other measures of connectivity.

i2S

where C = xx> and we define n to be the spectrahedron
of unit trace PSD matrices. The relaxation follows along
ˆ This linear functional forexactly for c2 (S) with C = ⌃.
mulation is very general and can be adapted to solve subgraph problems with other general cost functions.

(8)

We start by introducing some basic notation and concepts
from spectral graph theory. For a weighted graph H =
(VH , EH , h), we denote its adjacency by AH and its degree
matrix DH . The Laplacian of H is then defined as LH =
DH AH . The n ⇥ n Laplacian matrix for the graph on V
consisting only of edge {i, j} is Lij = eii + ejj eij eji ,
where eij is an all-zero matrix
P except for a one at index
(i, j). Notice that LH = (i,j)2EH hij Lij . We omit the
subscripts for all graph matrices and sets when referring to
the instance graph G. For a subset S ⇢ V , we denote by
KS the complete graph on S, i.e., the graph having an edge
of weigth di dj between i and j for any i, j 2 S. The spectral gap S of an induced subgraph GS of the input graph G
is defined as the minimum generalized eigenvalue of LGS
1
with respect to Vol(S)
LKS . Equivalently, the spectral gap
is
the
largest
real
such that LGS ⌫ Vol(S) LKS . The
S

star graph Star(r) , rooted at a vertex r 2 V , is the graph
consisting of the n 1 edges of the form (r, i) for all i 2 V ,
each with weight di . We associate to a solution M 2 n
of (8) two weighted graphs, G[M ] and Star(r) [M ], defined
by their Laplacians:
X
X
LG[M ] =
Mij Lij and LStar(r) [M ] =
di Mii Lri .
(i,j)2E

i2V

Cheeger’s inequality: An important result in spectral
graph theory is Cheeger’s inequality (Chung, 1997) that relates the conductance of a graph with the spectrum of its
Laplacian. An equivalent statement for the subgraph conductance that follows from Cheeger’s inequality and relates
the spectral gap of GS to the conductance of GS can be
written as follows.
Theorem 3.1 (Cheeger’s Inequality). For S ✓ V , 2S 
p
2 S.
GS 
The right-hand side of this inequality is proved by rounding
the generalized eigenvector of LGS associated with S to a
low-conductance cut by using the following lemma.
Lemma 3.1. P
Let y
0 and yr = 0. Assume that
2
y T L GS y <
d
y
.
i2S i i Then, there exists ⌧ > 0 such
that the sweep
cut
L⌧ = {i 2 S : yi ⌧ } of vector y has
p
(L
)
<
2
.
GS
⌧

Connected Subgraph Detection with Mirror Descent on SDPs

3.2. Relaxing the Conductance Requirement
Our proposed relaxation of the integral conductance constraint (4) with parameter is the following:
2

LG[M ] ⌫

2

LStar(r) [M ]

1
L GS
|S|

and LStar(r) [MS ] =

1
L (r) .
|S| StarS

Then, our proposed constraint becomes LGS
⌫
2
. We now show that this constitutes a relaxation
2 LStar(r)
S
of constraint (4). This can be seen as a variant of Cheeger’s
inequality for our relaxed notion of conductance in (9). The
proof of the following theorem appears in the appendix.
Theorem 3.2. For S ✓ V , if, for all T ✓ S, r 2
/ T and
2
(T
)
,
then
L
⌫
L
.
(r)
GS
GS
2
Star
S

Moreover, for a candidate integral solution MS , in the same
way as the integral constraint lower bounds the conductance of the induced subgraph GS , our relaxation can be
shown to lower bound the spectral gap of GS . This result
is a simple consequence of Schur’s complementation.
Lemma 3.2. For S P⇢ V with r 2 S, let y =
(Vol(S)
dr ) e r
dj ej . Then, LStar(r) =
S
⇥
⇤ j2S,j6=r
1
>
.
Vol(S) LKS + yy

Applying this lemma to (9), we observe that our constraint,
applied to an integral solution MS , implies a lower bound
2
of 2 on the induced spectral gap S through the inequality
2

L GS ⌫

2

2

LStar(r) [M ] . Then our relaxation is given by
max

(9)

To see how this relaxes the integral constraint, take MS =
1
>
|S| 1S 1S to be an integral solution corresponding to a subset S ✓ V . We have:
LG[MS ] =

notation for its constraints. Let Q (M ) ⌫ 0 be our relaxed connectedness constraint, i.e., Q (M ) = LG[M ]

2

LStar(r) ⌫

LK S .
S
2
2 Vol(S)
Finally, we prove that if any feasible candidate M that satisfies (9) is rounded to a subset S in a certain way, then the
connectivity of subgraph GS is ensured. This result shows
that the inequality constraint (9) is sufficent to ensure connectivity in our framework.
Theorem 3.3. For any > 0 and M ⌫ 0 that satisfies (9),
the subgraph GŜ for induced subset Ŝ = {i 2 V : Mii >
0} is connected.
Proof of Theorem 3.3 is in the appendix. It follows from an
alternative formulation of constraint (9) based on effective
resistance in electrical networks.
3.3. Primal and Dual Formulations
In this subsection, we study the dual form of our relaxation, which will be important in designing an efficient iterative algorithm. We start by introducing some shorthand

M 2 n ,M 0,
Q (M )⌫0

(10)

C · M.

We now write the SDP dual of our relaxation. We consider a scalar ↵ as the Lagrange multiplier corresponding
to constraint I · M = 1, and matrices Y, Z 2 Rn⇥n correspondingP
to Q (M ) ⌫ 0 and M P0 respectively. Let
P (Y ) = (i,j)2E (Lij · Y )eij
i2V di (Lri · Y )eii
be the transpose of the constraint Q , i.e., P (Y ) · M =
Q (M ) · Y . The dual can then be written as:
min

↵
C + P (Y ) + Z
↵

0, Y ⌫ 0, Z

↵I
0

An intuitive interpretation for this dual follows from considering P (Y ) as a matrix of gains to be added to the objective C as to force the primal solution M towards feasibility. In particular, P (Y ) establishes a gain of Lij · Y for
including edge {i, j} in the primal solution and a cost of
Lri · Y for including vertex i in the primal solution. Naturally, vertices are more expensive the further they are from
the root r in the dual solution and edges are more beneficial
if they bridge longer distances in the dual.
Distinctive Properties of Our Relaxation We wish to
highlight two important (and rare) structural properties of
our relaxation. The first property relates to the form of
the dual. We have C
0, by definition for the elevated mean problem with nonnegative signal values and
with high probability for correlation detection. Then the
term C + P (Y ) in the dual constraint is the sum of a
nonnegative matrix plus a diagonal matrix. By the PerronFrobenius Theorem, the top eigenvector of this matrix has
nonnegative components, allowing us to assume that Z = 0
wlog. We will use the same reasoning in the next section
to show that we do not need to explicitly enforce the n2
element-wise non-negativity constraints corresponding to
M
0, as our dual formulation will automatically yield
such solutions. This is a great advantage of our relaxation
as enforcing the M
0 constraints is known to be a computational roadblock to the efficient solution of SDP relaxations of {0, 1}-integral problems.
The second property has a similar flavor, but it concerns
the primal optimal solution. It is captured by the following
theorem, which is proved in the appendix.
Theorem 3.4. When C 0, the relaxation 10 always has
an optimal solution of rank-1. Moreover, any higher rank
solution M can be turned into a rank-1 solution mm> such
that Mii = m2i .

Connected Subgraph Detection with Mirror Descent on SDPs

The fact that a rank-1 solution is a remarkable property for
a SDP relaxation, making the fractional solution easier to
visualize and hopefully easier to round to integral.
Future work: In this work, we did not perform a theoretically study of the approximation guarantees achievable in
rounding our relaxation to an integral solution in the worstcase. The rank-1 property of the optimal solution should
be useful in this pursuit. At the same time, we believe that
additional constraints may be required to obtain meaningful approximation guarantees in the worst-case. This is an
interesting direction for future work.
Statistical Bounds: We omit developing statistical analysis of the proposed approach for subgraph detectability in
this paper for lack of space (see (Aksoylar, 2017) for analysis for simple graphs). We can derive statistical guarantees for grid graphs similar to (Qian & Saligrama, 2014)
based on analyzing primal and dual values. In particular
the primal provides a bound on the value of the positive
hypothesis (anomaly), while a feasible solution to the dual
provides an upper-bound of the value for null hypothesis.
Detectability bounds for elevated mean follows by comparing the primal value with the dual.

4. Mirror Descent on SDPs

max

n ,s

C ·M

s

s.t.

Q (M ) + s · · D ⌫ 0. (11)

Recalling that D is the degree matrix of G, the last term
provides a measure of how violated the SDP constraint is.
For now, we fix as a parameter of our algorithm. We
discuss choices of at the end of this section.
Introducing the Lagrange multiplier Y ⌫ 0 corresponding
to the constraint 1 · Q (M ) + sD ⌫ 0, we then obtain the
saddle point problem
max min

M2

n ,s

Y ⌫0

C ·M

1
s + Y · ( · Q (M ) + sD),

from which we obtain the dual
min f (Y ), where f (Y ) = max

Y2

D
n

M 2 n,
M 0

Theorem 4.1. Let f be a convex function over the spec1/2
rY f (Y )D 1/2 k  L for
trahedron D
n such that kD
D
all Y 2 n . For a parameter ⌘ = L✏2 , the mirror descent
update takes the following form at iteration t:
⇣
hP
i
⌘
t 1
(j)
1/2
exp
⌘ · D 1/2
r
f
(Y
)
D
Y
j=0
⇣
hP
i
⌘
Y (t) =
t 1
(j) ) D 1/2
D · exp
⌘ · D 1/2
r
f
(Y
Y
j=0
With this update, the algorithm achieves the following performance guarantee, where f ⇤ is the minimum of f :
r
log n
T
⇤
f (Y ) f  L ·
.
T

To apply mirror descent as described in the previous theorem, we need access to the gradient of f at Y (t) . By Danskin’s Theorem (Bertsekas et al., 2003), this is given by:
rY f (Y (t) ) =

We first consider a modification of our original SDP by
adding the slack variable s
0. For some fixed margin
value
0 we write
M2

and its application in the spectahedron setup. For the purposes of this section, we simply state the following theorem, which is a simple consequence of Theorem 5.2.1 in
(Ben-Tal & Nemirovski, 2015).

✓

C+

1

◆
· P (Y ) ·M,

and we defined D
n to be the D-spectrahedron {X ⌫ 0 :
D · X = 1}. For this dual optimization over Y we utilize the mirror descent method, which is the optimal optimization algorithm for non-smooth functions in the blackbox model. We refer the reader to Section 5.2 of (Ben-Tal
& Nemirovski, 2015) for more details on mirror descent

1

· Q (M (t) ),

M (t) = arg maxM 2

n ,M

0 (C

+

1

· P (Y (t) )) · M.

Hence, computation of the gradient requires finding M (t) ,
which plays the role of the primal update at time t. However, this is just the rank-1 matrix given by the projection
over the top eigenvector of C + 1 · P (Y (t) ), where M 0
is once again ensured by Perron-Frobenius. The following
lemma provides us with a bound on the Lipschitz parameter L of our objective f . Its straightforward proof appears
in the appendix.
Lemma 4.1. For all Y
kD 1/2 rY f (Y )D 1/2 k  2 .

2

D
n,

we

have:

With this setting of L, Theorem 4.1 yields the following
convergence bound for our mirror descent algorithm.
Theorem 4.2. Algorithm 1 converges
⇣ to⌘ an ✏-additive apn
steps.
proximation of optimal in T = O log
2 ✏2
Moreover, each iteration consists of computing the top
eigenvector of a non-negative matrix and the matrix exponential of a the sum of a Laplacian and a rank-1 term (cf.
Lemma 3.2). Thanks to recent breakthrough theoretical results, both of these objects can be approximated sufficiently
closely in almost-linear-time (Orecchia et al., 2012; Cohen
et al., 2016). In practice, existing iterative solvers, combined with the use of the Johnson-Lindenstrauss Lemma to
keep a low-dimensional sketch of the matrix exponential,

Connected Subgraph Detection with Mirror Descent on SDPs

Algorithm 1 Mirror Descent Algorithm
Input: C, , r, , ✏
Output: M̂
2
✏
L
, ⌘
L2
1
(0)
(0)
Y
0
Tr(D) In , G
for t = 1, . . . , T do
v
eig C + P (Y (t 1) )
M (t)
vv >
G(t)
G(t 1) + 1 · Q (M (t) )
Y (t)
exp ⌘ D 1/2 G(t) D 1/2
1
(t)
Y
Y (t)
D·Y (t)
end for P
T
1
(t)
M̂
t=1 M
T

already provide a very efficient computational approach to
this problem, as we demonstrate in our experiments.
We formally present the resulting algorithm in Algorithm 1
for our function f , where eig(·) operator returns the eigenvector corresponding to the largest eigenvalue.
2

Choosing the margin : If s
, it is possible to prove
that the SDP constraint is trivially satisfied for any M in
n at a cost of s in the objective (which follows from the
fact that LStar(r)
2D). To avoid such trivial solutions,
we wish to set the margin to be sufficiently small. In
2
particular, we should have  4✏ . However, from a worstcase point of view, this setting of may be insufficient to
obtain a solution that can be rounded to a connected subgraph. The choice of in this case depends on the rounding procedure used and its sensitivity. As a formal study
of the rounding of our relaxation is beyond of the scope of
this paper, we cannot provide a definitive setting of . Our
preliminary calculations show⇣ that,
⌘ from a theoretical point
2
of view, a setting of = O K should be sufficient for
rounding, where K is the size of the optimal set. In practice, we have found that setting to be order O( 2 ) suffices
for most of the examples we considered.
⇣
⌘This corresponds
n
to a number of iterations that is O log
.
4 ✏2

5. Experiments
We present experiments on two datasets: a real world geographical network of disease outbreaks and elevated mean
detection on very large random geometric graphs. In the
former we compare the statistical detection performance of
our mirror descent (MD) algorithm with subgraph detection methods from related work. For the latter we demonstrate the scalability of our method on large graphs.
5.1. Disease Outbreak Detection
We consider a geographical map and its corresponding network that are illustrated in Figures 1b and 1a respectively,

with 129 nodes representing counties in the northeastern
United States and average degree 4.7. The ground truth
cluster of 16 nodes for the anomalous case and the chosen anchor node are also illustrated. Following (Patil et al.,
2003) and (Qian et al., 2014; Qian & Saligrama, 2014), we
consider an elevated mean Poisson formulation for modeling the diseased population, where the number of disease
cases yi for a county i is given by yi ⇠ Poisson(Ni 0 )
where Ni is the population of the county, whereas for
anomalous counties we have yi ⇠ Poisson(Ni 1 ). We
consider 0 = 5 ⇥ 10 5 for the base disease rate and different 10 ratios {1.1, 1.3, 1.5} corresponding to different
SNR values. As our test statistic we consider the disease
yi
rate per person xi = N
. One sample realization for the
i
anomaly case with high SNR 10 = 4 appears in Fig. 1c.
To compare the performance with MD as proposed in Algorithm 1, we consider several other methods in the related literature, including the LMI-test (LMIT) method
of (Qian & Saligrama, 2014), simulated annealing (SA)
of (Duczmal & Assuncao, 2004) and the nearest-ball test
(NB), which is a parametric method that scans over nearestneighbor balls of different sizes for all nodes. For the MD
method we consider the optimization value xx> · M as the
scan statistic, with T = 100 iterations, ⌘ = 5 and different
values to quantify the size and conductance of the anomalous graph. For LMIT we use the same anchor node as MD,
anomaly size |S| = 16 corresponding to the ground truth
and consider scan statistic x> diag(M ). We search over a
range of values for parameter
. For SA and NB we conP
i2S xi
sider the test statistic p
. We initialize SA with the
|S|

result from NB and run for 40 restarts. To quantify detection performance, we threshold the scan statistics given by
the algorithms with various threshold values and compute
missed detection and false positive rates over a number of
samples (50 for MD and LMIT, 25 for SA and NB) generated from both H0 and H1 . We then compute the area under
the curve (AUC) generated by the pairs of missed detection
and false positive rates corresponding to threshold values.

Sensitivity of MD to the choice of : We first investigate
the sensitivity of detection performance of MD to , which
serves the purpose of parameterizing the internal conductance of candidate subgraphs. We note that unlike (Qian
et al., 2014; Qian & Saligrama, 2014), we do not explicitly specify or search over different cluster sizes, but size
information is also implicitly incorporated in . We run
MD on the range of values 0.01 to 5 in 10 logarithmic intervals. We illustrate the obtained AUC values for different
SNR’s in Figure 2. We observe that while optimal values
differ slightly with different SNR levels, the 0.3–0.7 value
range is mostly optimal in all cases. This is in accordance
with our expectations, since the size and conductance of the
ground truth anomalies do not change.

Connected Subgraph Detection with Mirror Descent on SDPs
−4

x 10
5
4

Anchor

3
Anomalous

2
Normal

1
0

(a) Graph representation of the county (b) Ground truth anomalous cluster and (c) Sample realization of disease rates for
graph.
anchor node.
the anomalous case.
Figure 1. Disease outbreak detection in northeastern United States counties.
1

AUC

λ1/λ0 = 1.1
0.95

λ1/λ0 = 1.3

MD
LMIT
SA
NB

λ1/λ0 = 1.5

0.9

AUC

0.85
0.8

1.1
0.74
0.65
0.57
0.57

1/ 0

1.3
0.79
0.81
0.67
0.67

1.5
0.92
0.86
0.72
0.68

Runtime
0.8s
3s
⇠3m
5s

Table 1. AUC performance of algorithms with different SNRs.

0.75
0.7
0.65

−2

10

−1

0

10

10

1

10

γ

Figure 2. Performance of MD algorithm for different

values.

Comparison to related methods: We also compare AUC
performance of MD to aforementioned methods and tabulate the results in Table 1. For MD we use a value of
0.7 and for LMIT we use a value of 0.3 which we observed to perform best empirically. We see that MD performs relatively similar to LMIT, with better performance
at some SNR levels. This is expected since the LMI connectivity constraints in both methods are very similar, even
though the relaxation to the space of matrices M differ.
On the other hand SA and NB perform worse, with SA
not significantly improving upon the results of NB. It is
also notable that the performance of these three methods
seem low when compared to their performance in (Qian &
Saligrama, 2014), which can be partially explained by the
different scan statistics used: the Poisson likelihood test in
contrast to the simpler linear form we specified above to
be better in line with the scan statistic of MD. It is also
possible that the performance of SA can be improved with
a larger number of restarts. We also provide the average
runtime for the recovery methods for a single set of measurements in Table 1, where the experiments were run on
MATLAB on a computer with an Intel i5 4590 processor.
5.2. Random Geometric Graphs
We also conducted experiments on simulated geometric
graphs to demonstrate the scalability of our method. For
this, we generated n points uniformly on the hypercube

[ 1, 1]D and created approximate k-NN graphs using the
ANN library (Arya et al., 1998). We generated anomalous
clusters by determining points that fall in hyperellipsoids
centered at the origin of the space. We consider different
hyperellipsoid axes lengths that correspond to different internal subgraph conductance.
Memory and run-time scalability: For very large graphs
with n nodes, storing on memory and operating on nonsparse n ⇥ n matrices present major problems for computational feasibility. While for primal variable M we work
directly with vectors v in Alg. 1, we also consider a lowerrank approximation scheme for representing dual variable
Y and an approximate computation for the matrix exponential. We define an n ⇥ k matrix Yk such that we have the
(t)
update Yk / exp ⌘Q (M (t) W (t) , where W (t) is an
n ⇥ k matrix with IID elements N (0, k1 ). With this defini(t) (t)>
tion we have the approximation Y (t) ⇡ Yk Yk
exploit(t)
ing the Johnson-Lindenstrauss lemma, for Yk normalized
appropriately. We then utilize the Leja method (Caliari
et al., 2016) to directly compute the action of the matrix
exponential on vectors. We again consider elevated mean
detection with yi ⇠ Poisson( 0 ) for non-anomalous nodes
and yi ⇠ Poisson( 1 ) otherwise. We specifically consider
10-NN graphs with parameters n = 104 and D = 3. We
consider two types of anomalous clusters: “thick” cluster
as a sphere with radius r and “thin” cluster as an ellipsoid
with radii (8r, r, r), where r is chosen such that on average
the clusters would contain K = 40 nodes.
Performance for different conductance anomalies and
comparison: We investigate the AUC performance of MD
and compare to the NB scan statistic over 40 sample realizations of measurements, for different SNR ratios 1 / 0
in Table 2 where we fix 0 = 100. Due to the memory and
run-time scaling of SA and LMIT it was not feasible to ap-

Connected Subgraph Detection with Mirror Descent on SDPs

Thick
Thin

MD
NB
MD
NB

1.1
0.71
0.70
0.70
0.68

1/ 0

1.3
0.93
0.92
0.92
0.90

1.5
0.99
0.96
0.99
0.92

Table 2. AUC performance of MD and NB with different SNR
values and cluster shapes.

Performance for graph sizes and iterations: We also investigate the effect of graph size n in conjunction with the
number of iterations T on the accuracy as quantified by
the detection AUC. We again consider random geometric
graphs generated with parameters in the previous experiments for 10 = 1.3, vary graph size n from 4000 to 10000
in 2000 increments and consider ellipsoidal anomalies of
radii (4r, r, r) encapsulating approximately K = 40 nodes
2
with 2 = 10 3 . We plot the AUC performance vs. number of iterations for different graph sizes in Figure 3. First,
we observe that detection accuracy deteriorates for larger
graph sizes as expected. Moreover, the rate of increase
in the accuracy with the increasing number of iterations
T does not seem to change too much for different sizes
n, which lends empirical support to Theorem 4.1 regarding
the sublinear relationship between accuracy and n. We also
plot the average run-time per iteration vs. graph size with
standard deviation error bars in Fig. 4, which illustrates
the approximately linear scaling of run-time per iteration
as discussed in Sec. 4.
Performance vs. Anomaly size: We investigate detection
performance for different anomalous cluster sizes K = |S|
in Figure 5. We again consider a fixed SNR 10 = 1.3
for n = 10000 and ellipsoidal anomalies of radii (4r, r, r),
with varying r such that K varies between 20 and 80. We
performed T = 300 iterations and used the same value of
2
3
for all K, as different values did not result in
2 = 10
a significant accuracy improvement in our cross-validation

0.95

AUC

0.9

0.85
n = 4000
n = 6000
n = 8000
n = 10000

0.8

0.75
50

100

150
200
Number of iterations

250

300

Figure 3. AUC performance for different graph sizes n for differing number of total iterations T .
0.18
Time per iteration (s)

AUC

1

0.16
0.14
0.12
0.1
0.08
2000

8000 10000 12000
n
Figure 4. Run-time per iteration vs. graph size n.

4000

6000

experiments. This in turn confirms the robustness of the
choice of which we also observed for the county graph
dataset. As seen the detection accuracy increases rapidly
with K for a fixed per-node SNR. This is in line with the
theoretical scaling behavior in (Qian & Saligrama, 2014).

1
0.95
AUC

ply these methods to the large graphs. For MD, we chose
2
3
for the thick cluster and 5 ⇥ 10 4 for the thin
2 = 10
one. We chose a random node in the cluster as the anchor,
k = 10 vectors for approximating Y and ran the algorithm
for T = 300 iterations. From the results we observe that
MD and NB perform similarly on thick clusters. This is expected since a spherical cluster is the optimal scenario for
NB, whereas MD still considers different shaped and sized
clusters for the given gamma. However for the thin cluster
we observe that MD improves upon NB significantly as expected, especially for higher SNR values. We also note that
each iteration of MD takes about 1s and empirically scales
linearly with n (as we demonstrate in the next set of experiments), where we applied the method for graphs with up
to 105 nodes.

0.9
0.85
0.8

20

40

K

60

80

Figure 5. AUC performance for different anomaly sizes K.

Connected Subgraph Detection with Mirror Descent on SDPs

References
Addario-Berry, Louigi, Broutin, Nicolas, Devroye, Luc, Lugosi,
Gábor, et al. On combinatorial testing problems. The Annals
of Statistics, 38(5):3063–3092, 2010.
Aksoylar, Cem. Discovery of Low-Dimensional Structure in
High-Dimensional Inference Problems. PhD thesis, Boston
University, Boston, MA, 2017.
Arias-Castro, Ery, Candès, Emmanuel J, Helgason, Hannes, and
Zeitouni, Ofer. Searching for a trail of evidence in a maze. The
Annals of Statistics, pp. 1726–1757, 2008.
Arias-Castro, Ery, Bubeck, Sébastien, Lugosi, Gábor, et al. Detection of correlations. The Annals of Statistics, 40(1):412–
435, 2012.
Arya, Sunil, Mount, David M., Netanyahu, Nathan S., Silverman, Ruth, and Wu, Angela Y. An optimal algorithm for
approximate nearest neighbor searching fixed dimensions. J.
ACM, 45(6):891–923, November 1998. ISSN 0004-5411. doi:
10.1145/293347.293348.

Orecchia, Lorenzo, Sachdeva, Sushant, and Vishnoi, Nisheeth K.
Approximating the exponential, the Lanczos method and an
Õ(m)-time spectral algorithm for balanced separator. In Proceedings of the 44th symposium on Theory of Computing STOC ’12, volume 2, pp. 1141–1160, New York, NY, USA,
November 2012. ACM Press. doi: 10.1145/2213977.2214080.
Patil, GP, Taillie, C, et al. Geographic and network surveillance
via scan statistics for critical area detection. Statist. Sci., 18(4):
457–465, 2003.
Priebe, Carey E, Conroy, John M, Marchette, David J, and Park,
Youngser. Scan statistics on Enron graphs. Computational &
Mathematical Organization Theory, 11(3):229–247, 2005.
Qian, J. and Saligrama, V. Efficient minimax signal detection on
graphs. In Advances in Neural Information Processing Systems
(NIPS), pp. 2708–2716. Curran Associates, Inc., 2014.
Qian, J., Saligrama, V., and Chen, Y. Connected sub-graph detection. In Proc. of the Seventeenth Int. Conf. on Artificial Intelligence and Statistics (AISTATS), pp. 796–804, Reykjavik,
Iceland, April 2014.

Ben-Tal, Aharon and Nemirovski, Arkadi. Lectures on modern
convex optimization. 2015.

Sharpnack, James, Rinaldo, Alessandro, and Singh, Aarti. Detecting anomalous activity on networks with the graph Fourier
scan statistic. IEEE Transactions on Signal Processing, 64(2):
364–379, 2016.

Bertsekas, Dimitri P, Nedic, Angelia, and Ozdaglar, Asuman E.
Convex Analysis and Optimization. Athena Scientific, 2003.
ISBN 1-886529-45-0.

Vishnoi, Nisheeth K. Laplacian solvers and their algorithmic applications. Theoretical Computer Science, 8(1-2):1–141, 2012.

Caliari, Marco, Kandolf, Peter, Ostermann, Alexander, and
Rainer, Stefan. The Leja method revisited: Backward error
analysis for the matrix exponential. SIAM Journal on Scientific Computing, 38(3):A1639–A1661, 2016. doi: 10.1137/
15M1027620.
Chung, F. R. K. Spectral Graph Theory, volume 92. American
Mathematical Society, 1997.
Cohen, Michael B., Kelner, Jonathan A., Peebles, John, Peng,
Richard, Rao, Anup, Sidford, Aaron, and Vladu, Adrian.
Almost-linear-time algorithms for markov chains and new
spectral primitives for directed graphs. CoRR, abs/1611.00755,
2016. URL http://arxiv.org/abs/1611.00755.
Duczmal, Luiz and Assuncao, Renato. A simulated annealing
strategy for the detection of arbitrarily shaped spatial clusters. Computational Statistics & Data Analysis, 45(2):269–
286, 2004.
Glaz, Joseph, Naus, Joseph, and Wallenstein, Sylvan. Scan Statistics. Springer Science & Business Media, 2001.
Johnson, David S., Minkoff, Maria, and Phillips, Steven. The
prize collecting steiner tree problem: Theory and practice. In
Proceedings of the Eleventh Annual ACM-SIAM Symposium on
Discrete Algorithms, SODA ’00, pp. 760–769, Philadelphia,
PA, USA, 2000. Society for Industrial and Applied Mathematics. ISBN 0-89871-453-2.
Kulldorff, Martin, Huang, Lan, Pickle, Linda, and Duczmal, Luiz.
An elliptic spatial scan statistic. Stat. Med., 25(22):3929–3943,
2006.

Wu, Nannan, Chen, Feng, Li, Jianxin, Zhou, Baojian, and Ramakrishnan, Naren. Efficient nonparametric subgraph detection using tree shaped priors. In Thirtieth AAAI Conference on
Artificial Intelligence, 2016.

Acknowledgements: This material is based upon work
supported in part by NSF Grants CCF: 1320566, NSF
Grant CNS: 1330008 NSF CCF: 1527618, the U.S. DHS,
Science and Technology Directorate, Office of University
Programs, under Grant Award 2013-ST-061-ED0001, and
by ONR contract N00014-13-C-0288. The views and conclusions contained in this document are those of the authors
and should not be interpreted as necessarily representing
the social policies, either expressed or implied, of the NSF,
U.S. DHS, ONR or AF.

