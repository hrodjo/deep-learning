Spectral Learning from a Single Trajectory under Finite-State Policies

Borja Balle 1 Odalric-Ambrym Maillard 2

Abstract
We present spectral methods of moments for
learning sequential models from a single trajectory, in stark contrast with the classical literature that assumes the availability of multiple i.i.d.
trajectories. Our approach leverages an efficient
SVD-based learning algorithm for weighted automata and provides the first rigorous analysis
for learning many important models using dependent data. We state and analyze the algorithm under three increasingly difficult scenarios: probabilistic automata, stochastic weighted automata,
and reactive predictive state representations controlled by a finite-state policy. Our proofs include novel tools for studying mixing properties
of stochastic weighted automata.

1. Introduction
Spectral methods of moments are a powerful tool for designing provably correct learning algorithms for latent variable models. Successful applications of this approach include polynomial-time algorithms for learning topic models (Anandkumar et al., 2012; 2014), hidden Markov models (Hsu et al., 2012; Siddiqi et al., 2010; Anandkumar
et al., 2014), mixtures of Gaussians (Anandkumar et al.,
2014; Hsu & Kakade, 2013), predictive state representations (Boots et al., 2011; Hamilton et al., 2014; Bacon et al.,
2015; Langer et al., 2016), weighted automata (Bailly,
2011; Balle et al., 2011; Balle & Mohri, 2012; Balle et al.,
2014a;b; Glaude & Pietquin, 2016), and weighted contextfree grammars (Bailly et al., 2010; Cohen et al., 2013;
2014). All these methods can be split into two classes depending on which spectral decomposition they rely on. The
first class includes algorithms based on an Singular Value
Decomposition (SVD) decomposition of a matrix contain-

ing (estimated) moments of the target distribution (e.g. Hsu
et al. (2012); Boots et al. (2011); Balle et al. (2014a)). The
other class includes algorithms relying on symmetric tensor decomposition methods (e.g. Anandkumar et al. (2014);
Hsu & Kakade (2013)). The advantage of tensor methods is
that their output is always a proper probabilistic model. On
the other hand, SVD methods, which do not always output
a probabilistic model, provide learning algorithms for models which are provably non-learnable using tensor methods. A notable example is the class of stochastic weighted
automata that do not admit a probabilistic parametrization
(Jaeger, 2000; Denis & Esposito, 2008).
Natural language processing (NLP) and reinforcement
learning (RL) are the two main application domains of
spectral learning. For example, SVD methods for learning weighted context-free grammars have proved very successful in language-related problems (Cohen et al., 2013;
Luque et al., 2012). In the context of RL, efficient SVD
methods for learning predictive state representations were
proposed in (Boots et al., 2011; Hamilton et al., 2014). A
recent application of tensor methods to RL is given in (Azizzadenesheli et al., 2016), where the authors use a spectral
algorithm to obtain a PAC-RL learning result for POMDP
under memory-less policies. All these results have in common that they provide learning algorithms for models over
sequences. However, there is a fundamental difference between the nature of data in NLP and RL. With the exception of a few problems, most of NLP ‚Äúsafely‚Äù relies on
the assumption that i.i.d. data from the target distribution
is available. In RL, however, the most general scenario assumes that the learner can only collect a single continuous
trajectory of data while all existing analysis of the SVD
method for sequential models1 rely on the i.i.d. assumption
(Hsu et al., 2012; Balle & Mohri, 2015; Glaude & Pietquin,
2016). Regarding tensor methods, (Azizzadenesheli et al.,
2016) gave the first analysis under dependent data satisfying certain mixing conditions.

Amazon Research, Cambridge, UK (work done at
Lancaster University) 2 Inria Lille - Nord Europe, Villeneuve d‚ÄôAscq, France. Correspondence to: Borja Balle
<pigem@amazon.co.uk>, Odalric-Ambrym Maillard <odalric.maillard@inria.fr>.

The purpose of this paper is to provide the first rigorous
analyses of spectral SVD methods for learning sequential
models from non-i.i.d. data. We provide efficient algorithms with provable guarantees for learning several sequential models from a single trajectory. Specifically, we

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

1
See (Thon & Jaeger, 2015) for a survey of sequential models
learnable with SVD methods.

1

Spectral Learning from a Single Trajectory under Finite-State Policies

consider three models: probabilistic automata, stochastic
weighted automata, and PSRs under control from a finitestate policy. The first two results extend existing results in
the literature for i.i.d. data (Hsu et al., 2012; Balle et al.,
2014a). The last result is an analog of the environment
learning result for POMDP ‚Äì not the whole RL result ‚Äì
of (Azizzadenesheli et al., 2016), with the difference that
our analysis provides guarantees under a much larger set
of policies (finite-state, as opposed to memory-less). This
result can also be interpreted as an extension of the batchbased PSR learning algorithm from (Boots et al., 2011)
to the non-i.i.d. case, although they do not provide finitesample guarantees. Our analysis is especially relevant since
the single trajectory spectral algorithm we analyze has been
used previously without an explicit instantiation or analysis. For example, (Kulesza et al., 2015; Shaban et al., 2015)
present experiments with datasets containing single or few
long trajectories which are broken into short subsequences
and given as input to an spectral algorithm designed for
i.i.d. data. A more detailed list of our contributions is as
follows:
(1) A single-trajectory spectral-learning algorithm for
probabilistic automata whose sample complexity depends on the mixing properties of the target automaton
(Section 3).
(2) An extension of this result showing that the same algorithm also learns stochastic weighted automata (Section 4). In this case the analysis is more involved,
and requires a novel notion of mixing for stochastic
weighted automata and tools from the theory of linearinvariant cones (Berman & Plemmons, 1994).
(3) A generalization of the algorithm that learns reactive
PSR controlled by a finite-state stochastic policy (Section 5). We provide for this algorithm finite-sample
bounds under a simple exploration assumption.
The most important tool in our analysis is a concentration
inequality for functions of dependent random variables.
These inequalities depend on the mixing coefficients of the
underlying process. We provide technical estimates for the
relevant mixing coefficients in each of the three cases listed
above. Our goal for future work is to extend (3) to prove
a PAC-RL for PSR under finite-state policies. We also
think that the tools we develop to prove (2) can be used to
improve the sample complexity of algorithms for learning
stochastic weighted automata in the i.i.d. case.
In Section 2, we start by recalling several facts about
weighted automata, spectral learning, and mixing that will
play a role in the sequel. For space reasons, most of our
proofs are deferred to the Supplementary Material.

2. Background
Let Œ£ be a finite alphabet, Œ£? denote the set of words of
finite length on Œ£, Œ£œâ the set of all infinite words on Œ£, and
 be the empty word. Given two sets of words U, V ‚äÇ Œ£?
we write U ¬∑ V to denote the set of words {uv|u ‚àà U, v ‚àà V}
obtained by concatenating all words in U with all words in
V. Let P(Œ£œâ ) be the set of probability distributions over
Œ£œâ . A member œÅ ‚àà P(Œ£œâ ) is called a stochastic process
and a random infinite word Œæ ‚àº œÅ is called a trajectory.
Weighted and probabilistic automata A weighted finite automaton (WFA) with n states is a tuple A =
hŒ±, Œ≤, {AœÉ }œÉ‚ààŒ£ i where Œ±, Œ≤ ‚àà Rn are vectors of initial and
final weights respectively, and AœÉ ‚àà Rn√ón are matrices of
transition weights. A weighted automaton A computes a
function fA : Œ£? ‚Üí R given by fA (w) = Œ±> Aw Œ≤ where
Aw = Aw1 ¬∑ ¬∑ ¬∑ Awt for w = w1 ¬∑ ¬∑ ¬∑ wt . A WFA is minimal
if there does not exist another WFA with less states computing the same function. A WFA A is stochastic if there
exists a stochastic process œÅ such that for every w ‚àà Œ£? ,
fA (w) = P[Œæ ‚àà wŒ£œâ ]; that is, A provides a representation for the probabilities of prefixes under the distribution
of œÅ. A weighted automaton is irreducible if the labelled
directed graph with n vertices obtained by adding a transition from i to j with label œÉ whenever AœÉ (i, j) 6= 0 is
strongly connected. It can be shown that irreducibility implies minimality, and that almost all WFA are irreducible in
the sense that the set of irreducible WFA are dense on the
set of all WFA (Balle et al., 2017).
A probabilistic finite automaton (PFA) is a stochastic WFA
A = hŒ±, Œ≤, {AœÉ }i where the weights have a probabilistic
interpretation. Namely, Œ± is a probability distribution over
[n], AœÉ (i, j) is the probability of emitting symbol œÉ and
transitioning to state j starting from state i, and Œ≤(i) = 1
for all i ‚àà [n]. It is immediate to check that a PFA satisfying these conditions induces a stochastic process. However
not all stochastic WFA admit an equivalent PFA (Jaeger,
2000; Denis & Esposito, 2008).
P
If A is a PFA, then the matrix A = œÉ‚ààŒ£ AœÉ yields the
Markov kernel A(i, j) = P[j | i] on the state space [n] after
marginalizing over the observations. It is easily checked
that A is row-stochastic, and thus AŒ≤ = Œ≤. Furthermore,
for every distribution Œ±0 ‚àà Rn over [n] we have Œ±0> A = Œ±1
for some other probability distribution Œ±1 over [n]. In the
case of PFA irreducibility coincides with the usual concept
of irreducibility of the Markov chain induced by A.
Hankel matrices and spectral learning The Hankel matrix of a function f : Œ£? ‚Üí R is the infinite matrix
?
?
Hf ‚àà RŒ£ √óŒ£ with entries Hf (u, v) = f (uv). Given finite sets U, V ‚äÇ Œ£? , HfU ,V ‚àà RU √óV denotes the restriction
of matrix Hf to prefixes in U and suffixes in V.
Fliess‚Äô theorem (Fliess, 1974) states that a Hankel matrix

Spectral Learning from a Single Trajectory under Finite-State Policies

Hf has finite rank n if and only if there exists a WFA A
with n states such that f = fA . This implies that a WFA A
with n states is minimal if and only if n = rank(HfA ). The
spectral learning algorithm for WFA (Balle et al., 2014a)
provides a mechanism for recovering such a WFA from
a finite sub-block HfU ,V of Hf such that: 1)  ‚àà U ‚à© V,
2) there exists a set U 0 such that U = U 0 ‚à™ (‚à™œÉ‚ààŒ£ U 0 œÉ),
0
3) rank(Hf ) = rank(HfU ,V ). A pair (U, V) that satisfies these conditions is called a complete basis for f . The
pseudo-code of this algorithm is given below:
Algorithm 1: Spectral Learning for WFA
Input: number of states n, Hankel matrix H U ,V
Find U 0 such that U = U 0 ‚à™ (‚à™œÉ‚ààŒ£ U 0 œÉ)
0
Let H = H U ,V
Compute the rank n SVD H ‚âà U DV >
Let hV = H {},V and take Œ± = V > hV
0
Let hU 0 = H U ,{} and take Œ≤ = D‚àí1 U > hU 0
foreach œÉ ‚àà Œ£ do
0
Let HœÉ = H U œÉ,V and take AœÉ = D‚àí1 U > HœÉ V
return A = hŒ±, Œ≤, {AœÉ }i
The main strength of Algorithm 1 is its robustness to noise.
b U ,V of the HanSpecifically, if only an approximation H
kel matrix is known, then the error between the target aub learned from H
b U ,V can
tomaton A and the automaton A
U ,V
U
b ,V k2 ; see
be controlled in terms of the error kH
‚àíH
(Hsu et al., 2012) for a proof in the HMM case and (Balle,
2013) for a proof in the general WFA case. These tedious
but now standard arguments readily reduce the problem of
learning WFA via spectral learning to that of estimating the
corresponding Hankel matrix.
Classical applications of spectral learning assume one has
access to i.i.d. samples from a stochastic process œÅ. In this
setting one can obtain a sample S = (Œæ (1) , . . . , Œæ (N ) ) containing N finite-length trajectories from œÅ, and use them to
b U ,V as follows:
estimate a Hankel matrix H
S
b U ,V (u, v) = 1
H
S
N

N
X

I{Œæ (i) ‚àà uvŒ£œâ } .

i=1

If œÅ = œÅA for some stochastic WFA, then obviously
b U ,V ] = H U ,V and a large sample size N will proES [H
S
fA
b U ,V of H U ,V . Explicit convide a good approximation H
S
fA
centration bounds for Hankel matrices bounding the error
b U ,V k2 can be found in (Denis et al., 2016).
kHfUA,V ‚àí H
S
In this paper we consider the more challenging setup where
we only have access to a sample S = {Œæ} of size N = 1
from œÅ. In particular, we show it is possible to replace the
empirical average above by a CeÃÅsaro average and still use
the spectral learning algorithm to recover the transition ma-

trices of a stochastic WFA. To obtain a finite-sample analysis of this single-trajectory learning algorithm we prove
concentration results for CeÃÅsaro averages of Hankel matrices. Our analysis relies on concentration inequalities for
functions of dependent random variables which depend on
mixing properties of the underlying process.
Mixing and concentration Let œÅ ‚àà P(Œ£œâ ) be a stochastic
process and Œæ = x1 x2 ¬∑ ¬∑ ¬∑ a random word drawn from œÅ.
For 1 6 s < t 6 T and u ‚àà Œ£s we let œÅt:T (¬∑|u) denote
the distribution of xt ¬∑ ¬∑ ¬∑ xT conditioned on x1 ¬∑ ¬∑ ¬∑ xs = u.
With this notation we define the quantity
Œ∑t (u, œÉ, œÉ 0 ) = kœÅt:T (¬∑|uœÉ) ‚àí œÅt:T (¬∑|uœÉ 0 )kT V
for any u ‚àà Œ£s‚àí1 , and œÉ, œÉ 0 ‚àà Œ£. Then the Œ∑-mixing
coefficients of œÅ at horizon T are given by
Œ∑s,t =

sup

Œ∑t (u, œÉ, œÉ 0 ) .

u‚ààŒ£s‚àí1 ,œÉ,œÉ 0 ‚ààŒ£

Mixing coefficients are useful in establishing concentration
properties of functions of dependent random variables. The
Lipschitz constant of a function g : Œ£T ‚Üí R with respect
to the Hamming distance is defined as
kgkLip = sup |g(w) ‚àí g(w0 )| ,
where the supremum is taken over all pairs of words
w, w0 ‚àà Œ£T differing in exactly one symbol. The following theorem proved in (Chazottes et al., 2007; Kontorovich
et al., 2008) provides a concentration inequality for Lipschitz functions of weakly dependent random variables.
Theorem 1 Let œÅ ‚àà P(Œ£œâ ) and Œæ = x1 x2 ¬∑ ¬∑ ¬∑ ‚àº œÅ. Suppose
g : Œ£T ‚Üí R satisfies kgkLip 6 1 and let Z = g(x1 , . . . , xT ).
PT
Let Œ∑œÅ = 1+max1<s<T t=s+1 Œ∑s,t , where Œ∑s,t are
the Œ∑-mixing coefficients of œÅ at horizon T . Then the following holds for any Œµ > 0:


‚àí2Œµ2 T
,
PŒæ [Z ‚àí EZ > ŒµT ] 6 exp
Œ∑œÅ2
with an identical bound for the other tail.
Theorem 1 shows that the mixing coefficient Œ∑œÅ is a key
quantity in order to control the concentration of a function of dependent variables. In fact, upper-bounding Œ∑œÅ
in terms of geometric ergodicity coefficients of a latent
variable stochastic process enables (Kontorovich & Weiss,
2014) to analyze the concentration of functions of HMMs
and (Azizzadenesheli et al., 2016) to provide PAC guarantees for an RL algorithm for POMDP based on spectral
tensor decompositions. Our Lemma 2 uses a similar but
more refined bounding strategy that directly applies when
the transition and observation processes are not conditionally independent. Lemma 4 refines this strategy further to
control Œ∑œÅ for stochastic WFA (for which there may be no
underlying Markov stochastic process in general). To the
best of our knowledge this yields the first concentration results for the challenging setting of stochastic WFA.

Spectral Learning from a Single Trajectory under Finite-State Policies

3. Single-Trajectory Spectral Learning of PFA
In this section we focus on the problem of learning the transition structure of a PFA A using single trajectory is generated by A. We provide a spectral learning algorithm for
this problem and a finite-sample analysis consisting of a
concentration bound for the error on the Hankel matrix estimated by the algorithm. We assume the learner has access
to a single infinite-length trajectory Œæ ‚àº œÅA that is progressively uncovered. The algorithm uses a length t prefix from
Œæ to estimate a Hankel matrix whose entries are CeÃÅsaro averages. This Hankel matrix is then processed by the usual
spectral learning algorithm to recover an approximation to
an automaton with transition weights equivalent to those of
A. We want to analyze the quality of the model learned by
the algorithm after observing the first t symbols from Œæ.
We start by showing that CeÃÅsaro averages provide a consistent mechanism for learning the transition structure of A.
Then we proceed to analyze the accuracy of the Hankel estimation step. As discussed in Section 2, this is enough to
obtain finite-sample bounds for learning PFA. The general
case of stochastic WFA is considered in Section 4.
3.1. Learning with CeÃÅsaro Averages is Consistent
Let A = hŒ±, Œ≤, {AœÉ }i be a PFA computing a function fA :
Œ£? ‚Üí R and defining a stochastic process œÅA ‚àà P(Œ£œâ ). For
convenience we drop the subscript and just write f and œÅ.
Since we only have access to a single trajectory Œæ from œÅ we
cannot obtain an approximation of the Hankel matrix for f
by averaging over multiple i.i.d. trajectories. Instead, we
compute CeÃÅsaro averages over the trajectory Œæ to obtain a
Hankel matrix whose expectation is related to A as follows.
For any t ‚àà N let f¬ØtP: Œ£? ‚Üí R be the function
t‚àí1
s
s
¬Ø
given
P by ft (w) = (1/t) s=0 f (Œ£ w), where f (Œ£ w) =
We shall sometimes write fs (w) =
u‚ààŒ£s f (uw).
f (Œ£s w). Using the definition of the function computed by
a WFA it is easy to see that
X
X
f (uw) =
Œ± > Au Aw Œ≤ = Œ± > As Aw Œ≤ ,
u‚ààŒ£s

u‚ààŒ£s

P

where A = œÉ AœÉ is the Markov kernel on the state space
Pt‚àí1
of A. Thus, introducing Œ±ÃÑt> = (1/t) s=0 Œ±> As we get
>
f¬Øt (w) = Œ±ÃÑt Aw Œ≤. Since Œ± is a probability distribution, A
is a Markov kernel, and probability distributions are closed
by convex combinations, then Œ±ÃÑt is also a probability distribution over [n]. Thus, we have just proved the following:
Lemma 1 (Consistency) The CeÃÅsaro average of f over
t steps, f¬Øt , is computed by the probabilistic automaton
AÃÑt = hŒ±ÃÑt , Œ≤, {AœÉ }i. In particular, A and AÃÑt have the same
number of states and the same transition probability matrices. Furthermore, if A is irreducible then AÃÑt is minimal.
The irreducibility claim follows from (Balle et al., 2017).

For convenience, in the sequel we write HÃÑtU ,V for the
(U, V)-block of the Hankel matrix HfAÃÑt .
Remark 1 The irreducible condition simply ensures there
is a unique stationary distribution, and that the Hankel matrix of AÃÑt has the same rank as the Hankel matrix of A
(otherwise it could be smaller).
3.2. Spectral Learning Algorithm
Algorithm 2 describes the estimation of the empirical Hanb U ,V from the first t+L symbols of a single trakel matrix H
t,Œæ
jectory using the corresponding CeÃÅsaro averages. To avoid
cumbersome notations, in the sequel we may drop super
b t or H
b when U,
and subscripts when not needed and write H
V, and Œæ are clear from the context. Note that by Lemma 1
b over Œæ ‚àº œÅ is equal to the Hankel mathe expectation E[H]
trix HÃÑt of the function f¬Øt computed by the PFA AÃÑt .
Algorithm 2: Single Trajectory Spectral Learning
(Generative Case)
Input: number of states n, length t, prefixes
U ‚äÇ Œ£? , suffixes V ‚äÇ Œ£?
Let L = maxw‚ààU ¬∑V |w|
Sample trajectory Œæ = x1 x2 ¬∑ ¬∑ ¬∑ xt+L ¬∑ ¬∑ ¬∑ ‚àº œÅ
foreach u ‚àà U and v ‚àà V do
Pt‚àí1
b
Let H(u,
v) = 1t s=0 I{xs+1:s+|uv| = uv}
b with rank n
Apply the spectral algorithm to H
3.3. Concentration Results
b t ‚àí HÃÑt in the HanNow we proceed to analyze the error H
kel matrix estimation inside Algorithm 2. In particular, we
provide concentration bounds that depend on the length t,
the mixing coefficient Œ∑œÅ of the process œÅ, and the structure of the basis (U, V). The main result of this section is
the matrix-wise concentration bound Theorem 3 where we
control the spectral norm of the error matrix. For comparison we also provide a simpler entry-wise bound and recall
the equivalent matrix-wise bound in the i.i.d. setting.
Before trying to bound the concentration of the errors using Theorem 1 we need to analyze the mixing coefficient
of the process generated by a PFA. This is the goal of the
following result, whose proof is provided in Appendix A.
Lemma 2 (Œ∑-mixing for PFA) Let A be PFA and assume
that it is (C, Œ∏)-geometrically mixing in the sense that for
some constants C > 0, Œ∏ ‚àà (0, 1) we have
‚àÄt ‚àà N,

¬µA
t = sup
Œ±,Œ±0

kŒ±At ‚àí Œ±0 At k1
6 CŒ∏t ,
kŒ± ‚àí Œ±0 k1

where the supremum is over all probability vectors. Then
we have Œ∑œÅA 6 C/(Œ∏(1 ‚àí Œ∏)).

Spectral Learning from a Single Trajectory under Finite-State Policies

Remark 2 A sufficient condition for the geometric control of ¬µA
t is that A admits a spectral gap. In this case Œ∏
can be chosen to be the modulus of the second eigenvalue
|Œª2 (A)| < 1 of the transition kernel A.
Before the main result of this section we provide a concentration result for each individual entry of the estimated
Hankel matrix as a warmup (see Appendix D).
Theorem 2 (Single-trajectory, entry-wise) Let A be a
(C, Œ∏)-geometrically mixing PFA and Œæ ‚àº œÅA a trajectory
of observations. Then for any u ‚àà U, v ‚àà V and Œ¥ ‚àà (0, 1),
"
b U ,V (u, v)‚àí HÃÑtU ,V (u, v) >
P H
t,Œæ

|uv|C
Œ∏(1 ‚àí Œ∏)

r



#
|uv| ‚àí 1  log(1/Œ¥)
1+
6Œ¥ ,
t
2t

with an identical bound for the other tail.
A naive way to handle the concentration of the whole Hanb t ‚àí HÃÑt kF
kel matrix is to control the Frobenius norm kH
by taking a union bound over all entries using Theorem 2.
However,
the resulting concentration bound would scale as
p
|U||V|. To have better dependency with the dimension
(the matrix has dimension |U| √ó |V|) can split the empirib into blocks containing strings of the
cal Hankel matrix H
same length (as suggested by the dependence of the bound
above on |uv|). We thus introduce the maximal length
L = maxw‚ààU ¬∑V |w|, and the set U` = {u ‚àà U : |u| = `}
for any ` ‚àà N. We use these to define the quantity
nU = |{` ‚àà [0, L] : |U` | > 0}|, and introduce likewise
V` , nV with obvious definitions. With this notation we can
now state the main result of this section.
Theorem 3 (Single-trajectory,
P matrix-wise) Let A be as
in Theorem 2. Let m = u‚ààU ,v‚ààV f¬Øt (uv) be the probability mass and d = min{|U||V|, 2nU nV } be the effective
dimension. Then, for all Œ¥ ‚àà (0, 1) we have
"
!r
r
‚àö
2C
2m
U ,V
U ,V
b
P kHt,Œæ ‚àí HÃÑt k2 >
L+
1‚àíŒ∏
t
#
r

L‚àí1  d ln(1/Œ¥)
2LC
+
1+
6Œ¥ .
Œ∏(1‚àíŒ∏)
t
2t
Remark 3 Note that quantity nU nV in d can be exponentially smaller than |U||V|. Indeed, for U = V = Œ£6L/2 we
have |U||V| = Œò(|Œ£|L ) while nU nV = Œò(L2 ).
For comparison, we recall a state-of-the-art concentration
bound for estimating the Hankel matrix of a stochastic language2 from N i.i.d. trajectories.
2

A stochastic language is a probability distribution over Œ£? .

Theorem 4 (Theorem 7 in (Denis et al., 2014)) Let A be
a stochastic WFA with stopping probabilities and S =
(Œæ (1) , . . . , Œæ (N ) ) be an i.i.d. sample
P of size N from the distribution œÅA ‚àà P(Œ£? ). Let m = u‚ààU ,v‚ààV fA (uv). Then,
for all c > 0 we have
"
#
r
2cm
2c
2c
U
,V
U
,V
b
P kH
‚àí HfA k2 >
+
6 c
.
S
N
3N
e ‚àíc‚àí1
3.4. Sketch of the Proof of Theorem 3
In this section we sketch the main steps of the proof of
Theorem 3 (the full proof is given in Appendices A and D).
We focus on highlighting the main difficulties and paving
the path for the extension of Theorem 3 to stochastic WFA
given in Section 4.
The key of the proof is to study the function g(Œæ) =
b U ,V ‚àí HÃÑtU ,V k2 , in view of applying Theorem 1. To
kH
t,Œæ
this end, we first control the Œ∑-mixing coefficients using
Lemma 2. The next step is to control the Lipschitz constant kgkLip . This part is not very difficult and‚àöwe derive
after a few careful steps the bound kgkLip 6 L d/t.
The second and most interesting part of the proof is about
the control of E[g(Œæ)]. Let us give some more details.
b tU ,V ‚àí HÃÑtU ,V k2 by its
Decomposition step We control kH
Frobenius norm and get
b tU ,V ‚àí HÃÑtU ,V k2 ]2 6
E[kH

X

|w|U ,V E[(fbt (w)‚àí f¬Øt (w))2 ] ,

w‚ààU ¬∑V

where we introduced |w|U ,V = |{(u, v) ‚àà U √ó V :
Pt
uv = w}|, and fbt (w) = 1t s=1 bs (w) using the shorthand notation bs (w) = I{xs . . . xs+|w|‚àí1 = w}. Also,
Pt
f¬Øt (w) = E[fbt (w)] = 1t s=1 fs (w), where fs (w) =
œÅA (Œ£s‚àí1 wŒ£œâ ). This implies that we have a sum of variances, where each of the terms can be written as
E[(fbt (w) ‚àí f¬Øt (w))2 ] =
Ô£Æ
!2 Ô£π
t
1 Ô£∞ X
1
E
bs (w) Ô£ª ‚àí 2
2
t
t
s=1

t
X

!2
fs (w)

.

s=1

Slicing step An important observation is that each probability term satisfies fs (w) = Œ±> As‚àí1 Aw Œ≤ because of
the PFA assumption on
P œÅA . Furthermore, it follows from
A being a PFA that |w|=l fs (w) = 1 for all s and l.
This suggests that we group the terms in the sum over
W = U ¬∑ V by length, so we write Wl = W ‚à© Œ£l and define
Ll = maxw‚ààWl |w|U ,V the maximum number of ways to
write a string of length l in W as a concatenation of a prefix
in U and a suffix in V. Note that we always have Ll 6 l+1.

Spectral Learning from a Single Trajectory under Finite-State Policies

4. Extension to Stochastic WFA

A few more steps lead to the following bound
b tU ,V ‚àí HÃÑtU ,V k2 ]2 6
E[kH
(1)

‚àû
t
X
1 X X
|w|U ,V
(1‚àífs (w))fs (w)
2
t
s=1
l=0 w‚ààWl

X 
E[bs (w)bs0 (w)]‚àífs (w)fs0 (w) .
+2
16s<s0 6t

We control the first term in (1) using
‚àû X
X

|w|U ,V

t
X

(1‚àífs (w))fs (w) 6 t

s=1

l=0 w‚ààWl

X

f¬Øt (uv) .

u‚ààU ,v‚ààV

4.1. The State-Space Geometry of SWFA

Cross terms Regarding the remaining ‚Äúcross‚Äù-term in (1)
we fix w ‚àà Wl and obtain the equation
E[bs (w)bs0 (w)] ‚àí fs (w)fs0 (w)
 0

>
= Œ±s‚àí1
Asw ‚àís ‚àí Aw Œ≤Œ±s>0 ‚àí1 Aw Œ≤ ,

(2)

>
> s
where we introduced
P the vectors Œ±s = Œ± A and transition
s0 ‚àís
matrix Aw = x‚ààŒ£s0 ‚àís Ax corresponding to the ‚Äúevent‚Äù
0

0

0

w

Œ£sw‚àís = wŒ£s ‚àís ‚à© Œ£s ‚àís w. We now discuss two cases.
First control If s0 ‚àí s < l, we use the simplifying fact that
0
0
Œ£sw ‚àís ‚äÇ wŒ£s ‚àís to upper bound (2) by
 0

>
Œ±s‚àí1
Aw As ‚àís ‚àí Œ≤Œ±s>0 ‚àí1 Aw Œ≤
=

fs (w)(1 ‚àí fs0 (w)) 6 fs (w) .
0
Œ£sw ‚àís

0

=
Second control When s ‚àí s > |w| = l we have
0
0
0
wŒ£s ‚àís‚àíl w and Asw ‚àís = Aw As ‚àís‚àíl Aw . Thus, we rewrite
(2) and bound it using HoÃàlder‚Äôs inequality as follows:
 0

>
Œ±s‚àí1
Aw As ‚àís‚àíl ‚àíŒ≤Œ±s>0 ‚àí1 Aw Œ≤ 6
(3)
0

>
kŒ±s‚àí1
Aw k1 kAs ‚àís‚àíl ‚àí Œ≤Œ±s>0 ‚àí1 k‚àû kAw Œ≤k‚àû .

Using Lemma 6 in Appendix A we bound the induced norm
0
A
as kAs ‚àís‚àíl ‚àí Œ≤Œ±s>0 ‚àí1 k‚àû 6 2¬µA
s0 ‚àís‚àíl , where ¬µt is the
mixing coefficient defined in Lemma 2. Also, it holds that
>
kAw Œ≤k‚àû 6 1. Finally, since Œ±s‚àí1
Aw is a sub-distribution
over states, we have the key equalities
X
X
>
>
|w|U ,V kŒ±s‚àí1
Aw k 1 =
|w|U ,V Œ±s‚àí1
Aw Œ≤ (4)
w‚ààWl

=

X
w‚ààWl

w‚ààWl

|w|U ,V fs (w) =

X

We now generalize the results in previous section to the
case where the distribution over Œæ is generated by a stochastic weighted automaton that might not have a probabilistic
representation. The key observation is that Algorithm 2
can learn stochastic WFA without any change, and the consistency result in Lemma 1 extends verbatim to stochastic
WFA. However, the proof of the concentration bound in
Theorem 3 requires further insights into the mixing properties of stochastic WFA. Before describing the changes required in the proof, we discuss some important geometric
properties of stochastic WFA.

fs (uv) .

u‚ààU ,v‚ààV:uv‚ààWl

The proof is concluded by collecting the previous bounds,
plugging them into (1), and using Lemma 2 to get


m
4C
2
.
(5)
E[g(Œæ)] 6 2L ‚àí 1 +
1‚àíŒ∏ t

Recall that a stochastic WFA (SWFA) A = hŒ±, Œ≤, {AœÉ }i
defines a stochastic process œÅA and computes a function
fA such that fA (w) = P[Œæ ‚àà wŒ£œâ ], where Œæ ‚àº œÅA . It is
immediate to check that this implies that the weights of A
satisfy the properties:
(i) Œ±> Ax Œ≤ > 0 for all x ‚àà Œ£? , and
P
> t
(ii) Œ± A Œ≤ = |w|=t Œ±> Aw Œ≤ = 1 for all t > 0, where
P
A = œÉ‚ààŒ£ AœÉ . Without loss of generality we assume
throughout this section that A is a minimal SWFA of dimension n, meaning that any SWFA computing the same
probability distribution than A must have dimension at least
n. Importantly, the weights in Œ±, Œ≤, and AœÉ are not required to be non-negative in this definition. Nonetheless,
it follows from these properties that Œ≤ is an eigenvector of
A of eigenvalue 1 exactly like in the case of PFA. We now
introduce further facts about the geometry of SWFA.
A minimal SWFA A is naturally associated with a proper
(i.e. pointed, closed, and solid) cone in K ‚äÇ Rn called the
backward cone (Jaeger, 2000), and characterized by the following properties: 1) Œ≤ ‚àà K, 2) AœÉ K ‚äÜ K for all œÉ ‚àà Œ£, and
3) Œ±> v > 0 for all v ‚àà K. Condition 2) says that every transition matrix AœÉ leaves K invariant, and in particular the
backward vector Aw Œ≤ belongs to K for all w ‚àà Œ£? .
The vector of final weights Œ≤ plays a singular role in the
geometry of the state space of a SWFA. This follows from
facts about the theory of invariant cones (Berman & Plemmons, 1994) which provides a generalization of the classical Perron‚ÄìFrobenius theory of non-negative matrices to
arbitrary matrices. We recall from (Berman & Plemmons,
1994) that a norm on Rn can be associated with every vector in the interior of K. In particular, we will take the norm
associated with the final weights Œ≤ ‚àà K. This norm, denoted by k ¬∑ kŒ≤ , is completely determined by its unit ball
BŒ≤ = {v ‚àà Rn : ‚àíŒ≤ 6K v 6K Œ≤}, where u 6K v means
v ‚àí u ‚àà K. In particular, kvkŒ≤ = inf{r > 0 : v ‚àà rBŒ≤ }.
Induced and dual norms are derived from k ¬∑ kŒ≤ as usual.
When A is a PFA one can take K to be the cone of vectors in
Rn with non-negative entries, in which case Œ≤ = (1, . . . , 1)
and k ¬∑ kŒ≤ reduces to k ¬∑ k‚àû (Berman & Plemmons, 1994).
The following result shows that k ¬∑ kŒ≤ provides the right

Spectral Learning from a Single Trajectory under Finite-State Policies

generalization to SWFA of the norm k ¬∑ k‚àû used in the Second control step of the proof for PFA (see Appendix B).
Lemma 3 For any w ‚àà Œ£? : (i) kAw Œ≤kŒ≤ 6 1, and (ii)
kŒ±> Aw kŒ≤,‚àó = Œ±> Aw Œ≤.
It is also natural to consider mixing coefficients for stochastic processes generated by SWFA in terms of the dual Œ≤norm. This provides a direct analog to Lemma 2 for PFA:
Lemma 4 (Œ∑-mixing for SWFA) Let A be SWFA and assume that it is (C, Œ∏)-geometrically mixing in the sense that
for some C > 0, Œ∏ ‚àà (0, 1),
¬µA
t =

kŒ±0> At ‚àí Œ±1> At kŒ≤,?
6 CŒ∏t .
kŒ±
‚àí
Œ±
k
>
>
0
1
Œ≤,?
Œ±0 ,Œ±1 :Œ±0 Œ≤=Œ±1 Œ≤=1
sup

Then the Œ∑-mixing coefficient satisfies Œ∑œÅA 6 C/Œ∏(1 ‚àí Œ∏).
Remark 4 A sufficient condition for the geometric control of ¬µA
t is that A admits a spectral gap. In this case
Œ∏ can be chosen to be the modulus of the second eigenvalue |Œª2 (A)| < 1 of A. Another sufficient condition is that
Œ∏ = Œ≥Œ≤ (A) < 1, where


||AŒΩ||Œ≤,?
Œ≥Œ≤ (A) = sup
: ŒΩ s.t. ||ŒΩ||Œ≤,? 6= 0, ŒΩ > Œ≤ = 0 .
||ŒΩ||Œ≤,?
4.2. Concentration of Hankel Matrices for SWFA
We are now ready to extend the proof of Theorem 3 to
SWFA. Using that both PFA and SWFA define probability distributions over prefixes it follows that any argument
in Section 3.4 that only appeals to the function computed
by the automaton can remain unchanged. Therefore, the
only arguments that need to be revisited are described in
the Second control step. In particular, we must provide
versions of (3) and (4) for SWFA.
Recalling that HoÃàlder‚Äôs inequality can be applied with
any pair of dual norms, we start by replacing the norms
k ¬∑ k‚àû and k ¬∑ k1 in (3) with the cone-norms k ¬∑ kŒ≤ and
k ¬∑ kŒ≤,? respectively. Next we use Lemma 3 to obtain,
for any w ‚àà Œ£? , the bound kAw Œ≤kŒ≤ 6 1 and the equation kŒ±> Aw kŒ≤,‚àó = Œ±> Aw Œ≤ which are direct analogs
of the results used for PFA. Then it only remains to re0
late the Œ≤-norm of As ‚àís‚àíl ‚àí Œ≤Œ±s>0 ‚àí1 to the mixing coefficients ¬µA
t . Applying Lemma 8 in Appendix A yields
0
kAs ‚àís‚àíl ‚àí Œ≤Œ±s>0 ‚àí1 kŒ≤ 6 2¬µA
s0 ‚àís‚àíl . Thus we obtain for
SWFA exactly the same concentration result that we obtained for empirical Hankel matrices estimated from a single trajectory of observations generated by a PFA.
Theorem 5 (Single-trajectory, SWFA) Let A be a SWFA
that is (C, Œ∏)-geometrically mixing with the definition in
Lemma 4. Then the concentration bound in Theorem 3 also
holds for trajectories Œæ ‚àº œÅA .

5. The Controlled Case
This section describes the final contribution of the paper:
a generalization of our analysis of spectral learning from
a single trajectory the case of dynamical systems under
finite-state control. We consider discrete-time dynamical
systems with finite set of observations O and finite set of
actions A, and let Œ£ = O √óA. We assume the learner has
access to a single trajectory Œæ = (ot , at )t>1 in Œ£œâ . The trajectory is generated by coupling an environment defining a
distribution over observations conditioned on actions and
a policy defining a distribution over actions conditioned
on observations. Assuming the joint action-observation
distribution can be represented by a stochastic WFA is
equivalent to saying that the environment corresponds to
a POMDP or PSR, and the policy has finite memory.
To fix some notation we assume the environment is represented by a conditional3 stochastic WFA A = hŒ±, Œ≤, {AœÉ }i
with n states. This implies the semantics fA (w) =
P[o1 ¬∑ ¬∑ ¬∑ ot |a1 ¬∑ ¬∑ ¬∑ at ] for the function computed by A,
where w = w1 ¬∑ ¬∑ ¬∑ wt with wi = (oi , au ). For any w ‚àà Œ£?
we shall write wA = a1 ¬∑ ¬∑ ¬∑ at and wO = o1 ¬∑ ¬∑ ¬∑ ot . We also
assume there is a stochastic policy œÄ represented by a conditional PFA AœÄ = hŒ±œÄ , Œ≤œÄ , {Œ†œÉ }i with k states; that is,
fAœÄ (w) = œÄ(wA |wO ) = P[a1 ¬∑ ¬∑ ¬∑ at |o1 ¬∑ ¬∑ ¬∑ ot ]. In particular, AœÄ represents a stochastic policy that starts in a state
s1 ‚àà [k] sampled according to Œ±œÄ (i) = P[s1 = i], and at
each time step samples an action and changes state according to Œ†o,a (i, j) = P[st+1 = j, at = a|ot = o, st = i].
The trajectory Œæ observed by the learner is generated by
the stochastic process œÅ ‚àà P(Œ£œâ ) obtained by coupling
A and AœÄ . A standard construction in the theory of
weighted automata (Berstel & Reutenauer, 1988) shows
that this process can be computed by the product automaton B = A ‚äó AœÄ = hŒ±‚äó , Œ≤‚äó , {BœÉ }i, where Œ±‚äó = Œ± ‚äó Œ±œÄ ,
Œ≤‚äó = Œ≤ ‚äó Œ≤œÄ , and Bo,a = Ao,a ‚äó Œ†o,a . It is easy to verify
that B is a stochastic WFA with nk states computing the
function fB (w) = fA (w)fAœÄ (w) = P[Œæ ‚àà wŒ£œâ ].
At this point, the spectral algorithm from Section 4 could
be used to learn B directly from a trajectory Œæ ‚àº œÅB . However, since the agent interacting with environment A knows
the policy œÄ, we would like to leverage this information to
learn directly a model of the environment. This approach
is formalized in Algorithm 3, which provides a singletrajectory version of the algorithm in (Bowling et al., 2006)
for learning PSR from non-blind policies with i.i.d. data.
The main difference with Algorithm 2 is that in the reactive
case we need a smoothing parameter Œ∫ that will prevent the
b to grow unboundentries in the empirical Hankel matrix H
edly plus that the policy œÄ satisfies an exploration assumption. Œ∫ plays a similar role in our analysis as the smoothing
parameter introduced in (Denis et al., 2014) for learning
3

Such WFA are also called reactive predictive state representations in the RL literature.

Spectral Learning from a Single Trajectory under Finite-State Policies

Algorithm 3: Single Trajectory Spectral Learning
(Reactive Case)
Input: number of states n, length t, U,V ‚äÇ (A√óO)? ,
policy œÄ, smoothing coefficient Œ∫
Let L = maxw‚ààU ¬∑V |w|
Sample trajectory o1 a1 o2 a2 ¬∑ ¬∑ ¬∑ ot+L at+L using œÄ
foreach u ‚àà U and v ‚àà V do
b
Let H(u,
v) =
Pt‚àí1 I{os+1 as+1 ¬∑¬∑¬∑os+|uv| as+|uv| =uv}
1
t

s=0

Œ∫s œÄ(a1 ¬∑¬∑¬∑as+|uv| |o1 ¬∑¬∑¬∑os+|uv| )

b with rank n
Apply the spectral algorithm to H

stochastic languages from factor estimates in the i.i.d. case.
The difference is that in our case the smoothing parameter
must satisfy Œ∫Œµ > 1, where Œµ is the exploration probability
of the policy œÄ provided by the following assumption.

parameter Œµ (cf. Assumption 1), then 1/Œ∫ 6 1/|A|. This
observation is used, for example, to bound some variance
terms in E[g(Œæ)] by replace occurrences of fÀút with fÀútunif ,
the function computed by taking the CeÃÅsaro average of the
first t steps of AÃÑ. Ultimately, this makes our bound depend
not only on the mixing properties of œÅB , but also on those
of the normalized process œÅAÃÑ induced by the SWFA AÃÑ. Incidentally, this argument is also used to address point (ii):
by bounding quantities involving Œ∫ by quantities computed
by a SWFA we can use again the arguments sketched in
Section 4.1.
Pursuing the ideas above, and assuming that AÃÑ is (CÃÑ, Œ∏ÃÑ)geometrically mixing, we obtain the following bound
which can be compared to the one in (5):
E[g(Œæ)]2 6

2mÃÑ
mÃÉ
+ 2L
L
2
tŒµ (1 ‚àí 1/(Œ∫Œµ) ) tŒµ


L+

CÃÑ
1 ‚àí Œ∏ÃÑ


,

Assumption 1 (Exploration) There exists some Œµ > 0
such that for each w ‚àà Œ£? the policy œÄ satisfies
œÄ(wA |wO ) > Œµ|w| . In particular, at every time step each
action a ‚àà A is picked with probability at least Œµ.

where L = maxw‚ààU ¬∑V |w|, mÃÉ =
P
mÃÑ = u‚ààU ,v‚ààV fÀútunif (uv).

Before moving to the next section, where we provide finitesample concentration results for the Hankel matrix estimated by Algorithm 3, we show that Algorithm 3 is consistent, that is it learns in expectation a WFA whose transition
matrices are equivalent to those of the environment A. The
proof of the following lemma is provided in Appendix E.

Theorem 6 Suppose that B is (C, Œ∏)-geometrically mixing
and AÃÑ is (CÃÑ, Œ∏ÃÑ)-geometrically mixing. Suppose œÄ satisfies Assumption 1 P
and the smoothing coefficient Œ∫ satisfies
Œ∫Œµ > 1. Let d = w‚ààU ¬∑V |w|U ,V , and define L, mÃÉ, mÃÑ as
above. Then for any Œ¥ ‚àà (0, 1) we have

b =H
b U ,V computed in AlLemma 5 The Hankel matrix H
t,Œæ
b U ,V ] = HÃÉtU ,V , where HÃÉtU ,V is
gorithm 3 satisfies E[H
t,Œæ
a block of the Hankel matrix corresponding to the stochastic WFA AÃÉt = hŒ±ÃÉt , Œ≤, {AœÉ }i where we introduced the modiPt‚àí1
fied vector Œ±ÃÉt = (1/t) s=0 Œ±> (A/Œ∫)s . We denote by
fÀút the function computed by AÃÉt .
5.1. Concentration Results
Broadly speaking, a concentration bound for the estimab U ,V ‚àí HÃÉtU ,V k2 can be obtained by following a
tion error kH
t,Œæ
proof strategy similar to the ones used in Theorems 3 and 5.
However, almost all the bounds used in the previous proofs
need to be reworked to account for (i) the effect of the extra
dependencies introduced by the policy œÄ, and (ii) the fact
that the target automaton A to be learned is not a stochastic WFA in the sense of Section 4 but rather a conditional
stochastic WFA.
Point (i) is addressed in our proof by introducing a ‚Äúnormalized‚Äù reference process œÅAÃÑ corresponding to the coupling AÃÑ = A ‚äó Aunif between the environment A and
the uniform random policy that at each step takes each action independently with probability 1/|A|. Assuming the
smoothing parameter satisfies Œ∫Œµ > 1 for some exploration

u‚ààU ,v‚ààV

fÀút (uv), and

s

"
P

P

mÃÉ
+
‚àí Œ∫‚àí2 Œµ‚àí2 )
s
#
r


2mÃÑ
CÃÑ
C
2d ln(1/Œ¥)
L+
+
6Œ¥ .
tŒµ2L
Œ∏(1‚àíŒ∏)ŒµL
t
1‚àí Œ∏ÃÑ
b U ,V
kH
t,Œæ

‚àí

HÃÉtU ,V k2

>

tŒµL (1

On a final note we remark that the dependence on ŒµL might
be unavoidable due to inherent increase in variance produced by importance sampling estimators.

6. Conclusion
We present the first rigorous analysis of single-trajectory
SVD-based spectral learning algorithms for sequential
models with latent variables. Our analysis highlights the
role of mixing properties of WFA and their relation with the
geometry of the underlying state space. In the controlled
case we obtain a result for control with finite-state policies, a much more general class than previously considered
memoryless policies. In future work we will use our results
to get upper confidence bounds on the predictions made by
the learned environment with the goal of solving the full
RL problem for PSR with complex control policies.

Spectral Learning from a Single Trajectory under Finite-State Policies

Acknowledgements
O.-A. M. acknowledges the support of the French Agence
Nationale de la Recherche (ANR), under grant ANR-16CE40-0002 (project BADASS).

References
Anandkumar, Anima, Foster, Dean P, Hsu, Daniel J,
Kakade, Sham M, and Liu, Yi-Kai. A spectral algorithm
for latent dirichlet allocation. In Advances in Neural Information Processing Systems, pp. 917‚Äì925, 2012.
Anandkumar, Animashree, Ge, Rong, Hsu, Daniel J,
Kakade, Sham M, and Telgarsky, Matus. Tensor decompositions for learning latent variable models. Journal of
Machine Learning Research, 15(1):2773‚Äì2832, 2014.
Azizzadenesheli, Kamyar, Lazaric, Alessandro, and
Anandkumar, Animashree. Reinforcement learning of
pomdps using spectral methods. In 29th Annual Conference on Learning Theory, pp. 193‚Äì256, 2016.
Bacon, Pierre-Luc, Balle, Borja, and Precup, Doina. Learning and planning with timing information in markov
decision processes. In Proceedings of the Thirty-First
Conference on Uncertainty in Artificial Intelligence, pp.
111‚Äì120. AUAI Press, 2015.
Bailly, R., Habrard, A., and Denis, F. A spectral approach
for probabilistic grammatical inference on trees. In Algorithmic Learning Theory, pp. 74‚Äì88, 2010.
Bailly, RaphaeÃàl. Quadratic weighted automata: Spectral
algorithm and likelihood maximization. In Proceedings of the 3rd Asian Conference on Machine Learning,
ACML 2011, Taoyuan, Taiwan, November 13-15, 2011,
pp. 147‚Äì163, 2011.
Balle, B. Learning Finite-State Machines: Algorithmic and
Statistical Aspects. PhD thesis, Universitat PoliteÃÄcnica
de Catalunya, 2013.
Balle, Borja and Mohri, Mehryar. Spectral learning of general weighted automata via constrained matrix completion. In Advances in neural information processing systems, pp. 2168‚Äì2176, 2012.
Balle, Borja and Mohri, Mehryar. Learning weighted automata. In International Conference on Algebraic Informatics, pp. 1‚Äì21. Springer, 2015.
Balle, Borja, Quattoni, Ariadna, and Carreras, Xavier. A
spectral learning algorithm for finite state transducers.
In Joint European Conference on Machine Learning
and Knowledge Discovery in Databases, pp. 156‚Äì171.
Springer, 2011.

Balle, Borja, Carreras, Xavier, Luque, Franco M, and Quattoni, Ariadna. Spectral learning of weighted automata.
Machine learning, 96(1-2):33‚Äì63, 2014a.
Balle, Borja, Hamilton, William L, and Pineau, Joelle.
Methods of moments for learning stochastic languages:
Unified presentation and empirical comparison. In
ICML, pp. 1386‚Äì1394, 2014b.
Balle, Borja, Gourdeau, Pascale, and Panangaden, Prakash.
Bisimulation metrics for weighted automata. In 44rd International Colloquium on Automata, Languages, and
Programming, ICALP, 2017.
Berman, Abraham and Plemmons, Robert J. Nonnegative
matrices in the mathematical sciences. SIAM, 1994.
Berstel, Jean and Reutenauer, Christophe. Rational Series
and Their Languages. Springer, 1988.
Boots, Byron, Siddiqi, Sajid M, and Gordon, Geoffrey J.
Closing the learning-planning loop with predictive state
representations. The International Journal of Robotics
Research, 30(7):954‚Äì966, 2011.
Bowling, Michael, McCracken, Peter, James, Michael,
Neufeld, James, and Wilkinson, Dana. Learning predictive state representations using non-blind policies. In
Proceedings of the 23rd international conference on Machine learning, pp. 129‚Äì136. ACM, 2006.
Chazottes, J-R, Collet, Pierre, KuÃàlske, Christof, and Redig,
Frank. Concentration inequalities for random fields via
coupling. Probability Theory and Related Fields, 137
(1-2):201‚Äì225, 2007.
Cohen, S. B., Stratos, K., Collins, M., Foster, D. P., and
Ungar, L. Experiments with spectral learning of latentvariable PCFGs. In Proceedings of NAACL, 2013.
Cohen, S. B., Stratos, K., Collins, M., Foster, D. P., and
Ungar, L. Spectral learning of latent-variable PCFGs:
Algorithms and sample complexity. Journal of Machine
Learning Research, 2014.
Denis, FrancÃßois, Gybels, Mattias, and Habrard, Amaury.
Dimension-free concentration bounds on hankel matrices for spectral learning. Journal of Machine Learning
Research, 17(31):1‚Äì32, 2016.
Denis, FrancÃßois and Esposito, Yann. On rational stochastic
languages. Fundamenta Informaticae, 86(1, 2):41‚Äì77,
2008.
Denis, FrancÃßois, Gybels, Mattias, and Habrard, Amaury.
Dimension-free concentration bounds on hankel matrices for spectral learning. In ICML, pp. 449‚Äì457, 2014.

Spectral Learning from a Single Trajectory under Finite-State Policies

Fliess, M. Matrices de Hankel. Journal de MatheÃÅmatiques
Pures et AppliqueÃÅes, 53, 1974.

Rosenthal, Jeffrey S. Convergence rates for markov chains.
Siam Review, 37(3):387‚Äì405, 1995.

Glaude, Hadrien and Pietquin, Olivier. Pac learning of
probabilistic automaton based on the method of moments. In Proceedings of The 33rd International Conference on Machine Learning, pp. 820‚Äì829, 2016.

Shaban, Amirreza, Farajtabar, Mehrdad, Xie, Bo, Song, Le,
and Boots, Byron. Learning latent variable models by
improving spectral solutions with exterior point method.
In UAI, pp. 792‚Äì801, 2015.

Hamilton, William L, Fard, Mahdi Milani, and Pineau,
Joelle. Efficient learning and planning with compressed
predictive states. Journal of Machine Learning Research, 15(1):3395‚Äì3439, 2014.

Siddiqi, S. M., Boots, B., and Gordon, G. J. Reduced-rank
hidden Markov models. AISTATS, 2010.

Hsu, Daniel and Kakade, Sham M. Learning mixtures of
spherical Gaussians: moment methods and spectral decompositions. In Innovations in Theoretical Computer
Science, 2013.
Hsu, Daniel, Kakade, Sham M, and Zhang, Tong. A spectral algorithm for learning hidden markov models. Journal of Computer and System Sciences, 78(5):1460‚Äì1480,
2012.
Jaeger, Herbert. Observable operator models for discrete
stochastic time series. Neural Computation, 12(6):1371‚Äì
1398, 2000.
Kontorovich, Aryeh and Weiss, Roi. Uniform chernoff and
dvoretzky-kiefer-wolfowitz-type inequalities for markov
chains and related processes. Journal of Applied Probability, 51(04):1100‚Äì1113, 2014.
Kontorovich, Leonid Aryeh, Ramanan, Kavita, et al. Concentration inequalities for dependent random variables
via the martingale method. The Annals of Probability,
36(6):2126‚Äì2158, 2008.
Kontoyiannis, Ioannis and Meyn, Sean P. Geometric ergodicity and the spectral gap of non-reversible markov
chains. Probability Theory and Related Fields, 154(12):327‚Äì339, 2012.
Kulesza, Alex, Jiang, Nan, and Singh, Satinder. Low-rank
spectral learning with weighted loss functions. In Artificial Intelligence and Statistics, pp. 517‚Äì525, 2015.
Langer, Lucas, Balle, Borja, and Precup, Doina. Learning multi-step predictive state representations. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016, New York,
NY, USA, 9-15 July 2016, pp. 1662‚Äì1668, 2016.
Luque, Franco M, Quattoni, Ariadna, Balle, Borja, and
Carreras, Xavier. Spectral learning for non-deterministic
dependency parsing. In Proceedings of the 13th Conference of the European Chapter of the Association for
Computational Linguistics, pp. 409‚Äì419. Association
for Computational Linguistics, 2012.

Thon, Michael and Jaeger, Herbert. Links between multiplicity automata, observable operator models and predictive state representations‚Äìa unified learning framework. Journal of Machine Learning Research, 16:103‚Äì
147, 2015.

