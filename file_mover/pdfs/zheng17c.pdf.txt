Collect at Once, Use Effectively:
Making Non-interactive Locally Private Learning Possible

Kai Zheng * 1 Wenlong Mou * 1 Liwei Wang 1

Abstract
Non-interactive Local Differential Privacy (LDP)
requires data analysts to collect data from users
through noisy channel at once. In this paper,
we extend the frontiers of Non-interactive LDP
learning and estimation from several aspects. For
learning with smooth generalized linear losses,
we propose an approximate stochastic gradient
oracle estimated from non-interactive LDP channel using Chebyshev expansion, which is combined with inexact gradient methods to obtain an
efficient algorithm with quasi-polynomial sample complexity bound. For the high-dimensional
world, we discover that under `2 -norm assumption on data points, high-dimensional sparse
linear regression and mean estimation can be
achieved with logarithmic dependence on dimension, using random projection and approximate
recovery. We also extend our methods to Kernel Ridge Regression. Our work is the first
one that makes learning and estimation possible
for a broad range of learning tasks under noninteractive LDP model.

1. Introduction
Data privacy has become an increasingly important issue
in the age of data science. Differential Privacy (DP), proposed in 2006 by Dwork et al.,(Dwork et al., 2006), provide
a solid foundation and rigorous standard for private data
analysis. Since then, there has been extensive literature
studying the fundamental trade-offs between differential
privacy and accuracy for query answering (Hardt & Rothblum, 2010; Hardt et al., 2012; Thaler et al., 2012; Wang
*

Equal contribution 1 Key Laboratory of Machine Perception,
MOE, School of EECS, Peking University, Beijing, China. Correspondence to: Kai Zheng <zhengk92@pku.edu.cn>, Wenlong Mou <mouwenlong@pku.edu.cn>, Liwei Wang <wanglw@cis.pku.edu.cn>.
Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

et al., 2016), machine learning (Chaudhuri & Monteleoni,
2008; Chaudhuri et al., 2011; Rubinstein et al., 2012; Wang
et al., 2015), and statistical inference (Lei, 2011; Smith,
2011). For more details on DP results, please refer to the
excellent monograph written by Dwork and Roth (Dwork
& Roth, 2014). Intuitively, a DP algorithm uses randomized response to defend against adversary, so that change
of one of data points could not be detected.
Despite the prevailing success of this notion in academia,
its applicability in data science practice could be limited.
For example, if data analysts just promise to follow the
differential privacy constraints, user will not feel their privacy are preserved. The promise could not be validated;
the mechanisms are complicated; and even worse: users do
not trust the data collector at all. Unfortunately, most of
differential privacy algorithms are based on adding noise
calibrated to stability of loss function, which essentially requires access to original data.
Borrowing ideas from classical wisdom on collecting sensitive survey data (Warner, 1965), Local Differential Privacy (LDP) (Kasiviswanathan et al., 2008; Duchi et al.,
2013b) was proposed as a stronger notion of privacy to resolve this problem. LDP requires each of data points to
be passed through a noisy channel during collection. This
channel will ensure one can hardly tell anything about the
user based on what he have sent. The practical advantage of LDP is obvious: users will be comfortable sending
their sensitive information through noisy channels, which
are transparent and reliable; additionally, users can choose
their own privacy parameters, making it possible to associate with economic value. Therefore, this line of research has attracted lots of attention (Duchi et al., 2013a;b;
Kairouz et al., 2014; Bassily & Smith, 2015; Kairouz et al.,
2016).
Despite the analogy in definition, the way in which LDP
achieves accurate results are fundamentally different from
classical DP. Essentially, the information collected from
each user is almost completely noisy, from which one needs
to obtain accurate results. The only way to do that is to
make the independently distributed noise cancel out with
each other in some sense. With sand being washed away
by waves, golds begin to appear.

Non-interactive Local DP Learning

Two local privacy notions have been discussed in existing
literature: the interactive model allows the algorithm to collect data sequentially, and decide what to ask based on information from previously asked users. The non-interactive
model, on the contrary, requires all data to be collected
at once, with no interactive queries allowed. Apparently
the non-interactive model is strictly stronger, and prohibition on interactive queries rules out most of SGD-type approaches, making the problem significantly harder. However, non-interactive LDP is more useful in real-world applications, as opportunities of interactive queries may not
be available in most settings.
In existing literature, learning and inference under interactive and non-interactive LDP therefore are exhibiting different appearances. In the interactive world, LDP
is promised with connection to Statistical Query (SQ)
model (Kearns, 1998), from its very beginning (Kasiviswanathan et al., 2011). SQ algorithms for a wide
range of convex ERM problems were proposed by (Feldman et al., 2017), implying good risk bounds for LDP.
(Duchi et al., 2013b) established matching upper and lower
bounds for convex risk minimization problems. On the
other hand, very few has been done in the non-interactive
setting. Existing works primarily focus on basic estimation problems such as means and discrete densities (Duchi
et al., 2013a; 2016; Bassily & Smith, 2015), or some function calculations (Kairouz et al., 2015b). Most of important
modern learning and inference tasks, including estimation
in linear models and convex ERM, are still poorly understood in non-interactive local DP settings.
For the high-dimensional world, where d  n while some
low-complexity constraints are imposed, we may hope the
error induced by privacy constraints to be logarithmically
dependent upon d. In classical differential privacy literature, this has been be addressed using different techniques,
guarantee error bounds logarithmically dependent on dimension (Talwar et al., 2015; Smith & Thakurta, 2013).
However, lower bounds have been shown in local privacy
model even for high-dimensional 1-sparse mean estimation, ruling out any good guarantees (Duchi et al., 2016).
The lower bound result illustrates fundamental difficulties
of local differential privacy. But if we still want to do highdimensional learning under local privacy, are there additional assumptions that helps?
Therefore, the starting point of this work lies on making
learning possible under the non-interactive LDP setting,
which is the hardest yet the most useful. We initiate the
first attempt towards a broad range of learning tasks beyond
simple distribution estimation. In particular, we investigate
two important classes of problems under non-interactive
LDP: (1) High-dimensional sparse linear regression and
mean estimation; (2) Generalized linear models. Our fo-

cus is to design corresponding mechanisms and study their
convergence rates with respect to the number and dimension of data. One can also consider optimal mechanisms
in terms of privacy parameters like (Geng & Viswanath,
2014), which is of independent interests.
Our Contributions: In this paper, we propose several efficient algorithms for learning and estimation problems under non-interactive LDP model, with good theoretical guarantees. In the following we summarize our contributions.
(1) High Dimensional Estimation: One of exciting
findings in this paper is about local privacy for highdimensional data. Roughly speaking, convergence rate
with logarithmic dependence on the dimension can be attained under LDP, if we assume data points are `2 bounded.
This is in sharp contrast with information-theoretic lower
bounds for 1-sparse mean estimation for `∞ bounded
data (Duchi et al., 2016). Valid algorithms are presented for
both sparse mean estimation and sparse linear regression,
respectively. Intuitively, non-interactivity doesn’t bring
about additional difficulties, since the loss functions are
quadratic forms. However, if we directly add noise to each
of data points and send it to the server, the aggregated noise
will lead to linear dependence on the dimension. Thus we
adopt the random projection technique, and send the noisy
version of projected data to the server. Based on the aggregated information, we can approximately recover the optimal solution via linear inverse problem.
(2) Learning Smooth Generalized Linear Models: Generalized linear problems which has additional smooth properties (we call the loss with respect to it as smooth generalized linear loss (SGLL), see rigorous definition in section
2) include many common loss functions, such as logistic
loss, square loss, etc. Optimizing such losses are intuitively
much more difficult in non-interactive LDP model, as the
loss can be an arbitrary function wT x. This even makes it
difficult for us to obtain an unbiased estimator for objective
function, or its gradient. As a result, when we aggregate the
loss of noisy data together, it is even hard to ensure it converge to the population loss. Approximation theory techniques are introduced to tackle this problem. In particular,
we use polynomials of wT x to approximate nonlinear coefficients of gradients. Chebyshev bases, instead of Taylor
series, are used to get faster convergence within an arbitrary domain. Then we are able to build inexact stochastic
gradient oracles to arbitrarily specified accuracy. SIGM algorithm in (Dvurechensky & Gasnikov, 2016) is exploited
to find the minimizer with inexact gradients.
Other Related Work:
Local privacy dates back
to (Warner, 1965), who uses random responses to protect
privacy in surveys. In recent LDP literature, both (Duchi
et al., 2013a) and (Kairouz et al., 2016) studied density estimation methods and their theoretical behaviors in

Non-interactive Local DP Learning

LDP model. Rather than statistical setting in above two
work, (Bassily & Smith, 2015) considered how to produce
frequent items and corresponding frequencies of a dataset
in local model. Besides, (Kairouz et al., 2014) investigated
optimality of LDP mechanisms based on information theoretical measures for statistical discrimination.
Approximation techniques are commonly used in DP literature. (Thaler et al., 2012) employed polynomials for
marginal queries. (Wang et al., 2016) leveraged trigonometric polynomials to answer smooth queries. (Zhang
et al., 2012) also used polynomial approximations and get
basic convergence results in standard DP model. Besides,
the random projection and recovery has also been used in
DP learning (Kasiviswanathan & Jin, 2016) and local DP
histogram estimation (Bassily & Smith, 2015).
In standard DP model, both high-dimensional sparse estimation and generalized linear model have been intensively studied. (Kifer et al., 2012) and (Smith & Thakurta,
2013) considered the convergence of private LASSO estimator under RSC and incoherence assumptions. (Talwar et al., 2015) considered constrained ERM of sparse
linear regression, and obtained Õ(log d/n2/3 ) rate using
private Frank-Wolfe. Above results assume `∞ -bounded
data. By stronger assumption of `2 bounded data, (Kasiviswanathan & Jin, 2016) gave a general framework for
high dimensional empirical risk minimization (ERM) problem. There are several works to estimate generalized linear model under DP, with a particular emphasis on logistic regression. Objective and output perturbation are used
to get low excess risks (Chaudhuri & Monteleoni, 2008;
Chaudhuri et al., 2011). Both (Bassily et al., 2014) and
(Zhang et al., 2017) considered concrete private algorithms
to solve ERM. None of these existing results extends directly to non-interactive LDP setting.

2. Preliminaries
Some notations: [p] = {1, 2, · · · , p}. Vectors are written in bold symbol, such as x, w. x represents univariate number, which has no relation with x. For a vector x = [x1 , x2 , · · · , xd ]T , xk represents the power of
each element. B2 (r) = {x| kxk2 6 r}. Denote S+
as the semipositive matrix space, ProjS+ (·) means projecting a matrix to S+ in terms of Frobenius norm (i.e.
eliminate all negative eigenvalues). For an univariate function f (x), f (k) (x) represents its k-th derivative, and define
 (k) 
R
(k+1)
f  := 1 |f √ (x)| dx. For the reason of limited
T

−1

1−x2

space, all omitted proof can be found in the supplementary.
2.1. Local Differential Privacy
Here we adopt the LDP definition given in (Bassily &
Smith, 2015).

Definition 1. A mechanism Q : V → Z is said to be (, δ)local differential private or (, δ)-LDP, if for any v, v 0 ∈ V,
and any (measurable) subset S ⊂ Z, there is
Pr[Q(v) ∈ S] 6 e Pr[Q(v 0 ) ∈ S] + δ
Just the same with basic results in DP (Dwork & Roth,
2014), there are corresponding basic results for LDP:
Lemma 1 (Gaussian Mechanism). If V = {v ∈
Rd | kvk2 6 1}, then Q(v) = v + epis (, δ)-LDP, where
e ∈ Rd , and e ∼ N (0, σ 2 Id ), σ = 2 2 ln(1.25/δ)/.
Lemma 2 (Composition Theorem1 ). Let Qi : V → Zi be
an (i , δi )-LDP mechanism for i ∈ [k]. Then if Q[k] : V →
Qk
i=1 Zi is defined to be Q[k] (v) = (Q1 (v), . . . , Qk (v)),
Pk
Pk
then Q[k] is ( i=1 i , i=1 δi )-LDP.
The following simple mechanism add Gaussian noise to
preserve LDP of a vector, which serves as a basic tool in
LDP learning and estimation.
Algorithm 1 Basic Private Vector mechanism
Input: A vector x ∈ Rd , privacy parameter , δ for LDP
Output: Private √
vector z
2 ln(1.25/δ)

Setting σ =

if kxk2 > 1 then
x = x/ kxk2
end if
z ← x + e, where e ∼ N (0, σ 2 Id )

1:
2:
3:
4:
5:

Theorem 1. Algorithm 1 preserves (, δ)-LDP.

3. High Dimensional and Non-parametric
Learning via Random Projections
In this section we consider three learning problems under
non-interactive LDP: Mean Estimation and Linear Regression in High-dimensions, as well as Kernel Ridge Regression. Using random projection techniques, we are able to
get logarithmic dependence on d in high-dimensional settings, and also to get good guarantees for Kernel version.
The first problem is considered in statistical settings, as we
need to assume a sparse mean vector. The latter two problems are considered as ERM problems, which can easily be
translated to population risk using uniform convergence.
3.1. High-dimensional Mean Estimation
In this section, we propose a non-interactive LDP mechanism for high-dimensional sparse mean estimation problem. By assuming `2 bounded data points, and `1 bounded
1

Note one can also use the advanced composition mechanism
(Kairouz et al., 2015a) with a refined analysis, but the main dependence over n and d will remain nearly the same.

Non-interactive Local DP Learning

population mean, we can get error rates with logarithmic
dependence on d. Our results are in sharp contrast with the
lower bound for `2 -bounded general mean estimation under standard DP (Bassily et al., 2014), as well as the lower
bound for `∞ -bounded 1-sparse mean estimation under local DP (Duchi et al., 2016). It can be easily seen that our
method extends to mean estimation problem for arbitrary
low-complexity constraint set in high dimensions. We state
our results in `1 setting to keep the arguments clear. Our
problem adopts a statistical estimation setting as follows:
`2 -bounded sparse mean estimation Suppose there is
an unknown distribution D supported on B(0, 1), with
kED (x)k1 ≤ Λ. The `2 -bounded sparse mean estimation
problem requires us to produce an estimator θ̂ that makes
kθ − ED (x)k2 small with high probability.
Algorithm 2 LDP `1 Constrained Mean Estimation
Input: x1 , x2 , · · · , xn ∼ i.i.d.D
Output: Estimator
√ z
Set p = dΛ ne, and m = d18 log 1δ e
Sample G ∼ √1p N (0, 1)p×d .
for User i do
Collect yi = Gxi + ri ,
with ri ∼ i.i.d.N (0, 2 log(1.25/δ)
Ip )
2
end for
for j ∈ {1,
n 2, · · · , m} do
o
(j−1)n
m ,2
P
1
i∈Sj
|Sj |

Sj = 1 +

+

(j−1)n
m ,···

m

P r[dX (θ̂, θ) ≥ 3] ≤ e− 18
m
2

	

.
Since the original data are i.i.d. samples from underlying
distribution, small group with fixed indices should also be
i.i, d.. Therefore µ1 , µ2 , · · · , µk are i.i.d.. Combining
Lemma 3 and Lemma 4 we get the following result:

z

100p log(nd/δ)


Lemma 3. Let x1 , x2 , · · · , xn ∼ i.i.d.D with µ = ED [x]
and supp(D) ⊆ B(0, 1). Let G and {yi }ni=1 defined in the
above procedure. For each of group Sj fixed, we have the
following with probability 2/3:
!

 1 X
p log(nd)


p
(2)
yi − Gµ ≤ O

|Sj |
1
 |Sj |
yi ∈Sj

Lemma 4 (Proposition 9 in (Hsu & Sabato, 2016)).
Suppose in metric space X , a set of points M =
[θ1 , θ2 , · · · , θm ] ∼ i.i.d.D, with P r[dX (θi , θ) ≥ ] ≤ 23 .
Let θ̂ be generated from the following
procedure: ri =
	
min r : |BX (θi , r) ∩ M| ≥ m
,and
θ̂
= arg minθi ri .
2
Then we have:

arg minkzk1
s.t.kGz − uk1 ≤

We first give the following bound on the error in projected
space.

The aggregation step in Algorithm 2 is a high-dimensional
generalization of Median-of-Mean estimator used in
heavy-tailed statistics. The tail properties are guaranteed
in the following lemma:

, jn
m .

yi .
Let µj =
end for
Let M = {µ1 , µ2 , · · · , µm }.
for j ∈ {1, 2, · · ·, m} do
Let rj = min r : |B`1 (µj , r) ∩ M| ≥
end for
Let j∗ = arg minj rj , and u = µj∗
Solve the following convex program:

nel. This locally private estimation procedure can be
viewed as a variant of noisy compressed sensing, where
`2 recovery rate is fundamentally controlled by the Gaussian Mean Width of constraint set (Vershynin, 2015).
Though the distribution has bounded support, the concentration for mean estimation is dimension-dependent,
while dimension-independent Markov Inequalities hold.
To tackle this problem, we employ Median-of-Mean estimator to get exponential tails (Hsu & Sabato, 2016).

r

m
n

(1)

In Algorithm 2 we describe our data collection procedure
and estimation algorithm. We are primarily using two
techniques: random projection and recovery from lowcomplexity structures; median-of-mean estimator to boost
failure probability. The privacy argument is directly implication of Theorem 1.
Intuitively, adding noise to each entry of mean vector will
result in error rate’s linear dependence on d. Thus we
adopt the random projection technique to send a compressed version of data vector through the noisy chan-

Corollary 1. The vector u constructed in Algorithm 2 satisfies the following with probability 1 − δ:
r 

p log(nd/δ) m
ku − Gµk1 ≤ O
(3)

n
Then we turn to the recovery of original mean estimator. The primary tool we are using are General M ∗ bound
in (Vershynin, 2015).
Lemma 5 (Theorem 6.2 in (Vershynin, 2015), High Probability Version). For unknown vector x ∈ K ⊆ Rd , let
G ∼ √1p N (0, 1)p×d . Noisy vector ν ∈ Rp with kνk1 ≤ σ.
Let y = Gx + ν. By solving the following optimization
problem:
arg min
kx0 kK
0
x

s.t. kGx0 − yk1 ≤ σ

(4)

Non-interactive Local DP Learning

where k·kK denotes the Minkowski functional of K. Then
we can get the following with probability 1 − δ
kx − x0 k2 ≤ O



w(K) + σ + log
√
p

1
δ



where w(K) denotes the Gaussian width of K.
By putting these results together we get the bound on estimation loss:
Theorem 2. Algorithm 2 outputs z satisfying the following
with probability 1 − δ:
nd
kz − µk2 ≤ O log
δ

r

1
log
δ



Λ2
2 n

 14 !

3.2. Sparse Linear Regression
In this section, we consider empirical
of sparse linear
Pn loss
1
T
regression, i.e. L(w; D) = 2n
(x
w
− yi )2 , where
i
i=1
D = {(xi , yi )|i ∈ [n]}, kxi k2 6 1, yi ∈ [−1, 1]. 2 .
Define w∗ = argminw∈C L(w; D), where C =
{w| kwk1 6 1}. We want to obtain a vector wpriv ∈ C
within non-interactive LDP model, such that the empirical
excess risk L(wpriv ; D) − L(w∗ ; D) has polynomial dependences on log d and n1 .
As in the case of high-dimensional mean estimation, directly manipulating in the original high dimensional feature space will introduce large noise, hence we use a subGaussian random matrix Φ ∈ Rm×d to project original data
(i.e. vectors in Rd ) into the low dimensional space (i.e.
Rm ) first, then perturb each data in low dimensional space
(i.e. Basic Private Vector mechanism given in Algorithm 1)
which protects local privacy, and send it to the server.
Having obtained private synopsis, the server then reconstruct an unbiased estimator for objective function according to these private synopsis. We subtract a quadratic term
to ensure unbiasedness and project to PSD matrices to preserve convexity. To show good approximation guarantee,
we make use of RIP bounds for random projection. As
the loss function is determined by inner products between
w and data, it could be uniformly preserved in projected
space, which guarantees the accuracy of solution estimated
with local privacy. Apparently, our methods also imply
bounds with general low-complexity constraint set that preserves RIP.
Our private learning mechanism is given in Algorithm
3 and any random projection matrix can be used here.
The privacy argument directly follows from Private Vector
Mechanism and composition.
2

Our methods suits to any radius of x and y.

Algorithm 3 LDP `1 Constrained Linear Regression
Input: Personal data (x, y), parameter , δ, projection matrix Φ ∈ Rd×m
Output: Learned classifier wpriv ∈ Rd
1: for Each user i = 1, . . . , n do
2:
zi ← Basic Private Vector (ΦT xi , /2, δ/2)
3:
vi ← Basic Private Vector (yi , /2, δ/2)
4: end for
√
2 2 ln(2.5/δ)
,
5: Setting Z = [z1 , · · · , zn ]T , σ =

Q = ProjS+ (Z T Z − nσ 2 Im ), v = [v1 , · · · , vn ]T
6: w priv ← argminw∈C L̂(w; Z, v), where
1
(ΦT w)T Q(ΦT w) − n1 v T ZΦT w
L̂(w; Z, v) := 2n

In fact, as original data is in L2 ball, and random projection
preserves norms with high probabilty, hence steps 2-4 in
Algorithm 1 will be executed with very low probability.
Denote the true objective function in low dimensional
2

1 
X̄ΦT w − n1 y T X̄ΦT w,
space L̄(w; X̄, y) := 2n
where X̄ = [x1 , · · · , xn ]T Φ, w ∈ C. Let ŵ∗ :=
argminw∈C L̄(w; X̄, y). The following lemma gives the
accuracy of private solution wpriv when reduced into low
dimensional space:
Lemma 6. Under the assumptions made in this section,
given projection matrix Φ, with high probability over the
randomness of private mechanism, we have
r

m
priv
∗
L̄(w
; X̄, y) − L̄(ŵ ; X̄, y) 6 Õ
(5)
n2
Now, combined with RIP bound for random projection, we
can move on to prove the empirical excess risk of sparse
linear regression:
Theorem
3. Under
 the assumption in this section, set m =
p
n2 log d , then with high probability , there is
Θ
L(wpriv ) − L(w∗ ) = Õ



log d
n2

1/4 !

Note (Talwar et al., 2015) assume data is in L∞ ball, while
both (Kasiviswanathan & Jin, 2016) and ours assume data
is in L2 ball. However, in LDP model, (Duchi et al., 2016)
show it was impossible to obtain polynomial dependences
over log d for `0 mean estimation problem if data is in L∞
ball.
3.3. Infinite Dimension: Kernel Ridge Regression
Previous method mainly applies to data with finite dimensional features. However, it is common to use kernel trick
in practice. This brings about new difficulties for LDP
learning, as we could not add noise in the Hilbert space.

Non-interactive Local DP Learning

In this subsection, we take kernel ridge regression as an example to show how to use Random Fourier Features (RFF)
(Rahimi et al., 2007) to deal with such cases caused by
shift-invariant kernels (i.e. k(x, y) = k(x − y)). Note
our technique also suits to similar problems.
Fix a shift-invariant kernel k(·, ·), denote the Hilbert space
implicitly defined as H, and the corresponding feature map
as Φ : Rd → H. Let the Hilbert space corresponding
to the random Fourier feature map be Ĥ ⊂ Rdp , and its
feature map Φ̂ : Rd → Ĥ, where dp is the RFF projection dimension. Given a subset X ⊂ Rd and data
D = {(xi , yi )|xi ∈ X , i ∈ [n]}, for any f ∈ H, g ∈ Ĥ,
define loss functions in H and Ĥ as follows:

C X
f T Φ(xi ) − yi 2 + 1 kf k2
(6)
LH (f ) :=
H
2
2n i
2
2 1
C X
 T

2
LĤ (g) :=
(7)
g Φ̂(xi ) − yi  + kgkĤ
2n i
2
2
where C is the regularization parameter. Denote f ∗ =
argminf ∈H LH (f ), g ∗ = argming∈Ĥ LĤ (g), G as the
Lipschitz constant of square loss, which depends on the
bounded norm of features. Kernel ridge regression try to
optimize formula (6), while after using RFF, we try to solve
formula (7) in non-interactive LDP model, which can be
easily tackled with similar mechanisms like sparse linear
regression above. Borrow the key result in (Rubinstein
et al., 2012) (restated in lemma 7 below), which used RFF
to design private mechanims for SVM in DP model, it becomes easy to prove guarantees for kernel ridge regression
in our setting (see Corollary 2).
Lemma 7 ((Rubinstein et al., 2012)). Suppose dual
variables with respect to f ∗ , g ∗ are L1 norm bounded
by some r > 0, and supx1 ,x2 ∈X |Φ(x1 )T Φ(x2 ) −
(Φ̂(x1 ))T Φ̂(x2 )| 6 γ,pthen there is supx∈X |Φ(x)T f ∗ −
(Φ̂(x))T g ∗ | 6 rγ + 2 (CG + r/2)rγ.
Corollary 2. Algorithm
 4 satisfies (, δ)-LDP, and by set√
2
ting dp = Õ
dn , with high probability, there is
LĤ (ŵ

priv

∗

)−LH (f ) 6 Õ



d
n2

sup |Φ(x)T f ∗ −(Φ̂(x))T ŵpriv | 6 Õ
x∈X

1/4 !



d
n2

1/8 !

4. Learning Smooth Generalized Linear
Model
In this section, we consider learning smooth generalized linear model in non-interactive LDP setting. Noninteractive LDP learning for this problem is essentially difficult, as it is even hard to obtain an unbiased estimator of

Algorithm 4 LDP kernel mechanism
Input: Personal data (xi , yi ), i ∈ [n], random feature’s
dimension dp , shift-invariant kernel k(x1 , x2 ) =
k(x1 − x2 ) with Fourier transform f (s) =
R −jsT x
1
e
k(x)dx, privacy parameter , δ
2π
Output: Private output ŵpriv ∈ Rdp
1: Draw i.i.d. samples s1 , s2 , . . . , sdp ∈ Rd from f (s)
and b1 , b2 , . . . , bdp ∈ R from the uniform distribution
on [0, 2π]
2: for i = 1, . . . , n do
3:
Construct low dimensional random feature Φ̂(xi ) =
i0
q h
1
T
T
∈
dp cos(s1 xi + b1 ), . . . , cos(sdp xi + bdp )
h q
q idp
⊂ Rd p
Cˆ := − d1p , d1p
4:
zi ← Basic Private Vector (Φ̂(xi ), /2, δ/2)
5:
vi ← Basic Private Vector (yi , /2, δ/2)
6: end for
√
7: Setting Z = [z1 , · · · , zn ]T , σ =

2

2 ln(2.5/δ)
,

[v1 , · · · , vn ]T

Q = ProjS+ (Z T Z − nσ 2 Idp ), v =
8: ŵ priv ← argminŵ L̂(ŵ; Z, v), where
1
L̂(ŵ; Z, v) := 2n
ŵT Qŵ − n1 v T Z ŵ

gradient. We resolve this problem using Chebyshev polynomial expansion, which requires additional smoothness
assumptions. Fortunately these assumptions are naturally
satisfied by a broad range of learning tasks.
We will first define the Smooth GLM loss family with
appropriate assumptions. Our definition could be shown
with connection to exponential family GLM, which is commonly used in machine learning. We also illustrate our algorithm and guarantees with logistic regression.
Definition 2. (Absolutely Smooth Functions) We say that
an univariate function h(x) is absolutely smooth, if for any
r > 0, f (x) := h(rx) satisfies the following properties:
there exist functions µ1 (k; r), µ2 (k; r), which are polynomial on k and µ2 (k; r) = O(kr), such that for any k ∈ N+ ,
there is:
(1) f (x), f 0 (x), . . . , f (k−1) (x) are absolutely continuous
on [−1, 1];


(2) f (k) (x)T 6 µ1 (k; r) · µ2 (k; r)k .
Definition 3. (Smooth Generalized Linear Loss, SGLL) A
loss function `(w; x, y), is called smooth generalized linear loss, if for any given data (x, y), `(w; x, y) is convex
and β-smooth with respect to w, and there exist absolutely
smooth functions h1 (x), h2 (x), such that `(w; x, y) =
−yh1 (xT w) + h2 (xT w).
It will be convenient to consider population risk directly.
Now, we adopt standard setting of learning problems,

Non-interactive Local DP Learning

where each data point (x, y) is drawn from some underlying unknown distribution D and kxk2 6 1. Given
a SGLL `(w; x, y), the population loss is defined as
L(w) := E(x,y)∼D `(w; x, y). For simplicity, instead
of assuming w belongs to B2 (r), we use the following equivalent notation: `(w; x, y) = −yh1 (rxT w) +
h2 (rxT w), and the constraint set for w is C = B2 (1).
Denote G(w; x, y) = ∇`(w; x, y) = rm(w; x, y)x,
where m(w; x, y) = h02 (rxT w) − yh01 (rxT w). Suppose
2
E(x,y)∼D [kG(w; x, y) − g(w)k2 ] 6 σ02 , where g(w) =
∇L(w). This is a common assumption in stochastic optimization literature, such as (Bubeck et al., 2015).
Given any α > 0, we hope to design a noninteractive local
DP mechanism with low sample complexity, such that the
final output point wpriv satisfies L(wpriv ) − L(w∗ ) 6 α.
For GLM loss functions, it is easy to see that the stochastic
gradient evaluated on w with data point xi is at the same
direction with xi . So adding isotropic noise to xi provides
”unbiased” information about direction of stochastic gradient. However, the magnitude is a nonlinear function of
wT xi , making it hard for SGD even to converge to population minimizer. This is why we seek to find polynomial
approximation of the magnitude of gradients.
To estimate the magnitude of gradients, we use Chebyshev
polynomials to approximate nonlinear univariate function
fi (x) = h0i (rx), where x ∈ [−1, 1]. For brevity of
notations, we just use f (x) to represent either f1 (x) or
f2 (x). Denote the Chebyshev approximation with degree
Pp
p as fˆp (x) = 12 + k=1 ak Tk (x), where Tk (x) is the kR1
(x)
√ k
dx
th Chebyshev polynomial, and ak = π2 −1 f (x)T
1−x2
is the corresponding coefficient. According to existing results about Chebyshev approximations and some calculations, we have the following lemma:
Lemma 8. Given any α > 0, by setting k =
c ln α1 , p = dk +
 eµ2 (k; r)e, where c is a constant, we have
ˆ

fp (x) − f (x) 6 α
∞

The Chebyshev approximations with degree p for fi (x)
Pp
(i = 1, 2) are denoted as fˆip (x) = 21 + k=1 aik Tk (x) =
P
p
k
k
k=0 cik x , where cik is the coefficient of term x . Now
we approximate m(w; x, y) and G(w; x, y) as follows:

in Algorithm 1. Note an important trick in Step 6-8 of
Algorithm 5, is that: we run basic private mechanism p
times, to obtain fresh private copies of the same vector x,
which are then used to calculate an unbiased estimation of
Ĝ(w; x, y) with variance as low as possible (i.e. line 8 in
Algorithm 6).The LDP property of Algorithm 5 is given
as follows: The privacy proof directly follows from Basic
Algorithm 5 LDP SGLD Mechanism - Collection
Input: Personal data (x, y), expansion order p, privacy parameter , δ
Output: Private synopsis b = {zyi , zj |i ∈ {0} ∪ [p], j ∈
[p(p + 1)/2]} sent to the server
δ


, δy = 4(p+1)
, 1 = p(p+1)
, δ1 =
1: Setting y = 4(p+1)
δ
p(p+1)

2:
3:
4:
5:
6:
7:
8:

z0 ← Basic Private Vector(x, /4, δ/4)
for i = 0, 1, . . . , p do
zyj ← Basic Private Vector(y, y , δy )
end for
for j = 1, . . . , p(p+1)
do
2
zj ← Basic Private Vector(x, 1 , δ1 )
end for

Vector Mechanism and Composition Theorem.
Theorem 4. LDP SGLD Mechanism 5 preserves (, δ)LDP.
Having obtained the private synopsis sent by all uers, now
the server can construct a stochastic inexact gradient oracle
(defined in Defintion 4) for any point w ∈ C, as stated in
Algorithm 6.
Definition 4. (Dvurechensky & Gasnikov, 2016) For an objective function f (w), a (γ, β, σ) stochastic oracle returns
a turple (Fγ,β,σ (w; ξ), Gγ,β,σ (w; ξ)), such that:
Eξ [Fγ,β,σ (w; ξ)] = fγ,β,σ (w)
Eξ [Gγ,β,σ (w; ξ)] = gγ,β,σ (w)
2

Eξ [kGγ,β,σ (w; ξ) − gγ,β,σ (w)k ] 6 σ 2
β
2
0 6 h(v, w) 6 kv − wk + γ, ∀v, w ∈ C
2
where h(v, w) = f (v) − fγ,β,σ (w) − hgγ,β,σ (w), v − wi.

m̂(w; x, y) := − y fˆ1p (rxT w) + fˆ2p (rxT w)
=

p
X

(c2k − c1k y)(rxT w)k

k=0

Ĝ(w; x, y) :=rm̂(w; x, y)x

With these approximations, we state our mechanism in Algorithm 5, where Basic Private Vector mechanism is given

For any (x, y) in the domain, as loss function `(w; x, y) is
convex and β-smooth with respect to w, we can prove the
following lemma:
Lemma 9. For any γ > 0, setting k = c ln 4r
γ ,p =
dk + 2µ2 (k; r)e, then Algorithm 6 outputs a (γ, β, σ)
stochastic
oracle defined in Definition 4, where σ =

2p+1
(4r)p+1
Õ σ0 + γ + p p+2
.

Non-interactive Local DP Learning

Algorithm 6 LDP SGLD Mechanism - Learning
Input: Private synopsis b = {zy , zj |j ∈ {0} ∪ [p(p +
1)/2]} of each user, public coefficients {c1k , c2k |k ∈
{0} ∪ [p]}, initial point w1
Output: Learned classifier wpriv
1: for s = 1, . . . , n do
2:
\\ Construct stochastic inexact gradient
3:
\\ Denote the private synopsis of user s as b above
for abbreviation
4:
Set t0 = 1
5:
for j = 1, . . . , p do
Qj(j+1)/2
6:
tj = i=j(j−1)/2+1 (wsT zi )
7:
end for
!
p
X
k+1
8:
G̃(ws ; b) ←
(c2k − c1k zyj )tk r
z0
k=0

\\ One update via SIGM
Run one iteration of SIGM algorithm with G̃(ws , b)
and obtain ws+1
11: end for
12: Set w priv := wn+1

9:
10:

highly nonlinear, we even can not obtain an unbiased estimation either for objective function or gradients. However,
our method shows it possible to learn smooth GLM with
quasi-polynomial sample complexity.
4.1. Example: Learning Logistic Regression
Either from the view of exponential family generalized
linear model or the concrete loss function, it is not difficult to see logistic loss belongs to SGLL. For example,
T
in logistic regression,
`(w; x, y) = log(1+ e−yw x ) =


T
− y2 wT x + 12 wT x + ln(1 + e−w x ) . So we let
h1 (x) = x2 , h2 (x) = x2 +ln(1+e−x ). As we know logistic
loss is convex and β-smooth for some parameter β, and the
absolutely smooth property of linear function is obvious,
hence once we prove f (x) = ln(1 + e−x ) is absolutely
smooth, then logistic loss satisfies the definition of SGLL.
Proposition 1. f √
(x) = ln(1 + e−x ) is absolutely smooth
with µ1 (k; r) = r 4kπ 3 , µ2 (k; r) = rk
e
Hence, we can use private mechanisms (5,6) to learn logistic regression.

Based on above (γ, β, σ) stochastic oracle, and the algorithm proposed in SIGM paper (Dvurechensky & Gasnikov, 2016) (omitted here, due to the limitation of space),
our complete learning algorithm is given in Algorithm 6.
Before proving our sample complexity, we state the basic
convergence result of SIGM algorithm:
Lemma 10 ((Dvurechensky & Gasnikov, 2016)). Assume
a function f (w) (suppose constrain set is W) is endowed
with a (γ, β, σ) stochastic oracle, then the sequence wk
(corresponds to yk in the original paper) generated by the
SIGM algorithm satisfies:


σ
∗
E[f (wk )] − f (w ) 6 O √ + γ
k
where expectation is over the randomness of the stochastic
oracle and w∗ = argminw∈W f (w).
The accuracy results directly follows from the quality of
inexact stochastic gradient oracle we constructed, and the
convergence result of SIGM.
Theorem 5. Consider smooth generalized linear loss. For
any setting α > 0, by setting γ = α2 , k = c ln 4r
γ ,p =
dk + 2µ2 (k; r)e in Algorithm 5, 6, if
 2cr ln(8r/α)+2 
!
8r 4r ln ln(8r/α) 4r
1
n>O ( )
,
α

α 2 2
we can achieve loss guarantee L(wpriv ) − L(w∗ ) 6 α
As we can see, learning in non-interactive LDP model is
more difficult than interactive form, especially when loss is

Theorem 6. Consider Logistic regression problem with
`(w; x, y) = log(1 + exp(−ywT x)) For any α > 0,
by setting γ = α2 , k = c ln 4r
r)e,
γ , p = dk + 2µ2 (k;



8r 4r ln ln(8r/α) 4r 2cr ln(8r/α)+2
1
if n > O ( α )
in

α2 2
Algorithm 5, 6, we can achieve L(wpriv ) − L(w∗ ) 6 α.

5. Conclusions
In this paper, we consider how to design efficient algorithms for common learning and estimation problems under
non-interactive LDP model. In particular, for sparse linear
regression and mean estimation problem, we propose efficient algorithms and prove the polynomial dependence of
excess risk or square error over log d and n1 , which is exactly to be expected in high dimensional case. We also
extend our methods to nonparametric case and show good
bounds for Kernel Ridge Regression.
For more difficult smooth generalized linear loss optimization problems, we use private Chebyshev approximations
to estimate gradients of the objective loss, combined with
existing inexact gradient descent methods to obtain final
outputs. The sample complexity of our mechanism is
quasi-polynomial with respect to α1 , where α is the desired
population excess risk.
An interesting open problem is whether our theoretical
guarantees are optimal. If not, how to improve them while
preserving the efficiency in non-interactive LDP model.
We think these problems are critical to understand LDP in
the future.

Non-interactive Local DP Learning

Acknowledgments
This work was partially supported by National Basic
Research Program of China (973 Program) (grant no.
2015CB352502), NSFC (61573026). We would like to
thank the anonymous reviewers for their valuable comments on our paper.

References
Bassily, Raef and Smith, Adam. Local, private, efficient
protocols for succinct histograms. In Proceedings of the
Forty-Seventh Annual ACM on Symposium on Theory of
Computing, pp. 127–135. ACM, 2015.
Bassily, Raef, Smith, Adam, and Thakurta, Abhradeep. Private empirical risk minimization: Efficient algorithms
and tight error bounds. In Foundations of Computer Science (FOCS), 2014 IEEE 55th Annual Symposium on,
pp. 464–473. IEEE, 2014.
Bubeck, Sébastien et al. Convex optimization: Algorithms
R in Machine
and complexity. Foundations and Trends
Learning, 8(3-4):231–357, 2015.
Chaudhuri, K. and Monteleoni, C. Privacy-preserving logistic regression. In Conference on Neural Information
Processing Systems, British Columbia, Canada, December, pp. 289–296, 2008.
Chaudhuri, K., Monteleoni, C., and Sarwate, A. D. Differentially private empirical risk minimization. The Journal
of Machine Learning Research, 12:1069–1109, 2011.
Duchi, John, Wainwright, Martin J, and Jordan, Michael I.
Local privacy and minimax bounds: Sharp rates for
probability estimation. In Advances in Neural Information Processing Systems, pp. 1529–1537, 2013a.
Duchi, John, Wainwright, Martin, and Jordan, Michael.
Minimax optimal procedures for locally private estimation. arXiv preprint arXiv:1604.02390, 2016.
Duchi, John C, Jordan, Michael I, and Wainwright, Martin J. Local privacy and statistical minimax rates. In
Foundations of Computer Science (FOCS), 2013 IEEE
54th Annual Symposium on, pp. 429–438. IEEE, 2013b.
Dvurechensky, Pavel and Gasnikov, Alexander. Stochastic
intermediate gradient method for convex problems with
stochastic inexact oracle. Journal of Optimization Theory and Applications, 171(1):121–145, 2016.
Dwork, C., McSherry, F., Nissim, K., and Smith, A. Calibrating noise to sensitivity in private data analysis. In
Theory of cryptography, pp. 265–284. Springer, New
York, USA, 2006.

Dwork, Cynthia and Roth, Aaron.
The algorithmic
foundations of differential privacy. Foundations and
R in Theoretical Computer Science, 9(3–4):211–
Trends
407, 2014.
Feldman, Vitaly, Guzmán, Cristóbal, and Vempala, Santosh. Statistical query algorithms for mean vector estimation and stochastic convex optimization. In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, pp. 1265–1277. Society for
Industrial and Applied Mathematics, 2017.
Geng, Quan and Viswanath, Pramod. The optimal mechanism in differential privacy. In Information Theory
(ISIT), 2014 IEEE International Symposium on, pp.
2371–2375. IEEE, 2014.
Hardt, M. and Rothblum, G. N. A multiplicative weights
mechanism for privacy-preserving data analysis. In
IEEE Symposium on Foundations of Computer Science,
pp. 61–70, 2010.
Hardt, M., Ligett, K., and Mcsherry, F. A simple and practical algorithm for differentially private data release. In
Advances in Neural Information Processing Systems, pp.
2339–2347, 2012.
Hsu, Daniel and Sabato, Sivan. Loss minimization and parameter estimation with heavy tails. Journal of Machine
Learning Research, 17(18):1–40, 2016.
Kairouz, Peter, Oh, Sewoong, and Viswanath, Pramod.
Extremal mechanisms for local differential privacy. In
Advances in neural information processing systems, pp.
2879–2887, 2014.
Kairouz, Peter, Oh, Sewoong, and Viswanath, Pramod. The
composition theorem for differential privacy. In Proceedings of The 32nd International Conference on Machine Learning, pp. 1376–1385, 2015a.
Kairouz, Peter, Oh, Sewoong, and Viswanath, Pramod. Secure multi-party differential privacy. In Advances in
Neural Information Processing Systems, pp. 2008–2016,
2015b.
Kairouz, Peter, Bonawitz, Keith, and Ramage, Daniel. Discrete distribution estimation under local privacy. In Proceedings of The 33rd International Conference on Machine Learning, pp. 2436–2444, 2016.
Kasiviswanathan, S. P., Lee, H. K., Nissim, K., Raskhodnikova, S., and Smith, A. What can we learn privately?
In IEEE Symposium on Foundations of Computer Science, pp. 531–540, 2008.
Kasiviswanathan, Shiva Prasad and Jin, Hongxia. Efficient
private empirical risk minimization for high-dimensional

Non-interactive Local DP Learning

learning. In Proceedings of The 33rd International Conference on Machine Learning, pp. 488–497, 2016.
Kasiviswanathan, Shiva Prasad, Lee, Homin K, Nissim,
Kobbi, Raskhodnikova, Sofya, and Smith, Adam. What
can we learn privately? SIAM Journal on Computing, 40
(3):793–826, 2011.
Kearns, Michael. Efficient noise-tolerant learning from statistical queries. Journal of the ACM (JACM), 45(6):983–
1006, 1998.
Kifer, Daniel, Smith, Adam, and Thakurta, Abhradeep.
Private convex empirical risk minimization and highdimensional regression. Journal of Machine Learning
Research, 1(41):3–1, 2012.
Lei, J. Differentially private m-estimators. In Advances
in Neural Information Processing Systems, pp. 361–369,
2011.
Rahimi, Ali, Recht, Benjamin, et al. Random features for
large-scale kernel machines. In NIPS, volume 3, pp. 5,
2007.
Rubinstein, B., Bartlett, P. L., Huang, L., and Taft, N.
Learning in a large function space: Privacy-preserving
mechanisms for svm learning. Journal of Privacy and
Confidentiality, 4(1):4, 2012.
Smith, A. Privacy-preserving statistical estimation with optimal convergence rates. In ACM Symposium on Theory
of Computing, STOC, pp. 813–822, 2011.
Smith, Adam and Thakurta, Abhradeep. Differentially private model selection via stability arguments and the robustness of the lasso. J Mach Learn Res Proc Track, 30:
819–850, 2013.
Talwar, Kunal, Thakurta, Abhradeep, and Zhang, Li.
Nearly optimal private lasso. In Advances in Neural Information Processing Systems, pp. 3025–3033, 2015.
Thaler, J., Ullman, J., and Vadhan, S. Faster algorithms
for privately releasing marginals. In International Colloquium on Automata, Languages, and Programming, volume 7391, pp. 810–821. 2012.
Vershynin, Roman. Estimation in high dimensions: a geometric perspective. In Sampling theory, a renaissance,
pp. 3–66. Springer, 2015.
Wang, Y., Fienberg, S. E., and Smola, A. J. Privacy for free:
Posterior sampling and stochastic gradient monte carlo.
In International Conference on Machine Learning, pp.
2493–2502, 2015.

Wang, Z., Jin, C., Fan, K., Zhang, J., Huang, J., Zhong,
Y., and Wang, L. Differentially private data releasing for
smooth queries. Journal of Machine Learning Research,
17(51):1–42, 2016.
Warner, Stanley L. Randomized response: A survey technique for eliminating evasive answer bias. Journal of the
American Statistical Association, 60(309):63–69, 1965.
Zhang, Jiaqi, Zheng, Kai, Mou, Wenlong, and Wang, Liwei. Efficient private erm for smooth objectives. arXiv
preprint arXiv:1703.09947, 2017.
Zhang, Jun, Zhang, Zhenjie, Xiao, Xiaokui, Yang, Yin, and
Winslett, Marianne. Functional mechanism: regression
analysis under differential privacy. Proceedings of the
VLDB Endowment, 5(11):1364–1375, 2012.

