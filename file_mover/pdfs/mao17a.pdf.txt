On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Xueyu Mao 1 Purnamrita Sarkar 2 Deepayan Chakrabarti 3

Abstract
The problem of finding overlapping communities in networks has gained much attention recently. Optimization-based approaches use nonnegative matrix factorization (NMF) or variants,
but the global optimum cannot be provably attained in general. Model-based approaches,
such as the popular mixed membership stochastic
blockmodel or MMSB (Airoldi et al., 2008), use
parameters for each node to specify the overlapping communities, but standard inference techniques cannot guarantee consistency. We link
the two approaches, by (a) establishing sufficient
conditions for the symmetric NMF optimization
to have a unique solution under MMSB, and (b)
proposing a computationally efficient algorithm
called GeoNMF that is provably optimal and
hence consistent for a broad parameter regime.
We demonstrate its accuracy on both simulated
and real-world datasets.

1. Introduction
Community detection is a fundamental problem in network analysis. It has been widely used in a diverse
set of applications ranging from link prediction in social networks (Soundarajan & Hopcroft, 2012), predicting
protein-protein or protein-DNA interactions in biological
networks (Chen & Yuan, 2006), to network protocol design such as data forwarding in delay tolerant networks (Lu
et al., 2015).
Traditional community detection assumes that every node
in the network belongs to exactly one community, but
many practical settings call for greater flexibility. For

instance, individuals in a social network may have multiple interests, and hence are best described as members of multiple interest-based communities. We focus
on the popular mixed membership stochastic blockmodel
(MMSB) (Airoldi et al., 2008) where each node i, i ∈ [n]
has a discrete probability distribution θi = (θi1 , . . . , θiK )
over K communities. The probability of linkage between
nodes i and j depends on the degree of overlap between
their communities:
θi ∼ Dirichlet(α)
P = ρΘBΘ

T

Aij = Aji = Bernoulli(Pij )

i ∈ [n]
i, j ∈ [n]

where θi is the i-th row of Θ, A represents the adjacency matrix of the generated graph, and B ∈ RK×K
is the community-community interaction matrix. The parameter ρ controls the sparsity of the graph, so WLOG,
the largest
P entry of B can be set to 1. The parameter
α0 = i αi controls the amount of overlap. In particular,
when α0 → 0, MMSB reduces to the well known stochastic blockmodel, where every node belongs to exactly one
community. Larger α0 leads to more overlap. Since we
only observe A, a natural question is: how can {θi } and B
be recovered from A in a way that is provably consistent?
1.1. Prior work
We categorize existing approaches broadly into three
groups: model-based parameter inference methods, specialized algorithms that offer provable guarantees, and
optimization-based methods using non-negative matrix
factorization.

1
Department of Computer Science. 2 Department of Statistics
and Data Sciences. 3 Department of Information, Risk, and Operations Management. The University of Texas at Austin, TX, USA.
Correspondence to: Xueyu Mao <xmao@cs.utexas.edu>, Purnamrita Sarkar <purna.sarkar@austin.utexas.edu>, Deepayan
Chakrabarti <deepay@utexas.edu>.

Model-based methods: These apply standard techniques
for inference of hidden variables to the MMSB model. Examples include MCMC techniques (Chang, 2012) and variational methods (Gopalan & Blei, 2013). While these often
work well in practice, there are no proofs of consistency for
these methods. The MCMC methods are difficult to scale
to large graphs, so we compare against the faster variational
inference methods in our experiments.

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

Algorithms with provable guarantees: There has been
work on provably consistent estimation on models similar
to MMSB. Zhang et al. (2014) propose a spectral method

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

(OCCAM) for a model where the θi has unit `2 norm (unlike MMSB, where they have unit `1 norm). In addition to
the standard assumptions regarding the existence of “pure”
nodes1 (which only belong to a single community) and a
positive-definite B, they also require B to have equal diagonal entries, and assume that the ground truth communities has a unique optimum of a special loss function,
and there is curvature around the optimum. Such assumptions may be hard to verify. Ray et al. (2015) and Kaufmann et al. (2016) consider models with binary community memberships. Kaufmann et al. (2016) show that the
global optimum of a special loss function is consistent.
However, achieving the global optimum is computationally
intractable, and the scalable algorithm proposed by them
(SAAC) is not provably consistent. Anandkumar et al.
(2014) propose a tensor based approach for MMSB. Despite their elegant solution the computational complexity is
O(n2 K), which can be prohibitive for large graphs.
Optimization-based methods: If B is positive-definite,
the MMSB probability matrix P can be written as
P = WWT , where the W matrix has only non-negative
entries. In other words, W is the solution to a Symmetric Non-negative Matrix Factorization (SNMF) problem:
W = arg minX≥0 loss(P, XXT ) for some loss function
that measure the “difference” between P and its factorization. SNMF has been widely studied and successfully used
for community detection (Kuang et al., 2015; Wang et al.,
2011; 2016; Psorakis et al., 2011), but typically lacks the
guarantees we desire. Our paper attempts to address these
issues.
We note that Arora et al. (2012; 2013) used NMF to consistently estimate parameters of a topic model. However,
their results cannot be easily applied to the MMSB inference problem. In particular, for topic models, the columns
of the word-by-topic matrix specifying the probability distribution of words in a topic sum to 1. For MMSB, the rows
of the node membership matrix sum to 1. The relationship
of this work to the MMSB problem is unclear.
1.2. Problem Statement and Contributions
We seek to answer two problems.
Problem 1: Given P, when does the solution to the SNMF
optimization yield the correct W?
The difficulty stems from the fact that (a) the MMSB model
may not always be identifiable, and (b) even if it is, the corresponding SNMF problem may not have a unique solution
1
This is a common assumption even for NMF methods for
topic modeling, where each topic is assumed to have an anchor
word (words belonging to only one topic). Huang et al. (2016)
introduced a special optimization criterion to relax the presence
of anchor words, but the optimization criterion is non-convex.

(even after allowing for permutation of communities).
Even when the conditions for Problem 1 are met, we may
be unable to find a good solution in practice. This is due
to two reasons. First, we only know the adjacency matrix
A, and not the probability matrix P. Second, the general
SNMF problem is non-convex, and SNMF algorithms can
get stuck at local optima. Hence, it is unclear if an algorithm can consistently recover the MMSB parameters. This
leads to our next question.
Problem 2: Given A generated from a MMSB model, can
we develop a fast and provably consistent algorithm to infer
the parameters?
Our goal is to develop a fast algorithm that provably solves
SNMF for an identifiable MMSB model. Note that generic
SNMF algorithms typically do not have any provable guarantees.
Our contributions are as follows.
Identifiability: We show conditions that are sufficient for
MMSB to be identifiable; specifically, there must be at least
one “pure” exemplar of each of the K clusters (i.e., a node
that belongs to that community with probability 1), and B
must be full rank.
Uniqueness under SNMF: We provide sufficient conditions under which an identifiable MMSB model is the
unique solution for the SNMF problem; specifically, the
MMSB probability matrix P has a unique SNMF solution
if B is diagonal. It is important to note that MMSB with
a diagonal B still allows for interactions between different
communities via members who belong to both.
Recovery algorithm: We present a new algorithm, called
GeoNMF, for recovering the parameters {θi } and B given
only the observed adjacency matrix A. The only computeintensive part of the algorithm is the calculation of the topK eigenvalues and eigenvectors of A, for which highly optimized algorithms exist (Press et al., 1992).
Provable guarantees: Under the common assumption that
θi are generated from a Dirichlet(α) prior, we prove the
consistency of GeoNMF when B is diagonal and there
are “pure” nodes for each cluster (exactly the conditions
needed for uniqueness of SNMF). We allow the sparsity
parameter ρ to decay with the graph size n. All proofs are
deferred to the appendix.
Empirical validation: On simulated networks, we compare GeoNMF against variational methods (SVI) (Gopalan
& Blei, 2013). Since OCCAM, SAAC, and BSNMF (a
Bayesian variant of SNMF (Psorakis et al., 2011)) are
formed under different model assumptions, we exclude
these for the simulation experiments for fairness. We
also run experiments on Facebook and Google Plus ego

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

networks collected by Mcauley & Leskovec (2014); coauthorship datasets constructed by us from DBLP (Ley,
2002) and the Microsoft academic graph (MAG) (Sinha
et al., 2015). These networks can have up to 150,000
nodes. On these graphs we compare GeoNMF against SVI,
SAAC, OCCAM and BSNMF. We see that GeoNMF is
consistently among the top, while also being one of the
fastest. This establishes that GeoNMF achieves excellent
accuracy and is computationally efficient in addition to being provably consistent.

2. Identifiability and Uniqueness
In order to present our results, we will now introduce some
key definitions. Similar definitions appear in (Zhang et al.,
2014).
Definition 2.1. A node i ∈ [n] is called a “pure” node if
∃ j ∈ [K] such that θij = 1 and θi` = 0 for all ` ∈ [K],
` 6= j.
Identifiability of MMSB. MMSB is not identifiable in
general. Consider the following counter example.




0.5 0.5 0
0.5 0.25 0.25
M1 =  0 0.5 0.5 M2 = 0.25 0.5 0.25
0.5 0 0.5
0.25 0.25 0.5
It can be easily checked that the probability matrices
P generated by the parameter set (Θ(1) , B(1) , ρ(1) ) =
(M1 , I3×3 , 1) is exactly the same as that generated by
(Θ(2) , B(2) , ρ(2) ) = (I3×3 , 2M2 , 0.5), where I3×3 is the
identity matrix. This example can be extended to arbitrar(2)
ily large n: for every new row θi added to Θ(2) , add the
(1)
(2)
row θi = θi M1 to Θ(1) . The new rows are still nonnegative and sum to 1; it can be verified that P(1) = P(2)
even after these new node additions.
Thus, while MMSB is not identifiable in general, we can
prove identifiability under certain conditions.
Theorem 2.1 (Sufficient conditions for MMSB identifiability). Suppose parameters Θ, B of the MMSB model satisfy
the following conditions: (a) there is at least one pure node
for each community, and (b) B has full rank. Then, MMSB
is identifiable up to a permutation.
Since identifiability is a necessary condition for consistent
recovery of parameters, we will assume these conditions
from now on.
Uniqueness of SNMF for MMSB model. Even when the
MMSB model is identifiable, the SNMF optimization may
not have a unique solution. In other words, given an MMSB
probability matrix P, there might be multiple matrices X
such that P = XXT , even if P corresponds to a unique
parameter setting (Θ, B, ρ) under MMSB. For SNMF to

√
work, W = ρΘB1/2 must the the unique SNMF solution. When does this happen?
In general, SNMF is not unique because W can be permuted, so we consider the following definition of uniqueness.
Definition 2.2. (Uniqueness of SNMF (Huang et al.,
2014)) The Symmetric NMF of P = WWT is said to
be (essentially) unique if P = W̃W̃T implies W̃ = WZ,
where Z is a permutation matrix.
Theorem 2.2 (Uniqueness of SNMF for MMSB). Consider an identifiable MMSB model where B is diagonal. Then, its Symmetric NMF W is unique and equals
√
ρΘB1/2 .
The above results establish that if we find a W that is the
symmetric NMF solution of P then it is at least unique.
However, two practical questions are still unanswered.
First, given the non-convex nature of SNMF, how can we
guarantee that we find the correct W given P? Second, in
practice we are given not P but the noisy adjacency matrix
A. Typical algorithms for SNMF do not provide guarantees even for the first question.

3. Provably consistent inference for MMSB
To achieve consistent inference, we turn to the specific
structure of the MMSB model. We motivate our approach
in three stages. First, note that under the conditions of Theorem 2.2, the rows of W form a simplex whose corners
are formed by the pure nodes for each cluster. In addition,
these corners are aligned along different axes, and hence
are orthogonal to each other. Thus, if we can detect the
corners of the simplex, we can recover the MMSB parameters. So the goal is to find the pure nodes from different
clusters, since they define the corners.
While our goal is to get W, note that it is easy to compute VE1/2 where V, E are the eigenvectors and eigenvalues of P, i.e., P = VEVT . Thus, WWT =
(VE1/2 )(VE1/2 )T . This implies that W = VE1/2 Q
for some orthogonal matrix Q (Lemma A.1 of (Tang et al.,
2013)). Essentially we should be able to identify the pure
nodes by finding the corners of the simplex based on V and
E.
Once we have found the pure nodes, it is easy to find the
rotation matrix Q modulo a permutaion of classes, because
we know that the pure nodes are on the axis for the simplex
of ΘB1/2 .
Now, we note something rather striking. Let D denote
the diagonal matrix with expected degrees on the diagonal. Consider the population Laplacian D −1/2 PD −1/2 .
Its square root is given by D −1/2 VE1/2 , which has the
following interesting property for equal Dirichlet parame-

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

ters αa = α0 /K. We show in Lemma 4.1 that while the
resulting rows no longer fall on a simplex, the rows with
the largest norm are precisely
p the pure nodes, for whom the
norm concentrates around K/n. Thus, picking the rows
with the largest norm of the square root gives us the pure
nodes. From this, Q, θi for other rows and the parameters
ρ and B can again be easily extracted.
Needless to say, this only answers the question for the expectation matrix P. In reality, we have a noisy adjacency
matrix. Let V̂ and Ê denote the matrices of eigenvectors
and eigenvalues of A. We also establish in this paper that
the rows of V̂Ê1/2 concentrate around its population counterpart (corresponding row of VE1/2 O for some rotation
matrix O). While there are eigenvector deviation results
in random matrix theory, e.g. the Davis-Kahan Theorem
(Davis & Kahan, 1970), these typically provide deviation
results for the whole V̂ matrix, not its rows. In a nutshell,
this crucial result lets us carefully bound the errors of each
step of the same basic idea executed on A, the noisy proxy
for P.
Algorithm 1 GeoNMF
Input: Adjacency matrix A; number of communities K;
a constant 0
Output: Estimated node-community distribution matrix
Θ̂, Community-community interaction matrix B̂,
sparsity-control parameter ρ̂;
1: Randomly split the set of nodes [n] into two equalsized parts S and S̄.
2: Obtain the top K eigen-decomposition of A(S, S) as
V̂1 Ê1 V̂1T and of A(S̄, S̄) as V̂2 Ê2 V̂2T .
3: Calculate degree matrices D2 , D12 and D21 for the
rows of A(S̄, S̄), A(S, S̄) and A(S̄, S) respectively.
−1/2
−1/2
4: X̂ = n
D21 A21 V̂1 Ê1 , where A21 = A(S̄, S).
o
5: F =

i : kX̂(i, :)k2 ≥ (1 − 0 ) maxj kX̂(j, :)k2

q


K mini∈F D2 (i,i)
6: Sp = PartitionPureNodes X̂(F, :), 4n
maxi∈F D2 (i,i)

7: X̂p = X̂(Sp , :)


2


1/2
8: Get β̂, where β̂i = eT
i D21 (Sp , Sp )X̂p  , i ∈ [K]
2

9: B̂ = diag(β̂)
10: ρ̂ = maxi B̂ii
11: B̂ = B̂/ρ̂
1/2

−1/2

12: Θ̂(S̄, :) = D21 X̂X̂−1
p D21

(Sp , Sp )

13: Repeat steps with D12 , A12 , V̂2 , and Ê2 to obtain pa-

rameter estimates for the remaining bipartition.
Algorithm 1 shows our NMF algorithm based on these geometric intuitions for inference under MMSB (henceforth,
GeoNMF). The complexity of GeoNMF is dominated by
the one-time eigen-decomposition in step 2. Thus this algorithm is fast and scalable. The consistency of parameters

inferred under GeoNMF is shown in the next section.
Algorithm 2 PartitionPureNodes
Input: Matrix M ∈ Rm×K , where each row represents a
pure node; a constant τ
Output: A set S consisting of one pure node from each
cluster.
1: S = {}, C = {}.
2: while C 6= [m] do
3:
Randomly pick one index from [m] \ C, say s
4:
S = S ∪ {s}
5:
C = C ∪ {i ∈ [m] \ C : kM(s, :) − M(i, :)k ≤ τ }
6: end while
Remark 3.1. Note that Algorithm 1 produces two sets of
parameters for the two partitions of the graph S and S̄. In
practice one may need to have parameter estimates of the
entire graph. While there are many ways of doing this,
the most intuitive way would be to look at the set of pure
nodes in S (call this Sp ) and those in S̄ (call this S̄p ). If
one looks at the subgraph induced by the union of all these
pure nodes, then with high probability, there should be K
connected components, which will allow us to match the
communities.
Also note that Algorithm 2 may return k 6= K clusters.
However, we show in Lemma 4.4 that the pure nodes extracted by our algorithm will be highly separated and with
high probability we will have k = K for an appropriately
chosen τ .
Finally, we note that, in our implementation, we construct
the candidate pure node set F (step 5 of Algorithm 1) by
finding all nodes with norm within 0 multiplicative error
of the largest norm. We increase 0 from a small value,
until X̂p has condition number close to one. This is helpful
when n is small, where asymptotic results do not hold.

4. Analysis
We want to prove that the sample-based estimates Θ̂, B̂
and ρ̂ concentrate around the corresponding population parameters Θ, B, and ρ after appropriate normalization. We
will show this in several steps, which follow the steps of
GeoNMF.
For the following statements, denote βmin = mina Baa ,
Θ2 = Θ(S̄, :), where S̄ is one of the random bipartitions
of [n]. Let D21 be the population version of D21 defined in
−1/2
−1/2
Algorithm 1. Also let X̂i = eTi D21 A21 V̂1 Ê1
and
√
−1/2
its population version Xi = ρ · eTi D21 Θ2 B1/2 for
i ∈ [ n2 ].
First we show the pure nodes have the largest row norm of
the population version of X̂.

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations
n

Lemma 4.1. Recall that X ∈ R 2 ×K . If Θ ∼ Dirichlet(α)
with αi = α0 /K, then ∀i ∈ [ n2 ],
2
kXi k2

2K
≤
max θia 1 + OP
n a

r

K log n
n

!!

with probability larger than 1 − O(1/n3 ).
In particular, if node i of subgraph A(S̄, S̄) is a pure node
(maxa θia = 1),
2
kXi k2

"
2K
∈
1 − OP
n

r

K log n
n

!

r
, 1 + OP

K log n
n

!#
.

Concentration of rows of X̂. We must show that the rows
of the sample X̂ matrix concentrate around a suitably rotated population version. While it is known that V̂ concentrates around suitably rotated V (see the variant of DavisKahan Theorem presented in (Yu et al., 2015)), these results are for columns of the V matrix, not for each row. The
trivial bound for row-wise error would be to upper bound it
by the total error, which is too crude for our purposes. To
get row-wise convergence, we use sample-splitting (similar
ideas can be found in (McSherry, 2001; Chaudhuri et al.,
2012)), as detailed in steps 1 to 4 of GeoNMF. The key
idea is to split the graph in two parts and project the adjacency matrix of one part onto eigenvectors of another part.
Due to independence of these two parts, one can show concentration.
Theorem 4.2. Consider an adjacency matrix A generated from MMSB(Θ, B, ρ), where Θ ∼ Dirichlet(α) with
αi = α0 /K, whose parameters satisfy the conditions of
Theorem 2.2. If ρn = Ω(log n), then ∃ orthogonal matrix
O ∈ RK×K that ∀ i ∈ [ n2 ],
!
√
K 2 log n
kX̂i − Xi Ok2
= OP
5/2 √
kXi k2
β ρ n
min

with probability larger than 1 − O(K 2 /n2 ).
Thus, the sample-based quantity for each row i converges
to its population variant.
Selection of pure nodes. GeoNMF selects the nodes with
(almost) the highest norm. We prove
that this

 only selects
nearly pure nodes. Let 0 = OP

√
K 2 log n
5/2 √
βmin ρ n

represent the

row-wise error term from Theorem 4.2.
Lemma 4.3. Let F be the set of nodes with
kX̂i k2 ≥ (1 − 0 ) maxj kX̂j k2 . Then ∀i ∈ F,
max θia ≥ 1 − OP (0 + 0 )
a

with probability larger than 1 − O(K 2 /n2 ).

We choose 0 = OP (0 ) and it is straightforward to show
by Lemmas 4.1, 4.3, and Theorem 4.2 that if 0 ≥ 20 , then
F includes all pure nodes from all K communities.
Clustering of pure nodes. Once the (nearly) pure nodes
have been selected, we run PartitionPureNodes (Algorithm 2) on them. We show that these nodes can form exactly K well separated clusters and each cluster only contains nodes whose θ are peaked on the same element, and
PartitionPureNodes can select exactly one node from each
of the K communities.
q
K mini∈F D2 (i,i)
Lemma 4.4. Let τ =
4n maxi∈F D2 (i,i) , where F is
defined in step 5 of Algorithm 1. If all conditions in Theorem 4.2 are satisfied, then PartitionPureNodes (X̂(F, :), τ )
returns one (nearly) pure node from each of the underlying
K communities with probability larger than 1−O(K 2 /n2 ).
Concentration of (Θ̂, B̂, ρ̂). GeoNMF recovers Θ using
D, X̂, and its pure portion X̂p (via the inverse X̂−1
p ). We
concentrates
around
its
expectation.
first prove that X̂−1
p
Theorem 4.5. Let Sp be the set of of pure nodes extracted
using our algorithm. Let X̂p denote the rows of X̂ indexed
by Sp . Then, for the orthogonal matrix O from Theorem
4.2,
!
√
−1
kF
kX̂−1
K 5/2 log n
p − (Xp O)
= OP
5/2 √
kX−1
p kF
βmin ρ n
with probability larger than 1 − O(K 2 /n2 ).
Next, we shall prove consistency for Θ̂2 := Θ̂(S̄, :); the
proof for Θ̂(S, :) is similar. Let D21p = D21 (Sp , Sp ).
−1/2

1/2

Theorem 4.6. Let Θ̂2 = D21 X̂X̂−1
p D21p , then ∃ a permutation matrix Π ∈ RK×K such that

 3√
kΘ̂2 − Θ2 ΠkF
K log n
√
= OP
3 ρ n
kΘ2 kF
βmin
with probability larger than 1 − O(K 2 /n2 ).

Recall that B and B̂ are both diagonal matrices, with diagonal components {βa } and {β̂a } respectively.
1/2

Theorem 4.7. Let ρ̂β̂a = keTa D21 (Sp , Sp )X̂p k22 . Then,
∃ a permutation matrix Π ∈ RK×K such that ∀a ∈ [K],
"
ρ̂β̂a ∈ ρβa0 1 − OP

K 5/2 log n
5/2 √
βmin ρ n

!
, 1 + OP

K 5/2 log n
5/2 √
βmin ρ n

!#

for some a0 such that Πa0 a = 1, with probability larger
than 1 − O(K 2 /n2 ).

Remark 4.1. While the details of our algorithms were designed for obtaining rigorous theoretical guarantees, many

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

of these can be relaxed in practice. For instance, while
we require the Dirichlet parameters to be equal, leading
to balanced cluster sizes, real data experiments show that
our algorithm works well for unbalanced settings as well.
Similarly, the algorithm assumes a diagonal B (which is
sufficient for uniqueness), but empirically works well even
in the presence of off-diagonal noise. Finally, splitting the
nodes into S and S̄ is not needed in practice.

balanced clusters, note that the real datasets have clusters
of different sizes and we will show that GeoNMF works
consistently well even for those networks (see Section 5.2).
Unless otherwise stated, we set n = 5000, K = 3, and
α0 = 1.

5. Experiments

over all K × K permutation matrices. For each experiment, we report the average and the standard deviation over
10 random samples. Since all the baseline algorithms only
return Θ̂, we only report relative error of that.

We present results on simulated and real-world datasets.
Via simulations, we evaluate the sensitivity of GeoNMF to
the various MMSB parameters: the skewness of the diagonal elements of B and off-diagonal noise, the Dirichlet
parameter α that controls the degree of overlap, the sparsity parameter ρ, and the number of communities K. Then,
we evaluate GeoNMF on Facebook and Google Plus ego
networks, and co-authorship networks with upto 150,000
nodes constructed from DBLP and the Microsoft Academic
Network.
Baseline methods: For the real-world networks, we compare GeoNMF against the following methods2 :
• Stochastic variational inference (SVI) for MMSB
(Gopalan & Blei, 2013),
• a Bayesian variant of SNMF for overlapping community detection (BSNMF) (Psorakis et al., 2011),
• the OCCAM algorithm (Zhang et al., 2014) for recovering mixed memberships, and
• the SAAC algorithm (Kaufmann et al., 2016).
For the simulation experiments, we only compare
GeoNMF against SVI, since these are the only two methods based specifically on the MMSB model. BSNMF has a
completely different underlying model, OCCAM requires
rows of Θ to have unit `2 norm and B to have equal diagonal elements, and SAAC requires Θ to be a binary matrix,
while MMSB requires rows of Θ to have unit `1 norm.
Since the community identities can only be recovered up-to
a permutation, in both simulated and real data experiments,
we figure out the order of the communities using the well
known Munkres algorithm in (Munkres, 1957).
5.1. Simulated data
Our simulations with the MMSB model are shown in Figure 1. We use αi = α0 /K for i ∈ [K]. While this leads to
2

We were not to run Anandkumar et al. (2014)’s main (GPU)
implementation of their algorithm because a required library
CULA is no longer open source, and a complementary CPU implementation did not yield good results with default settings.

Evaluation Metric: Since we have ground truth Θ, we
report the relative error of the inferred MMSB parameters
kΘ̂−ΘΠk
Θ defined as min kΘk F . Here the minimum is taken
Π

F

Sensitivity to skewness of the diagonal of B: Let β =
diag(B). For skewed β, different communities have different strengths of connection. We use β = (0.5 −
B , 0.5, 0.5 + B ) and plot the relative error against varying B . Figure 1(a) shows that GeoNMF has much smaller
error than SVI, and is robust to β over a wide range.
Sensitivity to off-diagonal element B: While SNMF is
identifiable only for diagonal B, we still test GeoNMF in
the setting where all off-diagonal entries of B have noise
. Figure 1(b) shows once again that GeoNMF is robust to
such noise, and is much more accurate than SVI.
Sensitivity to α0 : In Figure 1(c), the relative error is plotted against increasing α0 ; larger values corresponding to
larger overlap between communities. Accuracy degrades
with increasing overlap, as expected, but GeoNMF is much
less affected than SVI.
Sensitivity to ρ: Figure 1(d) shows relative error against
increasing ρ. For dense networks, both GeoNMF and SVI
perform similarly, but the error of SVI increases drastically
in the sparse regime (small ρ).
Scalability: Figure 1(f) shows the wall-clock time for networks of different sizes. Both GeoNMF and SVI scale linearly with the number of nodes, but SVI is about 100 times
slower than GeoNMF.
5.2. Real-world data
Datasets: For real-data experiments, we use two kinds of
networks:
• Ego networks: We use the Facebook and Google
Plus (G-plus) ego networks, where each node can be
part of multiple “circles” or “communities.”
• Co-authorship networks3 : We construct co-authorship
networks from DBLP (each community is a group
3
Available at http://www.cs.utexas.edu/˜xmao/
coauthorship

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

GeoNMF
SVI

0.5

0.7

0.4

0.2

0.2

0.1

0.1

0.1
0.15

0.20

0.25

ǫB0.30

0.35

0.40

0.45

(a) ρ = 1, B = diag(β/ maxi βi ),
β = (0.5 − B , 0.5, 0.5 + B )
Varying sparsity

0.9

0.30
0.25

0.6

−2

10

ǫ

0.0

−1

104

GeoNMF
SVI

103

0.15

0.4

0.10

0.3

0.05

0.2

1.0

1.5

α02.0

20

30

60

90

150

Average degree

300

(d) B = diag(β),
β = (1, 1, 1), ρ = 1

500

−0.05
2

4

6

8

K

10

12

14

16

(e) B = diag(0.35 · 1K + 0.65 · rK ),
rK = rand(K, 1), ρ = 1

3.0

Wall-clock time (log scale)

102
101

GeoNMF
SVI

100

0.00

0.1

2.5

(c) ρ = 0.7, B = diag(β),
β = (0.4, 0.7, 1)

Num. communities

0.20

0.5

0.5

(b) B = diag(β −  · 1K ) +  · 1K 1TK ,
β = (0.6, 0.8, 1), ρ = 1

Θ̂ Relative Error

0.7

10

0.35

GeoNMF
SVI

0.8

10

−3

Running Time /s

0.10

Θ̂ Relative Error

0.3

0.3

0.2

0.0

0.5

0.4

0.5

0.3

GeoNMF
SVI

0.6

0.6

0.4

Varying α0

0.7

GeoNMF
SVI

Θ̂ Relative Error

Θ̂ Relative Error

0.6

Noisy off-diag in B

0.9
0.8

Θ̂ Relative Error

Skewed B

0.7

10−1

5000

10000

15000

20000

25000

30000

Number of nodes n

35000

(f) B = diag(0.5 · 1K + 0.5 · rK ),
rK = rand(K, 1), ρ = 1

Figure 1. (a)-(e) Simulation results for varying parameters. (f) Running time.

of conferences), and from the Microsoft Academic
Graph (each community is denoted by a “field of
study” (FOS) tag). Each author’s θ vector is constructed by normalizing the number of papers he/she
has published in conferences in a subfield (or papers
that have the FOS tag).
We preprocessed the networks by recursively removing
isolated nodes, communities without any pure nodes, and
nodes with no community assignments. For the ego networks we pick networks with at least 200 nodes and the
average number of nodes per community (n/K) is at least
100, giving us 3 Facebook and and 40 G-plus networks. For
the co-authorship networks, all communities have enough
pure nodes, and after removing isolated nodes, the networks have more than 200 nodes and n/K is larger than
100. The statistics of the networks (number of nodes, average degree, number of clusters, degree of overlap etc.)
are shown in Table 1. The overlap ratio is the number of
overlapping nodes divided by the number of nodes. The
different networks have the following subfields:
• DBLP1: Machine Learning, Theoretical Computer
Science, Data Mining, Computer Vision, Artificial Intelligence, Natural Language Processing
• DBLP2: Networking and Communications, Systems,

Information Theory
• DBLP3: Databases, Data Mining, World Web Wide
• DBLP4: Programming Languages, Software Engineering, Formal Methods
• DBLP5: Computer Architecture, Computer Hardware, Real-time and Embedded Systems, Computeraided Design
• MAG1: Computational Biology and Bioinformatics,
Organic Chemistry, Genetics
• MAG2: Machine Learning, Artificial Intelligence,
Mathematical Optimization
Evaluation Metric: For real data experiments, we construct Θ as follows. For the ego-networks every node has
a binary vector which indicates which circle (community)
each node belongs to. We normalize this to construct Θ.
For the DBLP and Microsoft Academic networks we construct a row of Θ by normalizing the number of papers an
author has in different conferences (ground truth communities). We present the averaged Spearman rank correlation
coefficients (RC) between Θ(:, a), a ∈ [K] and Θ̂(:, σ(a)),

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Dataset
# nodes n
# communities K
Average Degree
Overlap %

GeoNMF

0.5

0
Facebook

SVI

SAAC

0.3

0.15

0.2

0.1

0.1
DBLP1

DBLP2

DBLP3

DBLP4

MAG1
142,788
3
12.4
3.3

MAG2
108,064
3
16.0
3.8

0.05

DBLP5

MAG1

(b)
Running time /s

101
100
10−1
G-plus

104
2

10

100
DBLP1

DBLP2

(d)

MAG2

(c)
Running time /s

(a)
Running time /s

OCCAM

DBLP5
42,351
4
6.8
18.5

0

G-plus

102

Facebook

BSNMF

DBLP4
25,481
3
5.2
14.4

RCavg

RCavg

1

RCavg

Table 1. Network statistics
G-plus
DBLP1 DBLP2 DBLP3
656.2 (± 422.0) 30,566
16,817
13,315
2.8 (±1.74)
6
3
3
103.4 (±74.9)
8.9
7.6
8.5
26.5 (±32.4)
18.2
14.9
21.1

Facebook
362.0 (± 148.5)
2.3 (±0.58)
56.8 (±32.3)
19.3(±29.8)

DBLP3

DBLP4

DBLP5

(e)

102
101
MAG1

MAG2

(f)

Figure 2. RCavg and running time (log scale) for real datasets.

where σ is a permutation of [K]. The formal definition is:
K

RCavg (Θ̂, Θ) =

X
1
max
RC(Θ̂(:, i), Θ(:, σ(i))).
K σ i=1

It is easy to see that RCavg (Θ̂, Θ) takes value from -1 to
1, and higher is better. Since SAAC returns binary assignment, we compute its RCavg against the binary ground truth.
Performance: We report the RCavg score in Figure 2(a)
averaged over different Faceboook and G-plus networks;
in Figure 2(b) for five DBLP networks, and in Figure 2(c)
for two MAG networks. We show the time in seconds (logscale) in Figure 2(d) averaged over Facebook and G-plus
networks; in Figure 2(e) for DBLP networks and in Figure 2(f) for MAG networks. We averaged over the Facebook and G-plus networks because all the performances
were similar.
• For small networks like Facebook and G-plus, all algorithms perform equally well both in speed and accuracy, although GeoNMF is fast even for relatively
larger G-plus networks.
• DBLP is sparser, and as a result the overall rank correlation decreases. However, GeoNMF consistently
performs well . While for some networks, BSNMF
and OCCAM have comparable RCavg , they are much
slower than GeoNMF.

• MAG is larger (hundreds of thousands of nodes) than
DBLP. For these networks we could not even run
BSNMF because of memory issues. Again, GeoNMF
performs consistently well while outperforming others in speed.
Estimating K: While we assume that K is known apriori,
K can be estimated using the USVT estimator (Chatterjee
et al., 2015). For the simulated graphs, when average degree is above ten, USVT estimates K correctly. However
for the real graphs, which are often sparse, it typically overestimates the true number of clusters.

6. Conclusions
This paper explored the applicability of symmetric NMF
algorithms for inference of MMSB parameters. We showed
broad conditions that ensure identifiability of MMSB, and
then proved sufficiency conditions for the MMSB parameters to be uniquely determined by a general symmetric
NMF algorithm. Since general-purpose symmetric NMF
algorithms do not have optimality guarantees, we propose
a new algorithm, called GeoNMF, that adapts symmetric
NMF specifically to MMSB. GeoNMF is not only provably
consistent, but also shows good accuracy in simulated and
real-world experiments, while also being among the fastest
approaches.

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

References
Airoldi, Edoardo M, Blei, David M, Fienberg, Stephen E,
and Xing, Eric P. Mixed membership stochastic blockmodels. Journal of Machine Learning Research, 9:
1981–2014, 2008.

Kaufmann, Emilie, Bonald, Thomas, and Lelarge, Marc. A
spectral algorithm with additive clustering for the recovery of overlapping communities in networks. In International Conference on Algorithmic Learning Theory, pp.
355–370. Springer, 2016.

Anandkumar, Animashree, Ge, Rong, Hsu, Daniel J, and
Kakade, Sham M. A tensor approach to learning mixed
membership community models. Journal of Machine
Learning Research, 15(1):2239–2312, 2014.

Kuang, Da, Yun, Sangwoon, and Park, Haesun. Symnmf:
nonnegative low-rank approximation of a similarity matrix for graph clustering. Journal of Global Optimization, 62(3):545–574, 2015.

Arora, Sanjeev, Ge, Rong, and Moitra, Ankur. Learning
topic models–going beyond svd. In Foundations of Computer Science (FOCS), 2012 IEEE 53rd Annual Symposium on, pp. 1–10. IEEE, 2012.

Ley, Michael. The dblp computer science bibliography:
Evolution, research issues, perspectives. In International symposium on string processing and information
retrieval, pp. 1–10. Springer, 2002.

Arora, Sanjeev, Ge, Rong, Halpern, Yonatan, Mimno,
David M, Moitra, Ankur, Sontag, David, Wu, Yichen,
and Zhu, Michael. A practical algorithm for topic modeling with provable guarantees. In ICML, pp. 280–288,
2013.

Lu, Zongqing, Sun, Xiao, Wen, Yonggang, Cao, Guohong,
and La Porta, Thomas. Algorithms and applications for
community detection in weighted networks. Parallel
and Distributed Systems, IEEE Transactions on, 26(11):
2916–2926, 2015.

Chang, Jonathan.
LDA: Collapsed gibbs sampling methods for topic models, 2012.
URL
http://cran.r-project.org/web/
packages/lda/index.html.

Mcauley, Julian and Leskovec, Jure. Discovering social circles in ego networks. ACM Transactions on Knowledge
Discovery from Data (TKDD), 8(1):4, 2014.

Chatterjee, Sourav et al. Matrix estimation by universal
singular value thresholding. The Annals of Statistics, 43
(1):177–214, 2015.

McSherry, Frank. Spectral partitioning of random graphs.
In Foundations of Computer Science, 2001. Proceedings.
42nd IEEE Symposium on, pp. 529–537. IEEE, 2001.

Chaudhuri, Kamalika, Graham, Fan Chung, and Tsiatas,
Alexander. Spectral clustering of graphs with general degrees in the extended planted partition model. In COLT,
volume 23, pp. 35–1, 2012.

Munkres, James. Algorithms for the assignment and transportation problems. Journal of the society for industrial
and applied mathematics, 5(1):32–38, 1957.

Chen, Jingchun and Yuan, Bo. Detecting functional modules in the yeast protein–protein interaction network.
Bioinformatics, 22(18):2283–2290, 2006.

Press, William H., Teukolsky, Saul A., Vetterling,
William T., and Flannery, Brian P. Numerical Recipes
in C. Cambridge University Press, 2nd edition, 1992.

Davis, Chandler and Kahan, William Morton. The rotation
of eigenvectors by a perturbation. iii. SIAM Journal on
Numerical Analysis, 7(1):1–46, 1970.

Psorakis, Ioannis, Roberts, Stephen, Ebden, Mark, and
Sheldon, Ben. Overlapping community detection using
bayesian non-negative matrix factorization. Phys. Rev.
E, 83:066114, Jun 2011.

Gopalan, Prem K and Blei, David M. Efficient discovery
of overlapping communities in massive networks. Proceedings of the National Academy of Sciences, 110(36):
14534–14539, 2013.
Huang, Kejun, Sidiropoulos, Nicholas, and Swami, Ananthram. Non-negative matrix factorization revisited:
Uniqueness and algorithm for symmetric decomposition.
Signal Processing, IEEE Transactions on, 62(1):211–
224, 2014.
Huang, Kejun, Fu, Xiao, and Sidiropoulos, Nikolaos D.
Anchor-free correlated topic modeling: Identifiability
and algorithm. In Advances in Neural Information Processing Systems, pp. 1786–1794, 2016.

Ray, A., Ghaderi, J., Sanghavi, S., and Shakkottai, S. Overlap graph clustering via successive removal. In 2014
52nd Annual Allerton Conference on Communication,
Control, and Computing, Allerton 2014, pp. 278–285,
United States, 1 2015. Institute of Electrical and Electronics Engineers Inc. doi: 10.1109/ALLERTON.2014.
7028467.
Sinha, Arnab, Shen, Zhihong, Song, Yang, Ma, Hao, Eide,
Darrin, Hsu, Bo-june Paul, and Wang, Kuansan. An
overview of microsoft academic service (mas) and applications. In Proceedings of the 24th international conference on world wide web, pp. 243–246. ACM, 2015.

On Mixed Memberships and Symmetric Nonnegative Matrix Factorizations

Soundarajan, Sucheta and Hopcroft, John. Using community information to improve the precision of link prediction methods. In Proceedings of the 21st international
conference companion on World Wide Web, pp. 607–608.
ACM, 2012.
Tang, Minh, Sussman, Daniel L, Priebe, Carey E, et al.
Universally consistent vertex classification for latent positions graphs. The Annals of Statistics, 41(3):1406–
1430, 2013.
Wang, Fei, Li, Tao, Wang, Xin, Zhu, Shenghuo, and Ding,
Chris. Community discovery using nonnegative matrix
factorization. Data Mining and Knowledge Discovery,
22(3):493–521, 2011.
Wang, Xiao, Cao, Xiaochun, Jin, Di, Cao, Yixin, and He,
Dongxiao. The (un) supervised nmf methods for discovering overlapping communities as well as hubs and
outliers in networks. Physica A: Statistical Mechanics
and its Applications, 446:22–34, 2016.
Yu, Yi, Wang, Tengyao, Samworth, Richard J, et al. A useful variant of the davis–kahan theorem for statisticians.
Biometrika, 102(2):315–323, 2015.
Zhang, Yuan, Levina, Elizaveta, and Zhu, Ji. Detecting overlapping communities in networks using spectral
methods. arXiv preprint arXiv:1412.3432, 2014.

