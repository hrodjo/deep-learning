Nonnegative Matrix Factorization for Time Series Recovery
From a Few Temporal Aggregates

Jiali Mei 1 2 Yohann De Castro 1 Yannig Goude 1 2 Georges Hébrail 2

Abstract
Motivated by electricity consumption reconstitution, we propose a new matrix recovery method
using nonnegative matrix factorization (NMF).
The task tackled here is to reconstitute electricity consumption time series at a fine temporal
scale from measures that are temporal aggregates
of individual consumption. Contrary to existing
NMF algorithms, the proposed method uses temporal aggregates as input data, instead of matrix
entries. Furthermore, the proposed method is extended to take into account individual autocorrelation to provide better estimation, using a recent
convex relaxation of quadratically constrained
quadratic programs. Extensive experiments on
synthetic and real-world electricity consumption
datasets illustrate the effectiveness of the proposed method.

1. Introduction
In this paper, we propose a new matrix recovery method
using nonnegative matrix factorization (NMF, Lee & Seung
(1999)) where matrix columns represent time series at a
fine temporal scale. Moreover, only temporal aggregates of
these time series are observed.
The method has its motivation in the context of electricity
load balancing, where time series represent electric power
consumption. To avoid failure in the electricity network,
suppliers are typically required by transmission system operators (TSO) to supply as much electricity as their consumers consume at every moment. This mechanism is
called balancing. In the context of an open electricity
market, all market participants, such as suppliers, utility
traders, and large consumers, have a balance responsibility: any imbalance caused within the perimeter of a par1

EDF Lab Paris-Saclay, 91120 Palaiseau, France 2 LMO, Univ.
Paris-Sud, CNRS, Universite Paris-Saclay, 91405 Orsay, France.
Correspondence to: Jiali Mei <jiali.mei@u-psud.fr>.
Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

ticipant is billed by the TSO. To calculate the imbalance
caused by a market participant, one needs an estimation
of the consumption and production within its perimeter
at a small temporal scale, for example, half-hourly (RTE
(2014), SVK (2016), REE (2016)).
However, for many customers (for instance residential)
within a perimeter, electricity consumption is not recorded
at that scale. Although smart meter readings may be
recorded locally up to every minute, utility companies often
have very limited access to such data, due to data transmission and processing costs and/or privacy issues. Following
a fixed schedule, cumulative consumption of each meter is
recorded by the utility company, for instance every day or
every month. By differentiating consecutive readings, the
utility obtains the consumption of a customer between two
reading dates. Currently, TSOs use proportional rules to
reconstitute consumption from these measurements, based
on national consumption profiles adjusted by temperature.
In this article, we develop an NMF-based matrix recovery
method providing a solution to consumption reconstitution
from such temporal aggregates.
Recent advances in matrix completion have made it clear
that when a large number of individuals and features are
involved, even partial data could be enough to recover
much of lost information, thanks to the low-rank property (Candès & Recht, 2009): although the whole data matrix V∗ ∈ RT ×N is only partially known, if V∗ = WH,
where W ∈ RT ×K , H ∈ RK×N , with K much smaller
than both T and N , one could recover V∗ entirely under
some conditions over the sampling process.
In this article, we adress electricity consumption reconstitution as a matrix recovery problem. Consider the electricity consumption of N consumers during T periods. Since
consumption is always positive, the N time series are organized into a nonnegative matrix V∗ ∈ RT+×N . An entry
∗
of this matrix, vt,n
represents, for example, the electricity
consumption of Consumer n for Period t.
Information about consumption is revealed as meter readings which do not correspond to matrix entries but to cumulative sums of each column of V∗ : at a meter-reading
Pt date
∗
t, we observe that Consumer n has consumed i=1 vi,n

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

since the first period. Several readings are available for
each consumer.

ativity (Recht et al., 2010; Candès & Plan, 2011; Zuk &
Wagner, 2015).

An alternative matrix representation could be to define entries directly as the cumulative consumption since the first
period. Again, this matrix has missing values and a matrix completion algorithm can be applied. However, this
cumulative matrix has increasing columns, which is quite
different from matrices considered in the standard matrix
completion literature, where matrix completion error is typically bounded by the upper bound on matrix.

The NMF literature is generally focused on full observation (Gillis, 2014; Alquier & Guedj, 2016), or on matrix
completion (Gillis & Glineur, 2011; Xu & Yin, 2013) Random projection measurements are used in an NMF context
in (Pnevmatikakis & Paninski, 2013), where a maximum
likelihood estimator is developed based on a specific generative model in neural imaging. The particular form of
measurement operator considered here arises from meter
reading, and can be used in other fields, such as Internet
traffic matrix estimation (Roughan et al., 2012). Because
of our choice of estimator (1) over estimator (2), we derive
a novel algorithm for this measurement operator, which
has a smaller time complexity than previously studied ones
(more details in Section 2.1).

We represent meter readings as linear measures on the consumption matrix V∗ . Temporal aggregates are derived
from meter readings by differentiating consecutive readings: we will consider these temporal aggregates as ”observations” in the rest of the paper. We consider D scalar observations, represented by a data vector a ≡ A(V∗ ) ∈ RD
+,
where A is a D-dimensional linear operator. To recover V∗
from a, we look for a low-rank NMF of V∗ : WH ' V∗ ,
where W ∈ RT+×K , H ∈ RK×N
. The columns of W are
+
K nonnegative factors, which can be interpreted as typical
profiles of the N time series, and the columns of H as the
weights of each individual. The problem is formalized as
the minimization of a quadratic loss function under nonnegativity and data constraints:
min

V, W, H

`(V, W, H) = kV − WHk2F

A(V) = a,
(1)
where X ≥ 0 (or x ≥ 0) means that the matrix X (or the
vector x) is element-wise nonnegative.
s.t.

V ≥ 0,

W ≥ 0,

H ≥ 0,

Note the difference between (1) and another potential estimator,
min

W, H

s.t.

ˆ
`(W,
H) = kA(WH) − ak22
W ≥ 0,

(2)

H ≥ 0,

studied in (Roughan et al., 2012). If V is a solution to (1), it
satisfies exactly the measurement constraint, but is approximately low-rank, while WH, a solution to (2) is exactly
of low rank, but only matches the measurements approximately. Since in our application, the estimated time series
matrix is to be used for billing, the match to metering data
is essential. Therefore, we use (1) in this work.
1.1. Prior works
The measurement operator A is a special instance of the
trace regression model (Rohde & Tsybakov, 2011) which
generalizes the matrix completion setting. In matrix completion, each measurement is exactly one entry. Various
forms of linear measurements other than matrix completion
have been considered for matrix recovery without nonneg-

In real-world applications, global information such as temporal autocorrelation could be available in addition to measurements. Previous approaches combining matrix factorization and autoregressive structure are often focused on
obtaining factors that are more smooth and/or sparse, both
in NMF (Chen & Cichocki, 2005; Févotte & Idier, 2011;
Smaragdis et al., 2014) and without nonnegativity (Udell
et al., 2016; Yu et al., 2015). Our objective is different from
these studies: we try to further improve the matrix recovery by constraining temporal correlation on individual time
series (not factors). We use a recent convex relaxation of
quadratically constrained quadratic programs (Ben-Tal &
den Hertog, 2013) to deduce a closed-form projection step
in this case.
We propose an algorithm to solve (1) in Section 2.1. To
take into account individual autocorrelation, a second algorithm is proposed in Section 2.2. In Section 3, both algorithms are validated on synthetic and real electricity consumption datasets, compared to a linear benchmark and a
state-of-art matrix completion method.

2. Reconstitution of time series with NMF
2.1. Iterative algorithm with simplex projection
We represent temporal aggregation by a linear operator A.
For each 1 ≤ d ≤ D, the d-th measurement on X, A(X)d ,
is the sum of several consecutive rows on one column of
X, that is,
X
A(X)d =
xt,n ,
(t,n)∈Id

where Id = {(t, n)|t0 (d)+1 ≤ t ≤ t0 (d)+h(d), n = nd },
is the index set over h(d) consecutive periods of Consumer nd , starting from Period t0 (d) + 1. Each measurement covers a disjoint index set. All entries of X are not
necessarily involved in the measurements.

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

A block Gauss-Seidel algorithm (Algorithm 1) is used to
solve (1). We alternate by minimizing `(V, W, H) over
W, H or V, keeping the other two matrices fixed. Methods from classical NMF problems are used to update W
and H (Kim et al., 2014). In the implementation, we use
two variants that seem similarly efficient (more details in
Section 3): Hierarchical Alternating Least Squares (HALS,
Cichocki et al. (2007)), and a matrix-base NMF solver with
Nesterov-type acceleration (NeNMF, Guan et al. (2012)).

2014, Section 3.1.7). We calculate

When W and H are fixed, the optimization problem on
V is equivalent to D simplex projection problems, one for
each scalar measurement. For 1 ≤ d ≤ D, we have to
solve

Convergence to a stationary point has been proved for past
NMF solvers with the full observation or the matrix completion setting (Guan et al. (2012); Kim et al. (2014)). Our
algorithms have similar convergence property. Although
the subproblems on W and H do not necessarily have
unique optimum, the projection of V attains a unique minimizer. By Grippo & Sciandrone (2000, Proposition 5), the
convergence to a stationary point is guaranteed.

t0 (d)+h(d)

X

min kvId −
v Id

s.t.

wt hnd k2

t=t0 (d)+1

vId ≥ 0,

(3)

v0Id 1 = ad .

The simplex projection algorithm introduced by Chen &
Ye (2011) solves this subproblem efficiently. Define the
operator, PA , as the orthogonal projection into the simplex
A ≡ {X ∈ RT+×N |A(X) = a}. A is the intersection
of the affine subspace {X ∈ RT ×N |A(X) = a} and the
first orthant. Projector PA encodes the measurement data
a = A(V∗ ). In Algorithm 1, we apply PA to a working
value of V in order to obtain its projection in A.
Contrary to previously studied algorithms (Roughan et al.,
2012), by choosing estimator (1) over (2), the simplex projection step is separated from the classical NMF update
steps in our algorithm. Instead of multiplying the rank and
the complexity introduced by the number of measurements,
we have an algorithm whose complexity is the sum of the
two. In cases where the number of measurements is large,
this difference can be crucial. 1

R(W)i,j = |(WH − V)H0 )i,j |1Wi,j 6=0 ,
and R(H)i,j = |(W0 (WH − V))i,j |1Hi,j 6=0 .
The algorithm is stopped if kR(W)k2F + kR(H)k2F ≤ ,
for a small threshold  > 0.

Algorithm 1 can be generalized to other types of measurement operators A, as long as a projection into the simplex
defined by the data constraint A(X) = a and the positivity
constraint can be efficiently computed.
2.2. From autocorrelation constraint to penalization
In addition to the measurements in a, we have some prior
knowledge on the temporal autocorrelation of the individuals. To take into account information about autocorrelation,
we add a penalization term to the original matrix recovery
problem, replacing (1) by:

min

V,W,H

A classical stopping criterion in the NMF literature is based
on Karush-Kuhn-Tucker (KKT) conditions on (1) (Gillis,
1

This intuition is confirmed by the comparison of Algorithm 1
and our implementation of the algorithm proposed in (Roughan
et al., 2012).

N
X

v0n ∆ρn vn

n=1

A(V) = a,
(4)
where λ ≥ 0 is a single fixed penalization parameter, and
∆ρn is a symmetric matrix precised shortly after. In the
rest of this section, we first show by Theorem 1, that with
an appropriately chosen value of λ, adding the penalization
term v0n ∆ρn vn is equivalent to impose that the temporal
autocorrelation of vn to be at least equal to ρn , a prior
threshold. Then we modify the Algorithm 1 to solve this
penalized problem.
s.t.

Algorithm 1 Block coordinate descent for NMF from temporal aggregates
input PA , 1 ≤ K ≤ min{T, N }
Initialize W0 , H0 ≥ 0, V0 = PA (W0 H0 ), i = 0
while Stopping criterion is not satisfied do
Wi+1 = Update(Wi , Hi , Vi )
Hi+1 = Update(Wi+1 , Hi , Vi )
Vi+1 = PA (Wi+1 Hi+1 )
i=i+1
end while
output Vi ∈ A, Wi ∈ RT+×K , Hi ∈ RK×N
+

kV − WHk2F − λ
V ≥ 0,

W ≥ 0,

H ≥ 0,

For 1 ≤ n ≤ N , suppose that the lag-1 autocorrelation of
Individual n’s time series is at least equal to a threshold ρn
(e.g. from historical data, excluded from observed temporal aggregates), that is,

T
−1
X
t=1

vt+1,n vt,n ≥ ρn

T
X
t=1

2
vt,n
.

(5)

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

Notice that with the lag matrix,


0 1 0 ... 0
0 0 1 ... 0




..
,
.
0
0
0
:
∆=




.
.
 : : . . . . 1
0 0 ... 0 0
PT −1
we have t=1 vt+1,n vt,n = v0n ∆vn . Define ∆ρ ≡ ∆ +
0
∆ − 2ρI, for a threshold −1 ≤ ρ ≤ 1. Inequality (5) is
then equivalent to
v0n ∆ρn vn ≥ 0.

(6)

Imposing (6) would require one to solve, at each iteration,
N quadratically constrained quadratic programs (QCQP)
of the form:
min ||x − x0 ||2
x
(7)
s.t. x0 Sx ≥ 0,
where S is a general symmetric matrix, not necessarily
semi-definite positive. This means that the QCQP is in general a non-convex problem. Let δ be the vector of eigenvalues of ∆. By eigendecomposition, S = U0 DU. where the
matrix U is orthogonal. The entries of δ are the diagonal
entries of D. The following theorem justifies the choice of
penalization term in (4), by showing with an appropriate λ,
adding this penalization term is equivalent to imposing the
autocorrelation constraint (5).
Theorem 1. Suppose that δ1 , the largest eigenvalue of S,
is strictly positive. Suppose that z0 ≡ Ux0 has no zero
component. Then there exists 0 ≤ λ < δ11 , that verifies
2
PT
z0,t
∗
−1
x0 is an
t=1 δt 2(1−λδt )2 = 0, so that x ≡ (I − λS)
optimal solution of (7).

T , then (z∗ , y∗ ) is also an optimal solution of (8), which
makes x∗ = U0 z∗ an optimal solution of (7).
We will look for such a solution to (9) by examining its first-order conditions of optimality.
Problem (9) is convex, and it verifies the Slater condition:
∃(ŷ, ẑ), −δ 0 ŷ < 0, 21 ẑt2 < ŷt , ∀1 ≤ t ≤ T . This is true,
because δ1 > 0. We could choose an arbituary value of
ŷ1 > 0 and strictly positive but small values for other
components of ŷ so as to have −δ 0 ŷ < 0, and ẑ = 0.
Thus, Problem (9) always has an optimal solution, because
the objective function is coercive over the constraint. This
shows the existence of (z∗ , y∗ ).
Now we show that 21 (zt∗ )2 = yt∗ , ∀1 ≤ t ≤ T . The KKT
conditions of (9) are verified by (z∗ , y∗ ). In particular,
there is some dual variable λ ≥ 0, µ ∈ RT+ that verifies,
1 − λδ − µ = 0,

(10)

−δ 0 y∗ ≤ 0,

(11)

0 ∗

λδ y = 0,
µt zt∗

−z0,t +
= 0,
1 ∗ 2
(z ) − yt∗ ≤ 0,
2 t
1
µt ( (zt∗ )2 − yt∗ ) = 0,
2

(12)
∀1 ≤ t ≤ T,

(13)

∀1 ≤ t ≤ T,

(14)

∀1 ≤ t ≤ T.

(15)

Since z0,t 6= 0, we have µt 6= 0, zt∗ = µ1t z0,t , ∀1 ≤ t ≤ T
by (13). Therefore, by (15), yt∗ = 12 (zt∗ )2 , ∀1 ≤ t ≤ T .
By (10), the values of µt = 1 − λδt can be deduced from
that of λ. Since µ > 0, we obtain that λ < δ11 .
z

0,t
, ∀1 ≤ t ≤ T . This shows that x∗ =
By (13), zt∗ = 1−λδ
t
0 ∗
0
U z = U (I − λD)−1 z∗0 = (I − λS)−1 x0 is an optimal
solution for (7).

Proof. We follow Ben-Tal & den Hertog (2013) to obtain
a convex relaxation of (7).

Theorem 1 shows that with a well chosen λ, the constraint
in (7) can be replaced by a penalization.

Define z ≡ Ux, z0 ≡ Ux0 , yt ≡ 12 zt2 , ∀1 ≤ t ≤ T .
Recall that δ1 > 0, and that ∀t, 1 ≤ t ≤ T , z0,t 6= 0.

There are in fact two cases. Either x0 verifies the constraint, in which case λ = 0, and x∗ = x0 is the solution.
Otherwise, λ > 0. We replug the values of

Problem (7) is equivalent to the non-convex problem
min 10 y − z00 z

yt∗ =

y,z

− δ 0 y ≤ 0,

s.t.

1 2
z = yt ,
2 t

(8)
∀1 ≤ t ≤ T.

back into (12), and obtain that λ verifies

Now consider its convex relaxation
min
y,z

s.t.

0

1y−
0

T
X

z00 z

− δ y ≤ 0,

1 2
z − yt ≤ 0,
2 t

2
z0,t
1 ∗ 2
(zt ) =
2
2(1 − λδt )2

(9)

t=1

2
δt z0,t
= 0.
2(1 − λδt )2

∀1 ≤ t ≤ T.

By Ben-Tal & den Hertog (2013, Theorem 3), if (z∗ , y∗ ) is
an optimal solution of (9), and if 12 (zt∗ )2 = yt∗ , ∀1 ≤ t ≤

When W and H are fixed, the subproblem of (4) on V can

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

impose (−1 ≤ ρn ≤ 1), ∆ρn has both strictly positive and
strictly negative eigenvalues, allowing the above theorems
to apply.

be separated into N constrained problems of the form,
min kx − x0 k2 − λx0 ∆ρn x,
x

A n x = cn ,

s.t.

(16)

x ≥ 0,
where x0 is the n-th column of WH, cn is the observations on the n-th column, and An is a matrix which encodes
the measurement operator over that column. The following
theorem shows how to solve this problem.
Theorem 2. Suppose that S is a symmetric matrix with
eigenvalues δ, and λ1 > 0. Suppose A ∈ Rm,l a full-rank
matrix with m ≤ l, x0 ∈ Rl , c ∈ Rm , λ ≥ 0. Define
1
, then
Q ≡ (I − λS)−1 A0 (A(I − λS)−1 A0 )−1 . If λ < δρ,1
−1
Qc + (I − QA)(I − λS) x0 is a minimizer of
min kx − x0 k2 − λx0 Sx,
x

(17)

s.t.

Ax = c,

Proof. Let l be the dimension of c. Define IC as the indicator function for the constraint of (17), that is
IC (x) = 0, if Ax = c,
and IC (x) = +∞, if Ax 6= c.

Both I − λ∆ρn and An (I − λ∆ρn )−1 A0n are invertible
with λ < δρn ,1 . The matrix inversion only needs to be
done once for each individual. After computing Qn ≡ (I−
λ∆ρn )−1 A0n (An (I − λ∆ρn )−1 A0n )−1 , Qn cn and (I −
Qn An )(I − λ∆ρn )−1 for each n, we use Algorithm 2 to
solve (4).
Algorithm 2 Block coordinate descent for NMF from temporal aggregates and autocorrelation penalty
input ρn , An , Qn , Qn cn , ∀1 ≤ n ≤ N, and 1 ≤ K ≤
min{T, N }
Initialize W0 , H0 ≥ 0, V0 = PA (W0 H0 ), i = 0
while Stopping criterion is not satisfied do
Wi+1 = Update(Wi , Hi , Vi )
Hi+1 = Update(Wi+1 , Hi , Vi )
for all 1 ≤ n ≤ N do
=
(Qn cn + (I − Qn An )(I −
vi+1
n
λ∆ρn )−1 Wi+1 hi+1
n )+
end for
i=i+1
end while
K×N
output Vi ∈ A, Wi ∈ RT+×K , Hi ∈ R+

Problem (17) is then equivalent to
min F (x) ≡
x

1
1
kx − x0 k2 − λx0 Sx + IC (x).
2
2

(18)

The subgradient of (18) is ∂F (x) = {x − x0 − λSx −
A0 | ∈ Rl }. When λ < δ11 , (18) is convex. Therefore,
x∗ is a minimizer if and only if 0 ∈ ∂F (x), and Ax∗ = c.
That is, ∃ ∈ Rl ,

Choosing λ An optimal value of λ could be calculated.
Substituting the values of y∗ in (12), shows that the optimal
2
PT
z0,t
λ is a root of the polynomial t=1 δρ,t 2(1−λδ
2 . The
ρ,t )
root-finding is too expensive to perform at every iteration.
However, the optimal λ verifies
0<λ<

(I − λS)x∗ − x0 − A0  = 0,
Ax∗ = c.
The vector  thereby verifies A(I − λS)−1 (x0 + A0 ) = c.
The l-by-l matrix A(I − λS)−1 A0 is invertible, because
l is smaller than m, and A is of full rank (because each
measurement covers disjoint periods). Therefore,
 = (A(I − λS)−1 A0 )−1 (c − A(I − λS)−1 x0 ),
x∗ = (I − λS)−1 (x0 + A0 )
= Qc + (I − QA)(I − λS)−1 x0 .
In our particular problem, the eigenvalues of ∆ρn are
δρn ,t = 2 cos(

t
π) − 2ρn ,
T +1

with t taking every value from 1 to T . This means that for
most of the autocorrelation threshold that we could need to

1
δρ,1

,

1
where δρ,1 = 2 cos( T +1
π) − 2ρ is the biggest eigenvalue of ∆ρ . This gives us a good enough idea about how
large a λ to use. In the numerical experiments, we chose
λ = min(1, 2 maxn1 δρ ,1 ) in the penalization when the conn
straint in (7) is active, and λ = 0 (no penalization) when
the constraint is verified by x0 .

3. Experimental results
We use one synthetic dataset and three real-world electricity consumption datasets to evaluate the proposed algorithms. In each dataset, the individual autocorrelation
is calculated on historical data from the corresponding
datasets, not used for evaluation.
• Synthetic data: 20 independent Gaussian processes
with Matern covariance function (shifted to be nonnegative) are sampled over 150 periods to form the

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

factor matrix W. A 20-by-120 weight matrix H is
generated by sampling from a standard normal distribution truncated at 0, independantly for each entry.
The data matrix is obtained as W×H (T = 150, N =
120). This matrix is exactly of rank 20.
• French electricity consumption (proprietary
dataset):
daily consumption of 636 mediumvoltage feeders gathering each around 1,500 consumers based near Lyon in France during 2012
(T = 365, N = 636).
• Portuguese electricity consumption (Trindade,
2016) daily consumption of 370 Portuguese clients
during 2014 (T = 365, N = 370).
• Electricity consumption of small Irish companies (Commission for Energy Regulation, Dublin,
2011a;b) daily consumption of 426 small Irish companies during 200 days in 2010 (T = 200, N = 426).
For each individual in a dataset, we generate observations
by selecting a number of observation periods. The temporal aggregates are the sum of the time series between
two consecutive observation periods. The observation periods are chosen in two possible ways: periodically (at regular intervals with the first observation period sampled at
random), or uniformly at random. The regular intervals
for periodic observations are p ∈ {2, 3, 5, 7, 10, 15, 30}.
This is motivated by the real application where meter readings are recorded regularly. With random observations,
we use sampling rates that are equivalent to the regular
intervals. That is, the number of observations D verifies
1
D
T N = p ∈ {0.5, 0.33, 0.2, 0.14, 0.1, 0.07, 0.03}.
We apply the following methods to recover the data matrix
from each set of sampled observations:
• interpolation Temporal aggregates are distributed
equally over the covered periods.
• softImpute As an alternative method, we apply a
state-of-art matrix completion algorithm to complete
the cumulative matrix. The observed entries are the
cumulative values of the column from the first period
to the observation dates. We use a nuclear-norm minimization algorithm, implemented in the R package,
softImpute (Mazumder et al. (2010)), to complete the
cumulative consumption matrix, before differentiating
each column to obtain recovered matrix. To choose
the thresholding parameter, we use the warm start procedure documented in softImpute.
• HALS, and NeNMF These are the proposed matrix
recovery algorithms using two classical W and H
update implementations: HALS, and NeNMF. When

autocorrelation penalization is used, we choose λ =
min(1, 2 maxn1 δρ ,1 ), as explained in the previous secn
tion. The rank used in proposed algorithms is chosen
by a 5-fold cross validation procedure: we split the
observations randomly into 5 folds, and apply the algorithm to 4 of the 5 folds with ranks 2 ≤ K ≤ 30.
We then calculate the `2 -distance between the temporal aggregates on the recovered matrix with the 1-fold
holdout. Repeating this procedure onto the 5 folds
separately, we choose the rank which minimizes the
average `2 -distance, to perform the algorithm on all
observations.
With a recovered matrix V obtained in an algorithm
run, we compute the relative root-mean-squared error
(RRMSE):
RRMSE(V, V∗ ) =

kV − V∗ kF
.
kV∗ kF

Each experiment (dataset, sampling scheme, sampling rate,
recovery method, unpenalized or penalized) is run three
times, and the average RRMSE is reported in Figure 1. The
figure is zoomed to show the RRMSE of the proposed algorithms. Much higher error rates for reference methods
are sometimes not shown.
On sample sets with random observation periods (lower
panel), proposed methods (HALS and NeNMF, blue and
purple lines), whether unpenalized (solid lines) or penalized (dashed lines), out-performs the interpolation benchmark (red solid lines) by large in all datasets. This is especially the case when the sampling rate is small, i.e. when
the task is more difficult. On the Irish dataset (lower panel,
furthest to the right), penalized HALS and NeNMF (dashed
blue and purple lines) are an improvement to unpenalized
HALS and NeNMF when the sampling rate is low.
With periodic observations (upper panel), the RRMSE is
higher for every method. Proposed unpenalized methods,
HALS and NeNMF (blue and purple solid lines) are equivalent to interpolation benchmark (red solid lines) for synthetic data, but sometimes worse for real datasets. Real
electricity consumption has significant weekly periodicity,
which is poorly captured by observations at similar periods. However, this shortcoming of the unpenalized method
is more than compensated for by the penalization (dashed
blue and purple lines).
We notice that penalized HALS and NeNMF consistently
outperform interpolation with both observation schemes.
This makes penalized methods particularly useful for the
application of electricity consumption reconstituion, where
it may be costly to install a random observation scheme,
or to change the current periodic observation scheme to a
random one.

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates
Synthetic

French

Portuguese

Irish

1.00
0.75
periodic

0.50

algorithm
interpolation

0.25

RRMSE

softImpute
HALS

0.00

NeNMF

1.00

penalized
0.75

unpenalized
random

0.50

penalized

0.25
0.00
0.1 0.2 0.3 0.4 0.5

0.1 0.2 0.3 0.4 0.5

0.1 0.2 0.3 0.4 0.5

Sampling rate (D TN)

0.1 0.2 0.3 0.4 0.5

Figure 1. Mean RRMSE of the recovered matrices over three separate runs over the four datasets. On the samples with random observation periods, proposed methods (HALS and NeNMF, blue and purple lines, both penalized and unpenalized) out-performs the
interpolation benchmark (solid red line). On the samples with regular observation periods, unpenalized HALS and NeNMF (solid blue
and purple lines) are similar to the interpolation benchmark, whiled penalized HALS and NeNMF (dashed blue and purple lines) are an
important improvement. The softImpute method (solid green line) only has comparable performance in two of the datasets, in the easiest
task (50% sampling rate at random periods). In most cases, RRMSE of softImpute is larger than 100%.

It is also interesting to note that the rank chosen by the
cross validation procedure is higher in higher sampling rate
scenarios (Figure 2). This shows that the cross validation
procedure is able to relax the rank constraint when more
information is available in the data.
The traditional matrix completion method seems to fail in
this application: softImpute (green solid lines) only has
comparable results to interpolation or proposed methods in
two of the four datasets, with 50% sampling rate in the random sampling scheme, which is the easiest case. In most
cases, softImpute has an RRMSE much larger than 100%,
and thus is not shown in the graphic. This indicates that
the cumulative matrix considered in this application does
not verify assumptions which guarantee matrix completion
success.

4. Perspectives
Motivated by a new industrial application, we extended
NMF to use temporal aggregates as input data, by adding
a projection step into NMF algorithms. With appropriate
projection algorithms, this approach could be further generalized to other types of data, such as disaggregating spatially aggregated data, or general linear measures. When
such information is available, we introduce a penalization
on individual autocorrelation, which improves the recovery
performance of the base algorithm. This component can be
generalized to larger lags (with a matrix ∆ with 1’s further off the diagonal), or multiple lags (by adding several
lag matrices together). It is also possible to generalize this
approach to other types of expert knowledge through additional constraints on V.

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates
Synthetic

French

Portuguese

Irish

25

periodic

15
10
5

algorithm
HALS

20

NeNMF

15
random

Rank chosen by cross validation

20

10

5

0.1 0.2 0.3 0.4 0.5

0.1 0.2 0.3 0.4 0.5

0.1 0.2 0.3 0.4 0.5

Sampling rate (D TN)

0.1 0.2 0.3 0.4 0.5

Figure 2. The rank chosen by the cross validation procedure generally increases with the sampling rate, for the four datasets. This shows
that procedure is able to relax the rank constraint when more information is available in the data.

Acknowledgements
We thank Jean-Marc Azaı̈s for his input and the anonymous
reviewers for pointing out applications with similar problem settings.

References
Alquier, Pierre and Guedj, Benjamin. An Oracle Inequality
for Quasi-Bayesian Non-Negative Matrix Factorization.
axXiv preprint arXiv:1601.01345, 2016.
Ben-Tal, Aharon and den Hertog, Dick. Hidden conic
quadratic representation of some nonconvex quadratic
optimization problems. Mathematical Programming,
143(1-2):1–29, 2013. doi: 10.1007/s10107-013-0710-8.
Candès, Emmanuel J. and Plan, Yaniv. Tight Oracle Inequalities for Low-Rank Matrix Recovery From a Minimal Number of Noisy Random Measurements. IEEE
Transactions on Information Theory, 57(4):2342–2359,
2011. doi: 10.1109/TIT.2011.2111771.
Candès, Emmanuel J. and Recht, Benjamin. Exact Matrix
Completion via Convex Optimization. Foundations of

Computational Mathematics, 9(6):717–772, 2009. doi:
10.1007/s10208-009-9045-5.
Chen, Yunmei and Ye, Xiaojing. Projection Onto A Simplex. arXiv preprint arXiv:1101.6081, 2011.
Chen, Zhe and Cichocki, Andrzej. Nonnegative matrix factorization with temporal smoothness and/or spatial decorrelation constraints. Laboratory for Advanced
Brain Signal Processing, RIKEN, Tech. Rep, 68, 2005.
Cichocki, Andrzej, Zdunek, Rafal, and Amari, Shun-ichi.
Hierarchical ALS algorithms for nonnegative matrix and
3D tensor factorization. In Independent Component
Analysis and Signal Separation, pp. 169–176. Springer,
2007.
Commission for Energy Regulation, Dublin. Electricity
smart metering customer behaviour trials findings report.
2011a.
Commission for Energy Regulation, Dublin. Results of
electricity coast-benefit analysis, customer behaviour trials and technology trials commission for energy regulation. 2011b.

Nonnegative Matrix Factorization for Time Series Recovery From a Few Temporal Aggregates

Févotte, Cédric and Idier, Jérôme. Algorithms for nonnegative matrix factorization with the beta-divergence. Neural Computation, 23(9):2421–2456, 2011.
Gillis, Nicolas. The why and how of nonnegative matrix factorization. Regularization, Optimization, Kernels,
and Support Vector Machines, 12:257, 2014.
Gillis, Nicolas and Glineur, François. Low-rank matrix approximation with weights or missing data is NP-hard.
SIAM Journal on Matrix Analysis and Applications, 32
(4):1149–1165, 2011.

Roughan, M., Zhang, Y., Willinger, W., and Qiu, L. SpatioTemporal Compressive Sensing and Internet Traffic Matrices (Extended Version). IEEE/ACM Transactions on
Networking, 20(3):662–676, June 2012. doi: 10.1109/
TNET.2011.2169424.
RTE. Balance Responsible Entity System. http:
//clients.rte-france.com/lang/an/
clients_producteurs/services_clients/
dispositif_re.jsp, May 2014.

Grippo, Luigi and Sciandrone, Marco. On the convergence of the block nonlinear Gauss–Seidel method under convex constraints. Operations Research Letters, 26
(3):127–136, 2000.

Smaragdis, Paris, Févotte, Cédric, Mysore, Gautham J.,
Mohammadiha, Nasser, and Hoffman, Matthew. Static
and Dynamic Source Separation Using Nonnegative
Factorizations: A unified view. IEEE Signal Processing Magazine, 31(3):66–75, 2014. doi: 10.1109/MSP.
2013.2297715.

Guan, Naiyang, Tao, Dacheng, Luo, Zhigang, and Yuan,
Bo. NeNMF: An Optimal Gradient Method for Nonnegative Matrix Factorization. IEEE Transactions on Signal
Processing, 60(6):2882–2898, 2012. doi: 10.1109/TSP.
2012.2190406.

SVK. Balance responsibility. http://www.svk.
se/en/stakeholder-portal/Electricitymarket/Balance-responsibility/, October
2016.

Kim, Jingu, He, Yunlong, and Park, Haesun. Algorithms
for nonnegative matrix and tensor factorizations: A unified view based on block coordinate descent framework.
Journal of Global Optimization, 58(2):285–319, 2014.

Trindade, Artur. UCI Maching Learning Repository ElectricityLoadDiagrams20112014 Data Set. http:
//archive.ics.uci.edu/ml/datasets/
ElectricityLoadDiagrams20112014, 2016.

Lee, Daniel D. and Seung, H. Sebastian. Learning the parts
of objects by non-negative matrix factorization. Nature,
401(6755):788–791, 1999.

Udell, Madeleine, Horn, Corinne, Zadeh, Reza, and Boyd,
Stephen. Generalized Low Rank Models. Foundations
and Trends in Machine Learning, 9(1), 2016. doi: 10.
1561/2200000055.

Mazumder, Rahul, Hastie, Trevor, and Tibshirani, Robert.
Spectral regularization algorithms for learning large incomplete matrices. Journal of machine learning research, 11(Aug):2287–2322, 2010.
Pnevmatikakis, Eftychios A and Paninski, Liam. Sparse
nonnegative deconvolution for compressive calcium
imaging: Algorithms and phase transitions. In Burges,
C. J. C., Bottou, L., Welling, M., Ghahramani, Z., and
Weinberger, K. Q. (eds.), Advances in Neural Information Processing Systems 26, pp. 1250–1258. Curran Associates, Inc., 2013.
Recht, Benjamin, Fazel, Maryam, and Parrilo, Pablo A.
Guaranteed minimum-rank solutions of linear matrix
equations via nuclear norm minimization. SIAM review,
52(3):471–501, 2010.
REE. Balance responsible party. https://www.
esios.ree.es/en/glossary\#letterB,
2016.
Rohde, Angelika and Tsybakov, Alexandre B. Estimation of high-dimensional low-rank matrices. The Annals
of Statistics, 39(2):887–930, 2011. doi: 10.1214/10AOS860.

Xu, Yangyang and Yin, Wotao. A Block Coordinate Descent Method for Regularized Multiconvex Optimization
with Applications to Nonnegative Tensor Factorization
and Completion. SIAM Journal on Imaging Sciences, 6
(3):1758–1789, 2013. doi: 10.1137/120887795.
Yu, Hsiang-Fu, Rao, Nikhil, and Dhillon, Inderjit S. Highdimensional Time Series Prediction with Missing Values. arXiv preprint arXiv:1509.08333, 2015.
Zuk, Or and Wagner, Avishai. Low-Rank Matrix Recovery
from Row-and-Column Affine Measurements. In Proceedings of The 32nd International Conference on Machine Learning, pp. 2012–2020, 2015.

