Identifying Best Interventions through Online Importance Sampling
Rajat Sen * 1 Karthikeyan Shanmugam * 2 Alexandros G. Dimakis 1 Sanjay Shakkottai 1

Abstract
Motivated by applications in computational advertising and systems biology, we consider the
problem of identifying the best out of several
possible soft interventions at a source node V
in an acyclic causal directed graph, to maximize
the expected value of a target node Y (located
downstream of V ). Our setting imposes a fixed
total budget for sampling under various interventions, along with cost constraints on different
types of interventions. We pose this as a best arm
identification bandit problem with K arms where
each arm is a soft intervention at V, and leverage
the information leakage among the arms to provide the first gap dependent error and simple regret bounds for this problem. Our results are a
significant improvement over the traditional best
arm identification results. We empirically show
that our algorithms outperform the state of the
art in the Flow Cytometry data-set, and also apply our algorithm for model interpretation of the
Inception-v3 deep net that classifies images.

1. Introduction
Causal graphs (Pearl, 2009b) are useful for representing
causal relationships among interacting variables in large
systems (Bottou et al., 2013). Over the last few decades,
causal models have found use in computational advertising (Bottou et al., 2013), biological systems (Meinshausen et al., 2016), sociology (Blalock, 1985), agriculture (Splawa-Neyman et al., 1990) and epidemiology (Joffe
et al., 2012). There are two important questions commonly
studied with causal graphs: (i) How to learn a directed
causal graph that encodes the pattern of interaction among
components in a system (casual structure learning)? (Pearl,
2009b) , and (ii) Using previously acquired (partial) knowledge about the causal graph structure, how to estimate
*

Equal contribution 1 The University of Texas at Austin 2 IBM
Thomas J. Watson Research Center. Correspondence to: Rajat
Sen <rajat.sen@utexas.edu>.
Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

Hidden Variables
Ad inventory

User-Use
Intention

CTR Prediction
Algorithm

UserQu
Query
Ads chosen

Bids Chosen

Predicted Click
Through rate
Pricing
Ad Placement
Design
C Clicks
Actual User

C
Revenue

Figure 1. Computational advertising example borrowed from
(Bottou et al., 2013). Various observable and hidden variables
are shown. The topology of the causal graph is known; however
the strengths of most interactions are unknown. A click-rate scoring algorithm predicts future user click through rates from users’
search queries and the set of ads relevant to the user query chosen from an ad inventory. The algorithm’s output determines the
ads displayed (as well as the display style), and through a complex causal graph, finally determines actual revenue. The part of
the network in bold – distribution of user queries and matching
ad keywords is known (including strengths), and the input output
characteristics of several candidate (randomized) click-rate scoring algorithms are known. The objective is to choose the best
algorithm that maximizes the revenue (target in bold red).

and/or to optimize the effect of a new intervention on other
variables (optimization) (Bottou et al., 2013; Joffe et al.,
2012; Kemmeren et al., 2014; Bonneau et al., 2007; Krouk
et al., 2013)? Here, an intervention is a forcible change to
the value of a variable in a system. The change either alters
the relationship between the parental causes and the variable, or decouples it from the parental causes entirely. Our
focus is on optimizing over a given set of interventions.
An illustrative example includes online advertising (Bottou
et al., 2013), where there is a collection of click-through
rate scoring algorithms that provide an estimate of the probability that an user clicks on an ad displayed at a specific
position. The interventions occur through the choice of
click-through rate scoring algorithm; the algorithm choice
directly impacts ad placement and pricing, and through a
complex network of interactions, affects the revenue generated through advertisements. The revenue is used to determine the best scoring algorithm (optimize for the best
intervention); see Figure 1. Another example is in biological gene-regulatory networks (Bonneau et al., 2007), where
a large number of genomes interact amongst each other and

Identifying Best Interventions through Online Importance Sampling

also interact with environmental factors. The objective here
is to understand the best perturbation of some genomes in
terms of its effect on the expression of another subset of
genomes (target) in cellular systems.
This paper focuses on the following setting: We are given
apriori knowledge about the structure and strength of interactions over a small part of the causal graph. In addition,
there is freedom to intervene (from a set of allowable interventions) at a certain node in the known part of the graph,
and collect data under the chosen intervention; further we
can alter the interventions over time and observe the corresponding effects. Given a set of potential interventions
to optimize over, the key question of interest is: How to
choose the best sequence of T allowable interventions in
order to discover which intervention maximizes the expectation of a downstream target node?
Determining the best intervention in the above setting can
be cast as a best arm identification bandit problem, as noted
in (Lattimore et al., 2016). The possible interventions to
optimize over are the arms of the bandit, while the sample
value of the target node under an intervention is the reward.
More formally, suppose that V is a node in a causal
graph G(V, E) (as shown in Fig. 2), with the parents
of V denoted by pa(V ). In Fig. 1, V corresponds to
the click-through rate and its parents are user-query and
ads-chosen. This essentially means that V is causally
determined by a function of pa(V ) and some exogenous random noise. This dependence is characterized
by the conditional P(V |pa(V ))1 . Then a (soft) intervention mathematically corresponds to changing this conditional probability distribution i.e. probabilistically forcing V to certain states given its parents. In the computational advertising example, the interventions correspond
to changing the click through rate scoring algorithm (i.e
P(click through rate|ads chosen, user query), whose
input-output characteristics are well-studied. Further, suppose that the effect of an intervention is observed at a
node Y which is downstream of V in the topological order (w.r.t G) -refer to Fig. 2. Then, our key question
is stated as follows: Given a collection of interventions
{P0 (V |pa(V )), . . . PK 1 (V |pa(V ))}, find the best intervention among these K possibilites that maximizes E[Y ]
under a fixed budget of T (intervention, observation) pairs.
1.1. Main Contributions
(Successive Rejects Algorithm) We provide an efficient
successive rejects multi-phase algorithm. The algorithm
uses clipped importance sampling. The clipper level is set
adaptively in each phase in order to trade-off bias and vari1

Formally if node V has parents V1 , V2 , then this distribution
is the conditional P(V = v|V1 = v1 , V2 = v2 ) for all v, v1 , v2 .

P A(V )

P0 , P1 , ..., PK

1

V

Layers

Y

Figure 2. Illustration of our setting. The soft interventions modify
P(V |pa(V ). The various conditionals and the marginal of pa(V )
is assumed to be known from prior data. The target variable Y lies
further downstream in the unknown portions of the causal graph.

ance. Our procedure yields a major improvement over the
algorithm in (Lattimore et al., 2016) (both in theoretical
guarantees and in practice), which sets the clippers and allocates samples in a static manner.
(Gap Dependent Error Guarantees under Budget Constraints) In the classic best arm identification problem (Audibert & Bubeck, 2010), Audibert et al. derive gap dependent bounds on the probability of error given a fixed sample
budget. Specifically, let (i) be the i-th largest gap (difference) in the expected reward from that of the best arm (e.g.
(1) is the difference between the best arm expected reward and the second best reward). Then, it has been shown
in (Audibert & Bubeck, 2010) that the number of samples
needed scales as (upto poly log factors) maxi (i/ 2(i) ).
In our setting, a fundamental difference from the classical
best arm setting (Audibert & Bubeck, 2010) is the information leakage across the arms, i.e, samples from one arm can
inform us about the expected value of other arms because
of the shared causal graph. We show that this information
leakage yields significant improvement both in theory and
practice. We derive the first gap dependent (gaps between
the expected reward at the target under different interventions) bounds on the probability of error in terms of the
number of samples T , cost budget B on the relative fraction of times various arms are sampled and the divergences
between soft intervention distributions of the arms.
In our result (upto poly log factors) the factor i is replaced
by the ’effective variance’ of the estimator for arm (i), i.e.
we obtain (with informal notation) maxi i2 / 2(i) . i can
p
be much smaller than i (the corresponding term in the results of (Audibert & Bubeck, 2010)). Our theoretical guarantees quantify the improvement obtained by leveraging information leakage, which has been empirically observed
in (Bottou et al., 2013). We discuss in more detail in Sections 3.3, about how these guarantees can be exponentially
better than the classical ones. We also derive gap dependent
simple regret bounds (Section 3.1).

Identifying Best Interventions through Online Importance Sampling

(Novel f -divergence measure for analyzing Importance
Sampling ) We provide a novel analysis of clipped importance sampling estimators, where pairwise f -divergences
between the distributions {Pk (V |pa(V ))}, for a carefully
chosen function f (.) (see Section E.1) act as the ‘effective
variance’ term in the analysis for the estimators (similar to
Bernstein’s bound (Bennett, 1962)).
(Extensive Empirical Validation) We demonstrate that
our algorithm outperforms the prior works (Lattimore et al.,
2016; Audibert & Bubeck, 2010) on the Flow Cytometry
data-set (Sachs et al., 2005) (in Section 4.1). We exhibit
an innovative application of our algorithm for model interpretation of the Inception Deep Network (Szegedy et al.,
2015) for image classification (refer to Section 4.2).
Remark 1. The techniques in this paper can be directly
applied to more general settings like (i) the intervention
source (V ) can be a collection of nodes (V) and the changes
affect the distribution P (V|pa(V)), where pa(V) is the
union of all the parents; (ii) the importance sampling can
be applied at a directed cut separating the sources and
the targets, provided the effect of the interventions, on the
nodes forming the cut can be estimated. Moreover, our
techniques can be applied without the complete knowledge
of the source distributions. We explain the variations in
more detail in Section B in the appendix.
1.2. Related Work
The problem lies at the intersection of causal inference and
best arm identification in bandits. There have been many
studies on the classical best arm identification in the bandit
literature, both in the fixed confidence regime (Kaufmann
et al., 2015; Gabillon et al., 2012) and in the fixed budget setting (Audibert & Bubeck, 2010; Chen & Li, 2015;
Jamieson et al., 2014; Carpentier & Locatelli, 2016). It
was shown recently in (Carpentier & Locatelli, 2016) that
the results of (Audibert & Bubeck, 2010) are optimal. The
key difference from our work is that, in these models, there
is no information leakage among the arms.
There has been a lot of work (Mooij et al., 2016; Hyttinen
et al., 2013; Eberhardt, 2008; Hauser & Bühlmann, 2012;
Spirtes et al., 2001; Pearl, 2009a; Loh & Bühlmann, 2014;
Shanmugam et al., 2015) on learning casual models from
data and/or experiments and using it to estimate causal
strength questions of the counterfactual nature. One notable work that partially inspired our work is (Bottou et al.,
2013) where the causal graph underlying a computational
advertising system (like in Bing, Google etc.) is known
and the primary interest is to find out how a change in the
system would affect some other variable.
At the intersection of causality and bandits, (Lattimore
et al., 2016) is perhaps most relevant to our setting. It studies the problem of identifying the best hard interventions

on multiple variables (among many), provided the distribution of the parents of the target is known under
p those
interventions. Simple regret bound of order O(1/ T ) was
derived. We assume soft interventions that affect the mechanism between a ’source’ node and its parents, far away
from the target (similar to the case of computational advertising considered in (Bottou et al., 2013)). Further, we
derive the first gap dependent bounds (that can be exponentially small in T ), generalizing the results of (Audibert &
Bubeck, 2010). Our formulation can handle general budget
constraints on the bandit arms and also recover the problem
independent bounds of (Lattimore et al., 2016) (orderwise).
Budget constraints in bandit settings have been explored
before in (Abernethy et al., 2015; Slivkins, 2013).
In the context of machine learning, importance sampling
has been mostly used to recondition input data to adhere
to conditions imposed by learning algorithms (Sugiyama
et al., 2007; Li et al., 2011; Zhang & Zhao, 2014).

2. Problem Setting
In this work, we consider the problem of identifying the
best soft intervention, i.e. the one that maximizes the expected value of a certain target variable. The problem setting is best illustrated in Figure 2. Consider a causal graph
G(V, E) that specifies directed causal relationships between
the variables V. We provide a short introduction to causal
graphs in Section A (in the appendix) for the sake of completeness. Let Y be a target random variable which is
downstream in the graph G; the expected value of this target
variable is the quantity of interest. Consider another random variable V along with its parents pa(V ). We assume
that there are K possible soft interventions. Each soft intervention is a distinct conditional distribution that dictates
the relationship pa(V ) ! V . During a soft intervention
k 2 [K] ([K] = {0, 1, ..., K 1}), the conditional distribution of V given its parents is set to Pk (V |pa(V )) and all
other relationships in the causal graph are unchanged.
It is assumed that the conditional distributions
Pk (V |pa(V )) and marginals for pa(V ) for k 2 [K]
are known from past experiments or existing domain
knowledge. We only observe samples of Y, V and pa(V ),
while the rest of the variables in the causal graph may be
unobserved under different interventions. For simplicity
we assume that the variables V, pa(V ) are discrete while
the target variable Y may be continuous/discrete and has
bounded support in [0, 1]. Further, we assume that the
various conditionals, i.e. Pk (V |pa(V )) are absolutely
continuous with respect to each other. In the case of
discrete distributions, the non-zero supports of these distributions are identical. However, our algorithm can be easily
generalized for continuous distributions on V and pa(V )
(as in our experiments in Section 4.1). In this setting, we

Identifying Best Interventions through Online Importance Sampling

are interested in the following natural question: Which of
the K soft interventions yield the highest expected value
of the target (E[Y ]) and what is the misidentification
error that can be achieved with a finite total budget T for
samples ?
Remark 2. Although we may know apriori the joint distribution of pa(V ) and V under different interventions, how
the change affects another variable Y in the causal graph
is unknown and must be learnt from samples. The task is to
transfer prior knowledge to identify the best intervention.
Bandit Setting: The K different soft interventions can
be thought of as the K arms of a bandit problem. Let
the reward of arm k be denoted by: µk = Ek [Y ], where
Ek [Y ] is the expected value of Y under the soft intervention when the conditional distribution of V given its parents
pa(V ) is set to Pk (V |pa(V )) (soft intervention k) while
keeping all other things in G unchanged. We assume that
there is only one best arm. Let k ⇤ be the arm that yields
the highest expected reward and µ⇤ be the value of the
corresponding expected reward i.e. k ⇤ = arg maxk µk
and µ⇤ = µk⇤ . Let the optimality gap of the k th arm be
defined as k = µ⇤ µk . We shall see that the these
1
gaps { k }K
k=0 and the relationship between distributions
1
{Pk (V |pa(V ))}K
k=0 are important parameters in the problem. Let = mink6=k⇤ k .
Fixed Budget for Samples: In this paper, we work under
the fixed budget setting of best arm identification (Audibert & Bubeck, 2010). Let Tk be the number of times the
th
k
samples. We require that
PKintervention is used to obtain
Tk
k=0 Tk = T . Let ⌫k = T be the fraction of times the
k th intervention is played.
Additional Cost Budget on Interventions: In the context of causal discovery, some interventions require a lot
more resources or experimental effort than the others. We
find such examples in the context of online advertisement
design (Bottou et al., 2013). Therefore, we introduce two
variants of an additional cost constraint that influences the
choice of interventions. (i) Difficult arm budget (S1): Some
arms are deemed to be difficult. Let B ⇢ [K] be the
set of difficult arms. We require that the total fraction of
times
P the difficult arms are played does not exceed B i.e.
k2B ⌫k  B. (ii) Cost Budget (S2): This is the most
general budget setting that captures the variable costs of
sampling each arm (Slivkins, 2013). We assume that there
is a cost ck associated with sampling arm k. It is required
that the average
PKcost1 of sampling does not exceed a cost
budget B .ie. k=0 ck ⌫k  B. c = [c1 , .., ck ] along with
the total budget T completely defines this budget setting. It
should be noted that S1 is a special case of S2.
We note that unless otherwise stated, we work with the
most general setting in S2. We state some of our results

in the setting S1 for clearer exposition.
Objectives: There are two main quantities of interest:
(Probability of Error): This is the probability of failing to
identify the best soft intervention (arm). Let k̂(T, B) be the
arm that is predicted to be the best arm at the end of the experiment. Then the probability of error e(T, B) (Audibert
& Bubeck, 2010; Carpentier & Locatelli, 2016) is given by,
⇣
⌘
e(T, B) = P k̂(T, B) 6= k ⇤
(Simple Regret): Another important quantity that has been
analyzed in the best arm identification setting is the simple
regret (Lattimore et al., 2016).
⇣ The simple
⌘ regret is given
P
by r(T, B) = k6=k⇤ k P k̂(T, B) = k .

3. Our Main Results

In this section we provide our main theoretical contributions. In Section 3.2, we provide a successive rejects style
algorithm that leverages the information leakage via importance sampling. Then, we provide theoretical guarantees on
the probability of mis-identification (e(T, B)) and simple
regret (r(T, B)) for our algorithm in Section 3.3. In order
to explain our algorithm and our results formally, we first
describe several key ideas in our algorithm and introduce
important definitions in Section 3.1.
3.1. Definitions
Quantifying Information
Leakage:
Observe that, µk =
h
i
|pa(V ))
Ek [Y ] = Ek0 Y PPk0(V
.
By
weighting samples
(V |pa(V ))
k

with the correct ratio of conditional probabilities Pk (·) and
Pk0 (·), it is possible to use samples under intervention k 0
to estimate the mean under intervention k. This is the basic
idea behind importance sampling which has been used in
similar settings (Lattimore et al., 2016; Bottou et al., 2013).
However, the variance of this estimator depends on the ratio
of Pk (·) to P0k (·). We use a specific f -divergence measure
between Pk (·) and P0k (·) to quantify the variance. This
f -divergence measure can be calculated analytically or estimated from empirical data (without access to full distributions) using techniques like that of (Pérez-Cruz, 2008).
Definition 1. Let f (·) be a non-negative convex function
such that f (1) = 0. For two joint distributions pX,Y (x, y)
and qX,Y (x, y) (and the associated conditionals), the conditional f -divergence Df (pX|Y kqX|Y ) is given by:
h ⇣
⌘i
pX|Y (X|Y )
Df (pX|Y kqX|Y ) = EqX,Y f qX|Y
.
(X|Y )

Recall that Pi is the conditional distribution of node V
given the state of its parents pa(V ). Thus, Df (Pi kPj ) is
the conditional f -divergence between the conditional distributions Pi and Pj . Now we define some log-divergences

Identifying Best Interventions through Online Importance Sampling

that are are crucial in the our analysis.
Definition 2. (Mij measure) Let f1 (x) = x exp(x 1) 1.
We define the following log-divergence measure: Mij =
1 + log(1 + Df1 (Pi kPj )), 8i, j 2 [K].
Aggregating Interventional Data: We describe an efficient estimator of Ek [Y ] (8k 2 [K]) that combines available samples from different arms. This estimator adaptively weights samples depending on the relative Mij measures, and also uses clipping to control variance by introducing bias. The estimator is given by (1).
Suppose we obtain ⌧i samples from arm i 2 [K]. Let the
total number of samples from all arms be denoted by ⌧ .
Further, let us index all the samples by s 2 {1, 2, .., ⌧ }, and
Tk ⇢ {1, 2, .., ⌧ } be the indices of all the samples collected
from arm k. Let Xj (s) denotes the sample collected for
random variable X
Punder intervention j, at time instant s.
Finally, let Zk = j2[K] ⌧j /Mkj . We denote the estimate

of µk by Ŷk✏ (✏ is an indicator of the level of confidence
desired). Our estimator is:
Ŷk✏ =
1

⇢

K
1 XX 1
Pk (Vj (s)|pa(V )j (s))
Yj (s)
⇥
Zk j=0
Mkj
Pj (Vj (s)|pa(V )j (s))
s2Tj

Pk (Vj (s)|pa(V )j (s))
 2 log(2/✏)Mkj
Pj (Vj (s)|pa(V )j (s))

.

(1)

In other words, Ŷk✏ is the weighted average of the clipped
samples, where the samples from arm j are weighted by
1/Mkj and clipped at 2 log(2/✏)Mkj . The choice of ✏ controls the bias-variance tradeoff which we will adaptively
change in our algorithm. This adaptive clipping is crucial
in deriving gap dependent bounds2 .

p
Pn
dlog 2 ⇥ log 10 T e. Let log(n) =
i=1 (1/i). We
will have an algorithm with n(T ) phases numbered by
` = 1, 2., , n(T ). Let ⌧ (`) be the total number of samples in phase `. We set P
⌧ (l) = T /(llog(n(T ))) for l 2
{1, .., n(T )}. Note that l ⌧ (l) = T . Let R be the set
of arms remaining to compete with the optimal arm at the
beginning of phase ` which is continuously updated.
Let ⌧k (`) be the samples allocated to arm k in phase `.
Let ⌧ (`) be the vector consisting of entries {⌧k (`)}. The
vector of allocated samples, i.e. ⌧ (`) is decided by Algorithm 3. Intuitively, an arm that provides sufficient information about all the remaining arms needs to be given more
budget than other less informative arms. This allocation depends on the average budget constraints and the relative log
divergences between the arms (Definition 2). Algorithm 3
formalizes this intuition, and ensures that variance of the
worst estimator (of the form (1)) for the arms in R is as
good as possible (quantified in Theorem 4 and Lemma 4).
Algorithm 1 Successive Rejects with Importance Sampling -v1 (SRISv1) - Given total budget T and the cost
budget B (along with ci ’s) picks the best arm.
1: SRIS(B, {Mkj }, T )
2: R = [K].
3: Form the matrix A 2 RK⇥K such that Akj =

4: for ` = 1 to n(T ) do
5:
⌧ (`) = ALLOCATE (c, B, A, R, ⌧ (`)) (Algo6:
7:
8:

3.2. Algorithm
Now, we describe our main algorithmic contribution - Algorithm 1 and 2. Algorithm 1 starts by having all the K
arms under consideration and then proceeds in phases, possibly rejecting one or more arms at the end of each phase.
At every phase, Estimator (1) with a phase specific choice
of the ✏ parameter (i.e. controlling bias variance trade-off),
is applied to all arms under consideration. Using a phase
specific threshold on these estimates, some arms are rejected at the end of each phase. A random arm among the
ones surviving at the end of all phases is declared to be the
optimal. We now describe the duration of various phases.
Recall the parameters T - Total sample budget available
and B - average cost budget constraint. Let n(T ) =
2

We note that the authors in (Lattimore et al., 2016) discuss the
possibility of a multi-phase approach, where clipper levels could
change across phases. However, they do not pursue this direction
(no specific algorithm or results) as their objective is to derive gap
independent bounds (minimax regret).

1
Mkj .

9:
10:
11:
12:
13:
14:
15:
16:

rithm 3)
Use arm k, ⌧k (`) times and collect samples
(Y, V, pa(V )).
for k 2 R do
Let Ŷk be the estimator for arm k as in (1) calculated with {Mkj }, ✏ = 2 (` 1) and the samples
obtained in Line 6.
end for
Let ŶH = arg maxk2R Ŷk .
R = R {k 2 R : ŶH > Ŷk + 5/2l }.
if |R| = 1 then
return: the arm in R.
end if
end for
return: A randomly chosen arm from R.

Remark 3. Note that Line 6 uses only the samples acquired in that phase. Clearly, a natural extension is to modify the algorithm to re-use all the samples acquired prior to
that step. We give that variation in Algorithm 2. We prove
all our guarantees for Algorithm 1. We conjecture that the
second variation has tighter guarantees (dropping a multiplicative log factor) in the sample complexity requirements.
The inverse of the maximal objective of the LP in Algorithm 3 acts as effective standard deviation uniformly for

Identifying Best Interventions through Online Importance Sampling

Algorithm 2 Successive Rejects with Importance Sampling -v2 (SRISv2) - Given total budget T and the cost
budget B (along with c) picks the best arm.
1: Identical to Algorithm 1 except for Line 6 where all

samples acquired in all the phases till that Line is used.

all the estimators for the remaining arms in R. It is analogous to the variance terms appearing in Bernstien-type concentration bounds (refer to Lemma 4 in the appendix).
Definition 3. The effective standard deviation for budget B and arm set R ✓ [K] is defined as ⇤ (B, R) =
1/v ⇤ (B, R) from Algorithm 3 with input B and arm set R.
Algorithm 3 Allocate - Allocates a given budget ⌧ among
the arms to reduce variance.
1: ALLOCATE(c, B, A, R, ⌧ )
2: Solve the following LP:
1
⇤ (B, R)

= v ⇤ (B, R) = max min[A⌫⌫ ]k
⌫

s.t.

K
X
i=0

(2)

k2R

ci ⌫i  B and

K
X

⌫j = 1, ⌫i

0.

j=0

3: Assign ⌧j = ⌫j⇤ (B, R)⌧

Comparison with the result in (Audibert & Bubeck,
2010): Let R̃( k ) = {s : s  k }, i.e. the set
of arms which are closer to the optimal than arm k. Let
H̃ = max |R̃( 2k )| . The result in (Audibert & Bubeck,
k6=k⇤

k

2010) can be stated as: The error
in finding
the optimal
⇣
⇣
⌘⌘
T K
arm is bounded as: e(T )  O K 2 exp
.
log(K)H̃

Our work is analogous to the above result (upto poly log
factors) except that H̄ appears instead of H̃. In Section D.1
(in the appendix), we demonstrate through simple exam⇤
⇤
ples
q that (B, R ( k )) can be significantly smaller than

R̃( k ) (the corresponding term in e(T ) above) even
when there are no average budget constraints. Moreover,
our results can be exponentially better in the presence of
average budget constraints (examples in Section D.1). Now
we present our bounds on simple regret in Theorem 2.
Theorem 2. (Proved formally as Theorem 5) Let ⇤ (.) be
the effective standard deviation as in Definition 3. The simple regret of Algorithm 1 when the number of samples is T
satisfies:
p o
10 n
r(T, B)  p 1 9k 6= k ⇤ s.t k < 10/ T +
T
✓
◆
✓
◆
X
20
T
2K 2
log
exp
k
2
2H̄k log(n(T ))
k
k6=k⇤ :
k

p
10/ T

(5)
3.3. Theoretical Guarantees
We state our main results as Theorem 1 and Theorem 2,
which provide guarantees on probability of error and simple regret respectively. Our results can be interpreted as a
natural generalization of the results in (Audibert & Bubeck,
2010), when there is information leakage among the arms.
This is the first gap dependent characterization.
Theorem 1. (Proved formally as Theorem 5) Let
=
min k . Let ⇤ (.) be the effective standard deviation as
k6=k⇤

in Definition 3. The probability of error for Algorithm 1
satisfies:
✓
◆
T
2
e(T, B)  2K log2 (20/ ) exp
(3)
2H̄log(n(T ))
when the p
budget for the total number of samples is T and
10/ T . Here,
H̄ = max⇤ log2 (10/
k6=k

k)

3

✓

⇤

(B, R⇤ (
k

k ))

◆2

(4)

⇣ ⌘
⇣ ⌘
and R⇤ ( k ) = {s : log2 10s
blog2 10k c} is the set
of arms whose distance from the optimal arm is roughly at
most twice that of arm k.

Here, H̄k = max{l: l
⇣ ⌘
R⇤ ( k ) = {s : log2 10s

k}

(

log2 (10/ l )3
2 v ⇤ (B,R⇤ (
⌘
10

l /10)

blog2

⇣

k

l ))

2

and

c}.

Comparison with the result in (Lattimore et al., 2016):
In (Lattimore
et al., 2016), the simple regret scales as
p
O(1/ T ) and does not adapt to the gaps. We provide gap
dependent bounds that can be exponentially better than that
of (Lattimore et al., 2016) (when k ’s are not too small and
the first term in (5) is zero). More over our bounds
p generalize to gap independent bounds that match O(1/ T ). Further details are provided in Section D.2 (in the appendix).
We defer the theoretical analysis to Section E. Theorem 1
and Theorem 2 are subparts of our main technical theorem
(Theorem 5), which is proved in Section E.5.

4. Empirical Validation
We empirically validate the performance of our algorithms
in two real data settings. In Section 4.1, we study the empirical performance of our algorithm on the flow cytometry
data-set (Sachs et al., 2005). In Section 4.2, we apply our
algorithms for the purpose of model interpretability of the
Inception Deep Network (Szegedy et al., 2015) in the context of image classification. In Section F (in the appendix)

Identifying Best Interventions through Online Importance Sampling

we include more experiments. In the appendix we empirically show that our divergence metric is fundamental and
replacing it with other divergences is sub-optimal.
4.1. Flow Cytometry Data-Set
The flow cytometry data-set (Sachs et al., 2005) (extensively used for validating causal inference algorithms) consists of multi-variate measurements of protein interactions
in a single cell, under different experimental conditions
(soft interventions). Our experiments are aimed at identifying the best intervention among many, given some ground
truth about the causal graph. For, this purpose we borrow
the causal graph from Fig. 5(c) in (Mooij & Heskes, 2013)
(shown in Fig. 3a) and consider it to be the ground truth.
Parametric linear models have been popularly used for
causal inference on this data-set (Meinshausen et al., 2016;
Cho et al., 2016). We fit a GLM gamma model (Hardin
et al., 2007) between the activation of each node and its parents in Fig. 3a using the observational data. In Section F.2
(in the appendix) we provide further details showing that
the sampled distributions in the fitted model are extremely
close to the empirical distributions from the data. The soft
interventions signifying the arms are generated by changing the distribution of a source node pkc in the GLM. The
objective is to identify the intervention that yields the highest output at the target node erk3 We provide empirical results for two sets of interventions at the source node. Both
these experiments have been performed with 15 arms each
representing different distributions at pkc.
Budget Restriction: The experiments are performed in the
budget setting S1, where all arms except arm 0 are deemed
to be difficult. We plot our results as a function of the total
samples T , while
the difficult arms
p the fractional budget ofP
p
(B) is set to 1/ T . Therefore, we have k6=0 Tk  T .
This essentially belongs to the case when there is a lot of
data that can be acquired for a default arm while any new
change requires significant cost in acquiring samples.
Competing Algorithms: We test our algorithms on different problem parameters and compare with related prior
work (Audibert & Bubeck, 2010; Lattimore et al., 2016).
The algorithms compared are (i) SRISv1: Algorithm 1 introduced in Section 3.2. The divergences, Df1 (Pi ||Pj ) are
estimated from sampled data using techniques from (PérezCruz, 2008); (ii)SRISv2: Algorithm 2 as detailed in Section 3.2; (iii) SR: Successive Rejects Algorithm from (Audibert & Bubeck, 2010) adapted to the budget setting. The
division of the total budget T into K 1 phases is identical,
3
The activations of the node erk have been scaled so that the
mean is less than one. Note that the marginal distribution still has
an exponential tail, and thus does not strictly adhere to our boundedness assumption on the target variable. However, the experiments suggest that our algorithms still perform extremely well.

while the individual arm budgets are decided in each phase
according to the budget restrictions; (iv) CR: Algorithm 2
from (Lattimore et al., 2016). The optimization problem for
calculating the mixture parameter ⌘ is not efficiently solvable for general distributions and budget settings. Therefore, the mixture proportions are set by Algorithm 3.
In these experiments, the budget restrictions imply that arm
0 can be pulled much more than the other arms. Intuitively
the divergences of the arms from arm 0 as well as the gap
defines the hardness of identification. Fig. 3b represents
a difficult scenario where the divergences Mk0 > 400 for
many arms (large divergences imply low information leakage) and = 0.01 (small increases hardness). In Fig. 3c
(easier scenario) the divergences Mk0 < 20 for most arms
while the gap is same as before. We see that SRISv2 outperforms all the other algorithms by a large margin, especially in the low sample regime.
4.2. Interpretability of Inception Deep Network
In this section we use our algorithm for model interpretation of the pre-trained Inception-v3 network (Szegedy
et al., 2015) for classifying images. Model Interpretation
essentially addresses: ’why does a learning model classify in a certain way?’, which is an important question for
complicated models like deep nets (Ribeiro et al., 2016).
When an RGB image is fed to Inception, it produces an
ordered sequence of 1000 labels (e.g ’drums’, ’sunglasses’)
and generally the top-10 labels are an accurate description
of the objects in the image. To address interpretability, we
segment the image into a number of superpixels/segments
(using segmentation algorithms like SLIC (Achanta et al.,
2010)) and infer which superpixels encourage the neural
net to output a certain label (henceforth referred to as labelI; e.g ’drum’) in top-k (e.g. k = 10), and to what extent.
Given a mixture distribution over the superpixels of an image (Figure 4a), a few superpixels are randomly sampled
from the distribution with replacement. Then a new image
is generated where all other superpixels of the original image are blurred out except the ones selected. This image
is then fed to Inception, and it is observed whether labelI appears within the top-k labels. A mixture distribution
is said to be a good interpretation for label-I if there is a
high probability that label-I appears for an image generated
by this mixture distribution. To empirically test the goodness of a mixture distribution, we would generate (using
this mixture distribution) a number of random images, and
determine the fraction of images for which label-I appears;
a large fraction indicates that the mixture distribution is a
good interpretation of label-I.
Motivated by the above discussion, we generate a large
number (3200) of mixture distributions, with the goal of

Identifying Best Interventions through Online Importance Sampling
0.3

0.4

pip3

SRISv1
SRISv2
SR
CR

pkc (Source)
0.35

66% below SR
0.3

pip2

SR
SRISv1
SRISv2
CR

0.25

86% below CR

pka

70% below SR

0.2
0.25

75% below CR
0.2

plcg

akt

mek

jnk

p38

0.15

0.15
0.1
0.1

erk (Target)

raf

0.05

0.05
0

(a) Causal Graph for Cytometry
Data (Mooij & Heskes, 2013)

100

200

300

400

500

600

700

800

900

(b) Simple Regret when divergences
Mk0 ’s are high and gap is small

0

100

200

300

400

500

600

700

800

900

(c) Simple Regret when divergences
Mk0 ’s are low and gap is small

Figure 3. Performance of various algorithms on the cytometry data under different scenarios. The results are averaged over the course of
500 independent
pexperiments. The total sample budget T is plotted on the x-axis. The budget for all arms other than arm 0 is constrained
to be less than T . Here K = 15. The performance improvement is especially evident in the low sample regime. For, example in (b)
SRISv2 provides more than 65% improvement over CR and SR. It is significant in biological data where number of samples is generally
small. SR does not use information leakage while the static clipper in CR cannot adapt to high divergences like in (b).

finding the one that best interprets label-I. To highlight the
applicability of our algorithm, we allow images to be generated for only 200 of these mixture distributions; in other
words, most of the mixture distributions cannot be directly
tested. Nevertheless, we determine the best from among the
entire collection of mixture distributions (counterfactuals).
Specifically in our experiments, we consider the image in
Figure 4a, partition it into 43 superpixels, and generate images from mixture distributions by sampling 5 superpixels
(with replacement). We generate 3000 arm distributions
which lie in the 43-dimensional simplex but have sparse
support (sparsity of 10 in our examples). The support of
these distributions are randomly generated by techniques
like markov random walk (encourages contiguity), random
choice, etc. as detailed in Section F.3 in the appendix.
We are only allowed to sample using a different set of 200
arms that are dense distributions chosen uniformly at random from the 43-dimensional simplex. The distributions
are generated in a manner which is completely agnostic to
the image content. The total sample budget (T ) is 2500.
Figure 4 shows images in which the segments are weighted
in proportion to the optimal distribution (obtained by
SRISv2) for the interpretation of three different labels. This
showcases the true counterfactual power of the algorithm,
as the set of arms that can be optimized over are disjoint
from the arms that can be sampled from. Moreover the
sample budget is less than the number of arms. This is
an extreme special case of budget setting S2. We see that
our algorithm can generate meaningful interpretations for
all the labels with relatively less number of runs of Inception. Even sampling 10 times from each of the arms to be
optimized over would require 30, 000 runs of Inception for
a single image and label, while we use only 2500 runs by
leveraging information leakage.
Conclusion: In this paper we provide the first gap depen-

(a) Original Image

(b) Interpretation- Drums

(c) Interpretation- TigerCat

(d) Interpretation- Sunglasses

Figure 4. Interpretation for different top labels for the image in
(a); Image courtesy (cat). The best mixture distribution generates
an image where the highlighted superpixels are most indicative of
a label. For example, in (b) we see the drums highlighted, while in
(d) (a different mixture distribution), sunglasses are in the focus.

dent error and simple regret bounds for identifying the best
soft intervention at a source node i.e the one that maximizes
the expected value of a downstream target node. These
bounds are a generalization of the classical best arm identification bounds (Audibert & Bubeck, 2010), when there
is information leakage among the arms. We test our algorithm empirically on the flow cytometry data-set and also
use it for interpretability of Inception-v3 deep net.

Acknowledgements
This work is partially supported by NSF grants CNS1320175, CCF-1344364, 1407278, 1422549, 1618689,
ARO grants W911NF-15-1-0227, W911NF-14-1-0258,
W911NF-16-1-0377 and the US DoT supported D-STOP
Tier 1 University Transportation Center.

Identifying Best Interventions through Online Importance Sampling

References
Image source. http://bit.ly/2hviIwP. Accessed:
2017-02-23.
Abernethy, Jacob, Chen, Yiling, Ho, Chien-Ju, and Waggoner, Bo. Low-cost learning via active data procurement. In Proceedings of the Sixteenth ACM Conference
on Economics and Computation, pp. 619–636. ACM,
2015.

Gabillon, Victor, Ghavamzadeh, Mohammad, and Lazaric,
Alessandro. Best arm identification: A unified approach
to fixed budget and fixed confidence. In Advances in
Neural Information Processing Systems, pp. 3212–3220,
2012.
Hardin, James William, Hilbe, Joseph M, and Hilbe,
Joseph. Generalized linear models and extensions. Stata
press, 2007.

Achanta, Radhakrishna, Shaji, Appu, Smith, Kevin, Lucchi, Aurelien, Fua, Pascal, and Süsstrunk, Sabine. Slic
superpixels. Technical report, 2010.

Hauser, Alain and Bühlmann, Peter. Two optimal strategies for active learning of causal networks from interventional data. In Proceedings of Sixth European Workshop
on Probabilistic Graphical Models, 2012.

Audibert, Jean-Yves and Bubeck, Sébastien. Best arm
identification in multi-armed bandits. In COLT-23th
Conference on Learning Theory-2010, pp. 13–p, 2010.

Hyttinen, Antti, Eberhardt, Frederick, and Hoyer, Patrik.
Experiment selection for causal discovery. Journal of
Machine Learning Research, 14:3041–3071, 2013.

Bennett, George. Probability inequalities for the sum of
independent random variables. Journal of the American
Statistical Association, 57(297):33–45, 1962.

Jamieson, Kevin G, Malloy, Matthew, Nowak, Robert D,
and Bubeck, Sébastien. lil’ucb: An optimal exploration
algorithm for multi-armed bandits. In COLT, volume 35,
pp. 423–439, 2014.

Blalock, Hubert M. Causal models in the social sciences.
Transaction Publishers, 1985.
Bonneau, Richard, Facciotti, Marc T, Reiss, David J,
Schmid, Amy K, Pan, Min, Kaur, Amardeep, Thorsson, Vesteinn, Shannon, Paul, Johnson, Michael H, Bare,
J Christopher, et al. A predictive model for transcriptional control of physiology in a free living cell. Cell,
131(7):1354–1365, 2007.
Bottou, Léon, Peters, Jonas, Candela, Joaquin Quinonero,
Charles, Denis Xavier, Chickering, Max, Portugaly,
Elon, Ray, Dipankar, Simard, Patrice Y, and Snelson, Ed.
Counterfactual reasoning and learning systems: the example of computational advertising. Journal of Machine
Learning Research, 14(1):3207–3260, 2013.
Carpentier, Alexandra and Locatelli, Andrea. Tight (lower)
bounds for the fixed budget best arm identification bandit
problem. arXiv preprint arXiv:1605.09004, 2016.
Chen, Lijie and Li, Jian. On the optimal sample complexity for best arm identification. arXiv preprint
arXiv:1511.03774, 2015.
Cho, Hyunghoon, Berger, Bonnie, and Peng, Jian. Reconstructing causal biological networks through active
learning. PloS one, 11(3):e0150611, 2016.
Eberhardt, Frederick. Almost optimal intervention sets for
causal discovery. In Proceedings of 24th Conference
in Uncertainty in Artificial Intelligence (UAI), pp. 161–
168, 2008.

Joffe, Michael, Gambhir, Manoj, Chadeau-Hyam, Marc,
and Vineis, Paolo. Causal diagrams in systems epidemiology. Emerging themes in epidemiology, 9(1):1, 2012.
Kaufmann, Emilie, Cappé, Olivier, and Garivier, Aurélien.
On the complexity of best arm identification in multiarmed bandit models. The Journal of Machine Learning
Research, 2015.
Kemmeren, Patrick, Sameith, Katrin, van de Pasch,
Loes AL, Benschop, Joris J, Lenstra, Tineke L, Margaritis, Thanasis, O?Duibhir, Eoghan, Apweiler, Eva,
van Wageningen, Sake, Ko, Cheuk W, et al. Largescale genetic perturbations reveal regulatory networks
and an abundance of gene-specific repressors. Cell, 157
(3):740–752, 2014.
Krouk, Gabriel, Lingeman, Jesse, Colon, Amy Marshall,
Coruzzi, Gloria, and Shasha, Dennis. Gene regulatory
networks in plants: learning causality from time and perturbation. Genome biology, 14(6):1, 2013.
Lattimore, Finnian, Lattimore, Tor, and Reid, Mark D.
Causal bandits: Learning good interventions via causal
inference. In Advances In Neural Information Processing Systems, pp. 1181–1189, 2016.
Li, Lihong, Chu, Wei, Langford, John, and Wang, Xuanhui.
Unbiased offline evaluation of contextual-bandit-based
news article recommendation algorithms. In Proceedings of the fourth ACM international conference on Web
search and data mining, pp. 297–306. ACM, 2011.

Identifying Best Interventions through Online Importance Sampling

Loh, Po-Ling and Bühlmann, Peter. High-dimensional
learning of linear causal networks via inverse covariance
estimation. Journal of Machine Learning Research, 15
(1):3065–3105, 2014.

Sugiyama, Masashi, Krauledat, Matthias, and MÃžller,
Klaus-Robert. Covariate shift adaptation by importance
weighted cross validation. Journal of Machine Learning
Research, 8(May):985–1005, 2007.

Meinshausen, Nicolai, Hauser, Alain, Mooij, Joris M, Peters, Jonas, Versteeg, Philip, and Bühlmann, Peter. Methods for causal inference from gene perturbation experiments and validation. Proceedings of the National
Academy of Sciences, 113(27):7361–7368, 2016.

Szegedy, Christian, Liu, Wei, Jia, Yangqing, Sermanet,
Pierre, Reed, Scott, Anguelov, Dragomir, Erhan, Dumitru, Vanhoucke, Vincent, and Rabinovich, Andrew.
Going deeper with convolutions. In Proceedings of
the IEEE Conference on Computer Vision and Pattern
Recognition, pp. 1–9, 2015.

Mooij, Joris and Heskes, Tom. Cyclic causal discovery from continuous equilibrium data. arXiv preprint
arXiv:1309.6849, 2013.
Mooij, Joris M, Peters, Jonas, Janzing, Dominik, Zscheischler, Jakob, and Schölkopf, Bernhard. Distinguishing
cause from effect using observational data: methods and
benchmarks. Journal of Machine Learning Research, 17
(32):1–102, 2016.
Pearl, Judea. Causality: Models, Reasoning and Inference.
Cambridge University Press, 2009a.
Pearl, Judea.
2009b.

Causality.

Cambridge university press,

Pérez-Cruz, Fernando. Kullback-leibler divergence estimation of continuous distributions. In Information Theory,
2008. ISIT 2008. IEEE International Symposium on, pp.
1666–1670. IEEE, 2008.
Ribeiro, Marco Tulio, Singh, Sameer, and Guestrin, Carlos.
Why should i trust you?: Explaining the predictions of
any classifier. In Proceedings of the 22nd ACM SIGKDD
International Conference on Knowledge Discovery and
Data Mining, pp. 1135–1144. ACM, 2016.
Sachs, Karen, Perez, Omar, Pe’er, Dana, Lauffenburger,
Douglas A, and Nolan, Garry P. Causal protein-signaling
networks derived from multiparameter single-cell data.
Science, 308(5721):523–529, 2005.
Shanmugam, Karthikeyan, Kocaoglu, Murat, Dimakis,
Alexandros G, and Vishwanath, Sriram. Learning causal
graphs with small interventions. In Advances in Neural
Information Processing Systems, pp. 3195–3203, 2015.
Slivkins, Aleksandrs. Dynamic ad allocation: Bandits with
budgets. arXiv preprint arXiv:1306.0155, 2013.
Spirtes, Peter, Glymour, Clark, and Scheines, Richard.
Causation, Prediction, and Search. A Bradford Book,
2001.
Splawa-Neyman, Jerzy, Dabrowska, DM, Speed, TP, et al.
On the application of probability theory to agricultural
experiments. essay on principles. section 9. Statistical
Science, 5(4):465–472, 1990.

Zhang, Tong and Zhao, Peiling. Stochastic optimization
with importance sampling for regularized loss minimization. arXiv preprint arXiv:1401.2753, 2014.

